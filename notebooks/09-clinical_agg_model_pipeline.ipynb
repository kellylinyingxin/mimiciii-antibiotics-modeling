{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# description 6/03/19 clinically guided aggregation modeling w/ 2 elix variables\n",
    "\n",
    "sklearn modeling using local methods of the median imputed training data using origional min/max clinically guided aggregation. note the preprocessing of data from 07.20-worst_case_model was performed in R (09.newagg2_preprocessing_med_impute.rmd). this eventually will be converted over to python, but for now works in r. \n",
    "\n",
    "preprocessing includes variable formatting (categorical to factor variables in r, train/test split, and median imputation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 50.7 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, auc, precision_recall_fscore_support, pairwise, f1_score, log_loss, make_scorer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, Imputer\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import validation\n",
    "from scipy.sparse import issparse\n",
    "from scipy.spatial import distance\n",
    "from sklearn import svm\n",
    "\n",
    "#importin xg boost and all needed otherstuff\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier #conda install -c conda-forge xgboost to install\n",
    "##adding these, lets see if it helps with xgboost crash\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#reducing warnings that are super common in my model\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.simplefilter(action='ignore') #ignore all warnings\n",
    "\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "RANDOM_STATE = 15485867\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing and formatting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.92 ms\n"
     ]
    }
   ],
   "source": [
    "# # ##24 hr sensitivity\n",
    "# # #importing in all clinical_variable files\n",
    "# lower_window=0\n",
    "# upper_window=1\n",
    "# time_col=\"charttime\"\n",
    "# time_var=\"t_0\"\n",
    "# folder=\"{}_hr_window\".format(timewindowdays)\n",
    "# timewindowdays=\"24\"\n",
    "# date= '09062019'\n",
    "# patient_df= final_pt_df2\n",
    "\n",
    "# #48 hr sensitivity\n",
    "# lower_window=0\n",
    "# upper_window=2\n",
    "# time_var=\"t_0\"\n",
    "# timewindowdays=\"48\"\n",
    "# folder=\"{}_hr_window\".format(timewindowdays)\n",
    "# date='16052019'\n",
    "# time_col=\"charttime\"\n",
    "# time_var= 't_0'\n",
    "# patient_df= final_pt_df2\n",
    "\n",
    "#72 hr elixhauser-redo\n",
    "date='11062019'\n",
    "lower_window=0\n",
    "upper_window=3\n",
    "timewindowdays=\"72\"\n",
    "folder=\"{}_hr_window\".format(timewindowdays)\n",
    "time_col=\"charttime\"\n",
    "time_var= 't_0'\n",
    "patient_df= final_pt_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 88.6 ms\n"
     ]
    }
   ],
   "source": [
    "#cohort import\n",
    "\n",
    "os.chdir('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling') #use to change working directory\n",
    "wd= os.getcwd() #'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling'\n",
    "\n",
    "\n",
    "final_pt_df2 = pd.read_csv(Path(wd + '/data/raw/csv/04042019_final_pt_df2_v.csv') , index_col=0) #only for patients with minimum vitals, 14478 icustay_id\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.3 ms\n"
     ]
    }
   ],
   "source": [
    "# #importing in all clinical_variable files\n",
    "# os.chdir(r'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/processed/')\n",
    "# train_data= pd.read_csv(Path(wd+'/data/processed/merged/{}_worst_df_train_preImp_{}.csv'.format(date,timewindowdays),  index_col=0))\n",
    "# test_data= pd.read_csv(Path(wd+'/data/processed/merged/{}_worst_df_test_preImp_{}.csv'.format(date,timewindowdays),  index_col=0))\n",
    "\n",
    "#importing in all clinical_variable files\n",
    "os.chdir(r'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/processed/')\n",
    "train_data= pd.read_csv(Path(wd+'/data/processed/merged/{}_worst_df_train_preImp_{}_2.csv'.format(date,timewindowdays),  index_col=0))\n",
    "test_data= pd.read_csv(Path(wd+'/data/processed/merged/{}_worst_df_test_preImp_{}_2.csv'.format(date,timewindowdays),  index_col=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'any_vasoactives',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'first_admit_age',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'weight',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " \"('max', 'calcium')\",\n",
       " \"('max', 'sodium')\",\n",
       " \"('max', 'wbc')\",\n",
       " \"('min', 'calcium')\",\n",
       " \"('min', 'sodium')\",\n",
       " \"('min', 'wbc')\",\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.63 ms\n"
     ]
    }
   ],
   "source": [
    "list(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.82 ms\n"
     ]
    }
   ],
   "source": [
    "vaso_active=['phenylephrine',\n",
    "            'norepinephrine',\n",
    "            'vasopressin',\n",
    "            'dobutamine',\n",
    "            'dopamine',\n",
    "            'epinephrine'] \n",
    "\n",
    "ordinal=[\n",
    "            'leukocyte',\n",
    "            'nitrite',\n",
    "            'vent_recieved',\n",
    "            'o2_flow',\n",
    "            'rrt',\n",
    "            'pao2fio2ratio',\n",
    "            'cancer_elix',\n",
    "            \"any_vasoactives\",\n",
    "            'bands',\n",
    "            'pco2'\n",
    "]\n",
    "\n",
    "categorical=[\n",
    "            \"ethnicity\",\n",
    "            'gender'\n",
    "]\n",
    "\n",
    "### 06/18/19 changed this to be consistent with the 07.20 model_aggregation notebook\n",
    "categorical_variables= vaso_active+ordinal+categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(preimp_df):\n",
    "\n",
    "    \"\"\"\n",
    "    1) rename columns\n",
    "    2) standardize last 2 columns to be standardized\n",
    "    3) convert categorical columns to proper format\n",
    "    4) median impute\n",
    "    \"\"\"\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    global categorical_variables\n",
    "    \n",
    "    rename_dic={\n",
    "    \"('max', 'sodium')\": \"maxSodium\" ,\n",
    "    \"('max', 'sodium')\" : \"maxSodium\",\n",
    "    \"('min', 'sodium')\" : \"minSodium\",\n",
    "    \"('max', 'calcium')\" : \"maxCalcium\",\n",
    "    \"('min', 'calcium')\" : \"minCalcium\",\n",
    "    \"('max', 'sodium')\": \"maxSodium\",\n",
    "    \"('min', 'sodium')\": \"minSodium\",\n",
    "    \"('max', 'wbc')\": \"maxWBC\",\n",
    "    \"('min', 'wbc')\": \"minWBC\",\n",
    "    \"any_vasoactive\": \"any_vasoactives\"\n",
    "        }\n",
    "    data=preimp_df.copy()\n",
    "    data=data.rename(rename_dic, axis='columns').copy()\n",
    "    \n",
    "#     ##changing the deitentified ages to 90.\n",
    "#     data.loc[data['first_admit_age']>90,\"first_admit_age\"]=90\n",
    "    \n",
    "\n",
    "#     weight_median=np.log(data.loc[data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).median()\n",
    "#     weight_quant1=np.log(data.loc[data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).quantile(0.25)#.between(train_data['col'].quantile(.25), df['col'].quantile(.75), inclusive=True)]\n",
    "#     weight_quant3=np.log(data.loc[data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).quantile(0.75)\n",
    "#     weight_iqr=weight_quant3-weight_quant1\n",
    "#     #print(weight_median,weight_quant3,weight_quant1, weight_iqr)\n",
    "\n",
    "#     age_median=np.log((data.loc[data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"].median()+1))\n",
    "# #     age_quant1=np.log((data.loc[data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]+1).quantile(0.25))\n",
    "# #     age_quant3=np.log((data.loc[data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]+1).quantile(0.75))\n",
    "#     age_quant1=(data.loc[data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]).quantile(0.25)\n",
    "#     age_quant3=(data.loc[data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]).quantile(0.75)\n",
    "#     age_iqr=np.log((age_quant3-age_quant1)+1)\n",
    "#     print(age_median,age_quant1,age_quant3, age_iqr)\n",
    "\n",
    "#     #converting to log scaled standardized data for age/weight\n",
    "#     data['weight']=data['weight'].apply(lambda x: (np.log(x+1)-weight_median)/weight_iqr)\n",
    "#     data['first_admit_age']=data['first_admit_age'].apply(lambda x: (np.log(x+1)-age_median)/age_iqr)\n",
    "    \n",
    "    ### onehot encoding categorical var\n",
    "    cols_to_transform= categorical_variables\n",
    "    data = pd.get_dummies(data, columns = cols_to_transform, drop_first=True)\n",
    "    \n",
    "    #binarizing and poping outcome for training data\n",
    "    data.loc[data['final_bin']==\"C_pos/A_full\",\"final_bin\"]=1\n",
    "    data.loc[data['final_bin']==\"C_neg/A_partial\",\"final_bin\"]=0\n",
    "    data['final_bin']=pd.to_numeric(data['final_bin'])\n",
    "    \n",
    "    \n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    data=pd.DataFrame(imp.fit_transform(data), columns=list(data))\n",
    "\n",
    "    ## establishing training data and labels\n",
    "    x_train= data.copy()\n",
    "    z_icustay_id=x_train.pop('icustay_id')\n",
    "    y_train= x_train.pop(\"final_bin\").values\n",
    "    \n",
    "    return(x_train, y_train, z_icustay_id)\n",
    "\n",
    "# x_train, y_train, z_icustay_id= preprocessing(pd.merge(preimp_train_df, final_pt_df2[['icustay_id','final_bin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.1 ms\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(preimp_df):\n",
    "\n",
    "    \"\"\"\n",
    "    1) rename columns\n",
    "    2) standardize last 2 columns to be standardized\n",
    "    3) convert categorical columns to proper format\n",
    "    4) median impute\n",
    "    \"\"\"\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    global categorical_variables\n",
    "    \n",
    "    rename_dic={\n",
    "    \"('max', 'sodium')\": \"maxSodium\" ,\n",
    "    \"('max', 'sodium')\" : \"maxSodium\",\n",
    "    \"('min', 'sodium')\" : \"minSodium\",\n",
    "    \"('max', 'calcium')\" : \"maxCalcium\",\n",
    "    \"('min', 'calcium')\" : \"minCalcium\",\n",
    "    \"('max', 'sodium')\": \"maxSodium\",\n",
    "    \"('min', 'sodium')\": \"minSodium\",\n",
    "    \"('max', 'wbc')\": \"maxWBC\",\n",
    "    \"('min', 'wbc')\": \"minWBC\",\n",
    "    \"any_vasoactive\": \"any_vasoactives\"\n",
    "        }\n",
    "    data=preimp_df.copy()\n",
    "    data=data.rename(rename_dic, axis='columns').copy()\n",
    "        \n",
    "    #binarizing and poping outcome for training  data\n",
    "    data.loc[data['final_bin']==\"C_pos/A_full\",\"final_bin\"]=1\n",
    "    data.loc[data['final_bin']==\"C_neg/A_partial\",\"final_bin\"]=0\n",
    "    data['final_bin']=pd.to_numeric(data['final_bin'])\n",
    "    \n",
    "    return(data)\n",
    "\n",
    "# x_train, y_train, z_icustay_id= preprocessing(pd.merge(preimp_train_df, final_pt_df2[['icustay_id','final_bin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.5 ms\n"
     ]
    }
   ],
   "source": [
    "train_data=preprocessing(pd.merge(train_data, final_pt_df2[['icustay_id','final_bin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#     ### onehot encoding categorical var\n",
    "#     cols_to_transform= categorical_variables\n",
    "#     data = pd.get_dummies(data, columns = cols_to_transform, drop_first=True)\n",
    "    \n",
    "#     #binarizing and poping outcome for training data\n",
    "#     data.loc[data['final_bin']==\"C_pos/A_full\",\"final_bin\"]=1\n",
    "#     data.loc[data['final_bin']==\"C_neg/A_partial\",\"final_bin\"]=0\n",
    "#     data['final_bin']=pd.to_numeric(data['final_bin'])\n",
    "    \n",
    "    \n",
    "#     imp = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "#     data=pd.DataFrame(imp.fit_transform(data), columns=list(data))\n",
    "\n",
    "#     ## establishing training data and labels\n",
    "#     x_train= data.copy()\n",
    "#     z_icustay_id=x_train.pop('icustay_id')\n",
    "#     y_train= x_train.pop(\"final_bin\").values\n",
    "    \n",
    "#     return(x_train, y_train, z_icustay_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.194642283537465 51.945 77.715 3.2872818575322613\n",
      "4.186923743515194 51.545 77.815 3.305787196857497\n",
      "time: 175 ms\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train, z_icustay_id = preprocessing(pd.merge(train_data, final_pt_df2[['icustay_id','final_bin']]))\n",
    "# x_test, y_test, z_icustay_id_test= preprocessing(pd.merge(test_data, final_pt_df2[['icustay_id','final_bin']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 885 Âµs\n"
     ]
    }
   ],
   "source": [
    "# x_train, y_train, z_icustay_id = preprocessing(pd.merge(train_data, final_pt_df2[['icustay_id','final_bin']]))\n",
    "# x_test, y_test, z_icustay_id_test= preprocessing(pd.merge(test_data, final_pt_df2[['icustay_id','final_bin']]))\n",
    "# #for local modeling\n",
    "# # all_xy=xy_preprocessing(train_data)\n",
    "# # all_xy_test=xy_preprocessing(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>any_vasoactives</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>...</th>\n",
       "      <th>maxWBC</th>\n",
       "      <th>minCalcium</th>\n",
       "      <th>minSodium</th>\n",
       "      <th>minWBC</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>bands</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "      <th>final_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.013376</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.098057</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.079716</td>\n",
       "      <td>-0.504523</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.344496</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200061.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227339</td>\n",
       "      <td>-0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.113897</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.332269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.851968</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>-0.038084</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721779</td>\n",
       "      <td>-0.227670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200078.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009248</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.386848</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200091.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812191</td>\n",
       "      <td>0.143949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.260704</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200136.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025228</td>\n",
       "      <td>0.164484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200141.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200188.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>-0.354673</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>-0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200215.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481072</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.427919</td>\n",
       "      <td>-0.350603</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>0.284418</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200231.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.058671</td>\n",
       "      <td>0.243696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.851968</td>\n",
       "      <td>1.160964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.252156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.536490</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200249.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>-1.478712</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085892</td>\n",
       "      <td>0.049143</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.131249</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200265.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200312.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.528634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.151932</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200321.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.195868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.278222</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200325.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.379634</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200343.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028296</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.159008</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200345.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281303</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200352.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>0.251425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018678</td>\n",
       "      <td>1.840472</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.203555</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200368.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200398.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.455340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.067573</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200417.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.687091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>2.441506</td>\n",
       "      <td>0.868483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>-0.504523</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200439.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200441.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.202063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.337591</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>299534.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>299557.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.510567</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126568</td>\n",
       "      <td>-0.249229</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>299581.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>2.106843</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314609</td>\n",
       "      <td>0.291465</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>299593.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.085892</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>299614.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>-0.489433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258973</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.038084</td>\n",
       "      <td>-0.061604</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>299629.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689817</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221881</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>299630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>0.479095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>2.539874</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>-0.980315</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>299645.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271847</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.122378</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>299654.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.434142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>1.952073</td>\n",
       "      <td>1.251250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315081</td>\n",
       "      <td>-2.061754</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-1.018842</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>299655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.952073</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.044086</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>299666.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.151932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.195868</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>299685.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>299695.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.273576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>299715.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.133254</td>\n",
       "      <td>0.326242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>1.111196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193190</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.324707</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>299728.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.358787</td>\n",
       "      <td>0.219354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035311</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>1.111196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314609</td>\n",
       "      <td>-0.249229</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.892552</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>299734.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>-0.198908</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.096522</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>299736.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.371004</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166755</td>\n",
       "      <td>-0.556336</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.073610</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>299751.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>299765.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214851</td>\n",
       "      <td>-0.452965</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>299811.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.788787</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023463</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.118154</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>299826.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510959</td>\n",
       "      <td>0.294328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.104861</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>299853.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076090</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242431</td>\n",
       "      <td>-1.766184</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>299858.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>-0.094492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>-0.124529</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>299863.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450237</td>\n",
       "      <td>0.219354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162870</td>\n",
       "      <td>-0.148826</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.481647</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>299880.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>0.425264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056133</td>\n",
       "      <td>2.056801</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.049862</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>299883.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.235459</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>299913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>0.508310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.689817</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>-0.010685</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>299914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>0.371619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048130</td>\n",
       "      <td>2.884747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.067573</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>299950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>asian</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>299955.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>0.273576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>2.337099</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5316 rows Ã 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      icustay_id  any_vasoactives  bilirubin       bun  cancer_elix  chloride  \\\n",
       "0       200030.0              1.0   2.013376  0.122043          0.0  0.031036   \n",
       "1       200033.0              1.0        NaN -0.053381          1.0  0.017980   \n",
       "2       200036.0              0.0        NaN  0.154377          0.0  0.026723   \n",
       "3       200061.0              0.0   1.227339 -0.073293          0.0  0.009074   \n",
       "4       200063.0              0.0  -0.077740  0.332269          0.0  0.017980   \n",
       "5       200075.0              0.0   0.721779 -0.227670          0.0  0.026723   \n",
       "6       200078.0              1.0        NaN  0.031305          0.0 -0.009248   \n",
       "7       200091.0              0.0   0.812191  0.143949          0.0  0.039548   \n",
       "8       200108.0              0.0        NaN  0.122043          0.0  0.004558   \n",
       "9       200136.0              1.0  -0.025228  0.164484          0.0  0.000000   \n",
       "10      200141.0              1.0        NaN -0.034607          0.0  0.026723   \n",
       "11      200188.0              0.0        NaN -0.167785          0.0  0.022371   \n",
       "12      200197.0              0.0        NaN -0.167785          0.0  0.000000   \n",
       "13      200215.0              0.0   0.481072  0.266357          0.0  0.004558   \n",
       "14      200231.0              1.0   1.058671  0.243696          1.0  0.013547   \n",
       "15      200249.0              0.0        NaN -0.073293          0.0  0.039548   \n",
       "16      200252.0              0.0        NaN  0.122043          0.0  0.043748   \n",
       "17      200265.0              0.0  -0.254817 -0.141494          0.0  0.000000   \n",
       "18      200312.0              0.0        NaN -0.528634          1.0  0.022371   \n",
       "19      200321.0              0.0        NaN -0.141494          0.0  0.039548   \n",
       "20      200325.0              0.0        NaN  0.059885          0.0  0.043748   \n",
       "21      200328.0              0.0        NaN  0.122043          0.0  0.017980   \n",
       "22      200343.0              0.0  -0.077740  0.016026          0.0 -0.028296   \n",
       "23      200345.0              1.0        NaN -0.141494          0.0  0.004558   \n",
       "24      200352.0              0.0  -0.192135  0.251425          0.0 -0.018678   \n",
       "25      200368.0              0.0  -0.192135 -0.053381          0.0  0.004558   \n",
       "26      200398.0              0.0        NaN -0.455340          0.0  0.031036   \n",
       "27      200417.0              0.0  -0.321825  0.687091          0.0  0.039548   \n",
       "28      200439.0              0.0  -0.321825  0.098572          0.0 -0.004602   \n",
       "29      200441.0              1.0        NaN  0.202063          0.0  0.000000   \n",
       "...          ...              ...        ...       ...          ...       ...   \n",
       "5286    299534.0              0.0        NaN  0.073293          0.0  0.004558   \n",
       "5287    299557.0              1.0        NaN  0.193064          0.0  0.026723   \n",
       "5288    299581.0              1.0        NaN  0.143949          0.0 -0.004602   \n",
       "5289    299593.0              1.0        NaN  0.016026          0.0  0.047912   \n",
       "5290    299614.0              1.0        NaN -0.196365          0.0  0.017980   \n",
       "5291    299629.0              0.0        NaN  0.280640          0.0  0.000000   \n",
       "5292    299630.0              0.0  -0.393801  0.479095          0.0 -0.004602   \n",
       "5293    299645.0              1.0        NaN  0.059885          0.0  0.026723   \n",
       "5294    299654.0              1.0  -0.321825  0.434142          0.0  0.026723   \n",
       "5295    299655.0              0.0        NaN  0.553912          0.0  0.031036   \n",
       "5296    299666.0              0.0        NaN  0.031305          0.0 -0.028296   \n",
       "5297    299685.0              0.0        NaN -0.196365          0.0  0.031036   \n",
       "5298    299695.0              0.0        NaN  0.273576          0.0  0.017980   \n",
       "5299    299715.0              1.0  -0.133254  0.326242          0.0  0.064215   \n",
       "5300    299728.0              1.0   1.358787  0.219354          1.0  0.035311   \n",
       "5301    299734.0              1.0        NaN -0.053381          0.0  0.013547   \n",
       "5302    299736.0              0.0   1.371004 -0.141494          0.0  0.004558   \n",
       "5303    299751.0              1.0        NaN  0.332269          0.0  0.017980   \n",
       "5304    299765.0              0.0  -0.321825  0.059885          0.0  0.013547   \n",
       "5305    299811.0              1.0   1.788787  0.031305          0.0 -0.023463   \n",
       "5306    299826.0              0.0   0.510959  0.294328          0.0  0.043748   \n",
       "5307    299853.0              0.0        NaN  0.382047          0.0  0.076090   \n",
       "5308    299858.0              0.0  -0.393801 -0.094492          0.0  0.000000   \n",
       "5309    299863.0              1.0   0.450237  0.219354          1.0  0.047912   \n",
       "5310    299880.0              0.0  -0.254817  0.425264          0.0  0.056133   \n",
       "5311    299883.0              0.0   0.241314  0.016026          0.0  0.031036   \n",
       "5312    299913.0              0.0  -0.192135  0.508310          0.0  0.031036   \n",
       "5313    299914.0              0.0  -0.254817  0.371619          0.0 -0.048130   \n",
       "5314    299950.0              0.0        NaN -0.053381          0.0  0.013547   \n",
       "5315    299955.0              0.0  -0.393801  0.273576          1.0  0.017980   \n",
       "\n",
       "      creatinine  daily_sofa  dobutamine  dopamine  ...    maxWBC  minCalcium  \\\n",
       "0       0.000000    0.500000         1.0       0.0  ...  0.207728    0.098057   \n",
       "1      -0.276493   -0.292481         0.0       0.0  ... -0.079716   -0.504523   \n",
       "2       0.000000   -0.292481         0.0       0.0  ... -0.144949         NaN   \n",
       "3      -0.087265    0.207519         0.0       0.0  ...  0.265449         NaN   \n",
       "4       0.851968    0.611196         0.0       0.0  ... -0.055701   -0.660735   \n",
       "5      -0.379634    0.368483         0.0       0.0  ...  0.317537         NaN   \n",
       "6       0.162151         NaN         0.0       0.0  ...  0.469035    0.386848   \n",
       "7       0.000000    0.500000         0.0       0.0  ... -0.124529    0.000000   \n",
       "8      -0.179250    0.000000         0.0       0.0  ...  0.185770         NaN   \n",
       "9       0.162151    0.207519         0.0       0.0  ...  0.185770   -0.660735   \n",
       "10     -0.276493    0.368483         0.0       0.0  ...  0.158956   -0.401659   \n",
       "11     -0.179250    0.207519         0.0       0.0  ...  0.155013         NaN   \n",
       "12     -0.087265   -0.792481         0.0       0.0  ...  0.158956         NaN   \n",
       "13      0.310183    0.368483         0.0       0.0  ...  0.427919   -0.350603   \n",
       "14      0.851968    1.160964         0.0       0.0  ... -0.252156         NaN   \n",
       "15     -0.276493   -0.792481         0.0       0.0  ...  0.158956   -1.478712   \n",
       "16     -0.276493         NaN         0.0       0.0  ... -0.085892    0.049143   \n",
       "17     -0.276493   -0.292481         0.0       0.0  ...  0.064685         NaN   \n",
       "18     -0.379634         NaN         0.0       0.0  ... -0.055701         NaN   \n",
       "19     -0.179250    0.000000         0.0       0.0  ... -0.195868         NaN   \n",
       "20     -0.087265    0.207519         0.0       0.0  ...  0.055229   -0.299794   \n",
       "21      0.379634   -0.292481         0.0       0.0  ...  0.323344         NaN   \n",
       "22     -0.276493   -0.292481         0.0       0.0  ...  0.370310         NaN   \n",
       "23     -0.379634    0.500000         0.0       0.0  ...  0.281303   -0.299794   \n",
       "24      1.840472    0.500000         0.0       0.0  ...  0.025814         NaN   \n",
       "25      0.083007   -0.292481         0.0       0.0  ...  0.296700         NaN   \n",
       "26     -0.379634   -0.292481         0.0       0.0  ...  0.126568         NaN   \n",
       "27      2.441506    0.868483         0.0       0.0  ...  0.182021   -0.504523   \n",
       "28      0.237777    0.368483         0.0       0.0  ...  0.109606         NaN   \n",
       "29      0.083007    0.207519         0.0       0.0  ...  0.383373         NaN   \n",
       "...          ...         ...         ...       ...  ...       ...         ...   \n",
       "5286    0.446360    0.000000         0.0       0.0  ...  0.122378         NaN   \n",
       "5287    0.510567    0.368483         0.0       0.0  ...  0.126568   -0.249229   \n",
       "5288    2.106843    0.792481         0.0       0.0  ...  0.314609    0.291465   \n",
       "5289    0.237777         NaN         0.0       0.0  ...  0.130725         NaN   \n",
       "5290   -0.489433    0.000000         0.0       0.0  ...  0.258973   -0.401659   \n",
       "5291    0.689817    0.368483         0.0       0.0  ...  0.221881   -0.660735   \n",
       "5292    2.539874    0.500000         0.0       0.0  ...  0.087618   -0.980315   \n",
       "5293    0.083007    0.207519         0.0       0.0  ...  0.271847   -0.299794   \n",
       "5294    1.952073    1.251250         1.0       1.0  ... -0.315081   -2.061754   \n",
       "5295    0.952073    0.368483         0.0       0.0  ...  0.130725         NaN   \n",
       "5296    0.000000    0.207519         0.0       0.0  ... -0.151932         NaN   \n",
       "5297   -0.087265    0.000000         0.0       0.0  ...  0.105280         NaN   \n",
       "5298    0.000000   -0.292481         0.0       0.0  ...  0.025814         NaN   \n",
       "5299    0.083007    1.111196         0.0       0.0  ...  0.193190   -0.401659   \n",
       "5300    0.083007    1.111196         0.0       0.0  ...  0.314609   -0.249229   \n",
       "5301   -0.179250    0.000000         0.0       0.0  ...  0.182021   -0.198908   \n",
       "5302   -0.087265    0.207519         0.0       0.0  ...  0.166755   -0.556336   \n",
       "5303    0.310183    0.611196         0.0       1.0  ...  0.239061         NaN   \n",
       "5304   -0.087265    0.207519         0.0       0.0  ...  0.214851   -0.452965   \n",
       "5305    0.083007    0.937235         0.0       0.0  ...  0.398638         NaN   \n",
       "5306    0.000000    0.368483         0.0       0.0  ...  0.025814         NaN   \n",
       "5307    0.162151    0.368483         0.0       0.0  ...  0.242431   -1.766184   \n",
       "5308    0.237777   -0.292481         0.0       0.0  ...  0.134851         NaN   \n",
       "5309   -0.087265    0.937235         0.0       0.0  ...  0.162870   -0.148826   \n",
       "5310    2.056801    0.500000         0.0       0.0  ...  0.196862         NaN   \n",
       "5311    0.310183    0.000000         0.0       0.0  ... -0.159008         NaN   \n",
       "5312    0.689817    0.368483         0.0       0.0  ...  0.030830         NaN   \n",
       "5313    2.884747         NaN         0.0       0.0  ...  0.211302         NaN   \n",
       "5314   -0.276493    0.207519         0.0       0.0  ...  0.262221         NaN   \n",
       "5315    2.337099    0.611196         0.0       0.0  ...  0.030830         NaN   \n",
       "\n",
       "      minSodium    minWBC          ethnicity  gender  bands  pao2fio2ratio  \\\n",
       "0     -0.003684  0.155013              black       1    NaN            NaN   \n",
       "1     -0.022510 -0.180817  white/nonhispanic       1    NaN            NaN   \n",
       "2     -0.011132 -0.344496  white/nonhispanic       1    NaN            NaN   \n",
       "3     -0.007394  0.113897      unknown/other       1    NaN            NaN   \n",
       "4     -0.038084 -0.092141      unknown/other       1    NaN            NaN   \n",
       "5     -0.014897  0.050438  white/nonhispanic       0    NaN            NaN   \n",
       "6     -0.022510  0.437333  white/nonhispanic       1    NaN            NaN   \n",
       "7      0.007289 -0.260704      unknown/other       1    NaN            NaN   \n",
       "8      0.010896  0.030830  white/nonhispanic       0    NaN            NaN   \n",
       "9     -0.007394 -0.180817      unknown/other       1    NaN            NaN   \n",
       "10    -0.022510  0.025814  white/nonhispanic       0    NaN            NaN   \n",
       "11    -0.022510 -0.354673  white/nonhispanic       0    NaN            NaN   \n",
       "12     0.003658  0.158956  white/nonhispanic       1    NaN            NaN   \n",
       "13    -0.018689  0.284418  white/nonhispanic       1    NaN            NaN   \n",
       "14    -0.030238 -0.536490              black       0    NaN            NaN   \n",
       "15    -0.022510  0.050438  white/nonhispanic       0    NaN            NaN   \n",
       "16    -0.014897 -0.131249  white/nonhispanic       1    NaN            NaN   \n",
       "17    -0.026360  0.020750  white/nonhispanic       1    NaN            NaN   \n",
       "18    -0.003684 -0.151932              black       1    NaN            NaN   \n",
       "19     0.010896 -0.278222      unknown/other       1    NaN            NaN   \n",
       "20     0.007289 -0.166180      unknown/other       0    NaN            NaN   \n",
       "21    -0.014897  0.035800              black       1    NaN            NaN   \n",
       "22    -0.018689 -0.159008  white/nonhispanic       0    NaN            NaN   \n",
       "23    -0.014897  0.262221  white/nonhispanic       0    NaN            NaN   \n",
       "24    -0.014897 -0.203555  white/nonhispanic       0    NaN            NaN   \n",
       "25    -0.011132  0.170613              black       1    NaN            NaN   \n",
       "26     0.000000 -0.067573  white/nonhispanic       0    NaN            NaN   \n",
       "27     0.003658  0.182021  white/nonhispanic       0    NaN            NaN   \n",
       "28    -0.018689 -0.166180  white/nonhispanic       0    NaN            NaN   \n",
       "29    -0.022510  0.337591      unknown/other       1    NaN            NaN   \n",
       "...         ...       ...                ...     ...    ...            ...   \n",
       "5286  -0.014897  0.030830  white/nonhispanic       0    NaN            NaN   \n",
       "5287  -0.026360 -0.055701  white/nonhispanic       1    NaN            NaN   \n",
       "5288   0.007289  0.015638           hispanic       0    NaN            NaN   \n",
       "5289  -0.007394 -0.085892  white/nonhispanic       0    NaN            NaN   \n",
       "5290  -0.038084 -0.061604  white/nonhispanic       0    NaN            NaN   \n",
       "5291   0.010896 -0.005316  white/nonhispanic       1    NaN            NaN   \n",
       "5292  -0.018689 -0.166180              black       1    NaN            NaN   \n",
       "5293  -0.030238  0.122378      unknown/other       1    NaN            NaN   \n",
       "5294  -0.030238 -1.018842      unknown/other       1    NaN            NaN   \n",
       "5295  -0.003684 -0.044086  white/nonhispanic       1    NaN            NaN   \n",
       "5296  -0.007394 -0.195868  white/nonhispanic       1    NaN            NaN   \n",
       "5297  -0.011132 -0.180817           hispanic       1    NaN            NaN   \n",
       "5298   0.003658 -0.092141  white/nonhispanic       1    NaN            NaN   \n",
       "5299  -0.003684 -0.324707  white/nonhispanic       0    NaN            NaN   \n",
       "5300  -0.030238 -0.892552  white/nonhispanic       0    NaN            NaN   \n",
       "5301  -0.030238  0.096522  white/nonhispanic       1    NaN            NaN   \n",
       "5302  -0.030238 -0.073610      unknown/other       1    NaN            NaN   \n",
       "5303  -0.022510  0.015638  white/nonhispanic       1    NaN            NaN   \n",
       "5304   0.025073  0.138945           hispanic       0    NaN            NaN   \n",
       "5305  -0.026360  0.118154  white/nonhispanic       1    NaN            NaN   \n",
       "5306  -0.018689 -0.104861      unknown/other       0    NaN            NaN   \n",
       "5307   0.010896  0.064685  white/nonhispanic       1    NaN            NaN   \n",
       "5308   0.003658 -0.124529              black       1    NaN            NaN   \n",
       "5309  -0.011132 -0.481647  white/nonhispanic       1    NaN            NaN   \n",
       "5310  -0.003684 -0.049862  white/nonhispanic       1    NaN            NaN   \n",
       "5311  -0.003684 -0.235459  white/nonhispanic       1    NaN            NaN   \n",
       "5312   0.025073 -0.010685  white/nonhispanic       1    NaN            NaN   \n",
       "5313  -0.003684 -0.067573              black       1    NaN            NaN   \n",
       "5314  -0.003684  0.015638              asian       0    NaN            NaN   \n",
       "5315   0.007289  0.010476  white/nonhispanic       1    NaN            NaN   \n",
       "\n",
       "      pco2  final_bin  \n",
       "0      NaN          1  \n",
       "1      NaN          1  \n",
       "2      NaN          0  \n",
       "3      NaN          0  \n",
       "4      NaN          0  \n",
       "5      NaN          0  \n",
       "6      NaN          0  \n",
       "7      NaN          0  \n",
       "8      NaN          0  \n",
       "9      NaN          0  \n",
       "10     NaN          0  \n",
       "11     NaN          0  \n",
       "12     NaN          0  \n",
       "13     NaN          1  \n",
       "14     NaN          1  \n",
       "15     NaN          0  \n",
       "16     NaN          0  \n",
       "17     NaN          0  \n",
       "18     NaN          0  \n",
       "19     NaN          0  \n",
       "20     NaN          0  \n",
       "21     NaN          0  \n",
       "22     NaN          0  \n",
       "23     NaN          1  \n",
       "24     NaN          1  \n",
       "25     NaN          0  \n",
       "26     NaN          0  \n",
       "27     NaN          1  \n",
       "28     NaN          0  \n",
       "29     NaN          1  \n",
       "...    ...        ...  \n",
       "5286   NaN          0  \n",
       "5287   NaN          0  \n",
       "5288   NaN          0  \n",
       "5289   NaN          0  \n",
       "5290   NaN          0  \n",
       "5291   NaN          0  \n",
       "5292   NaN          0  \n",
       "5293   NaN          0  \n",
       "5294   NaN          1  \n",
       "5295   NaN          1  \n",
       "5296   NaN          0  \n",
       "5297   NaN          0  \n",
       "5298   NaN          0  \n",
       "5299   NaN          1  \n",
       "5300   NaN          1  \n",
       "5301   NaN          0  \n",
       "5302   NaN          0  \n",
       "5303   NaN          1  \n",
       "5304   NaN          0  \n",
       "5305   NaN          0  \n",
       "5306   NaN          0  \n",
       "5307   NaN          0  \n",
       "5308   NaN          0  \n",
       "5309   NaN          1  \n",
       "5310   NaN          0  \n",
       "5311   NaN          0  \n",
       "5312   NaN          0  \n",
       "5313   NaN          0  \n",
       "5314   NaN          0  \n",
       "5315   NaN          0  \n",
       "\n",
       "[5316 rows x 51 columns]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.2 ms\n"
     ]
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4120.000000\n",
       "mean       -0.018625\n",
       "std         0.097062\n",
       "min        -0.413793\n",
       "25%        -0.064909\n",
       "50%         0.002944\n",
       "75%         0.054559\n",
       "max         0.096194\n",
       "Name: first_admit_age, dtype: float64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.61 ms\n"
     ]
    }
   ],
   "source": [
    "x_train['first_admit_age'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experimenting with pipelines start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4120.000000\n",
       "mean       77.485117\n",
       "std        59.956766\n",
       "min        16.020000\n",
       "25%        52.585000\n",
       "50%        65.975000\n",
       "75%        78.360000\n",
       "max       300.000000\n",
       "Name: first_admit_age, dtype: float64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.72 ms\n"
     ]
    }
   ],
   "source": [
    "train_data['first_admit_age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.5 ms\n"
     ]
    }
   ],
   "source": [
    "### in a sklearn pipeline each step just has a .transform applied to it.\n",
    "### except the last step which has .fit applied\n",
    "###here we are just making a factorextractor class that tells what to do when transform is applied to it.\n",
    "###\n",
    "\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class FactorExtractor(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "\n",
    "    def transform(self, df):\n",
    "        return df[self.factor]\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "#demonstrates this is the same thing:\n",
    "(FactorExtractor(\"final_bin\").transform(train_data) == train_data['final_bin']).all()\n",
    "\n",
    "##estimator= anyclass in sklearn with a .fit and a .predict. this is what i will use. ie a rf classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "5       0\n",
       "6       0\n",
       "7       0\n",
       "8       0\n",
       "9       0\n",
       "10      0\n",
       "11      0\n",
       "12      0\n",
       "13      1\n",
       "14      1\n",
       "15      0\n",
       "16      0\n",
       "17      0\n",
       "18      0\n",
       "19      0\n",
       "20      0\n",
       "21      0\n",
       "22      0\n",
       "23      1\n",
       "24      1\n",
       "25      0\n",
       "26      0\n",
       "27      1\n",
       "28      0\n",
       "29      1\n",
       "       ..\n",
       "5286    0\n",
       "5287    0\n",
       "5288    0\n",
       "5289    0\n",
       "5290    0\n",
       "5291    0\n",
       "5292    0\n",
       "5293    0\n",
       "5294    1\n",
       "5295    1\n",
       "5296    0\n",
       "5297    0\n",
       "5298    0\n",
       "5299    1\n",
       "5300    1\n",
       "5301    0\n",
       "5302    0\n",
       "5303    1\n",
       "5304    0\n",
       "5305    0\n",
       "5306    0\n",
       "5307    0\n",
       "5308    0\n",
       "5309    1\n",
       "5310    0\n",
       "5311    0\n",
       "5312    0\n",
       "5313    0\n",
       "5314    0\n",
       "5315    0\n",
       "Name: final_bin, Length: 5316, dtype: int64"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.31 ms\n"
     ]
    }
   ],
   "source": [
    "FactorExtractor(\"final_bin\").transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.66 ms\n"
     ]
    }
   ],
   "source": [
    "class ConvertToDataFrame:\n",
    "\n",
    "    def transform(self, data):\n",
    "        df=pd.DataFrame(data)\n",
    "        self.columns= df.columns\n",
    "        return df\n",
    "        #return [{self.factor: self.normalize(tt)} for tt in data[self.factor]]\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DateImputer(TransformerMixin):\n",
    "\n",
    "#     def transform(self, df):\n",
    "#      # Observations don't always exist. Hence impute by lower/upper bound.\n",
    "#         df = df.fillna({'date_first_observation': df['date_creation'],\n",
    "#                          'date_last_observation': df['date_deletion']})\n",
    "#         return df\n",
    "\n",
    "#     def fit(self, df, labels=None):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.4 ms\n"
     ]
    }
   ],
   "source": [
    "class onehot(TransformerMixin):\n",
    "    def __init__(self, cols_to_transform):\n",
    "        self.cols_to_transform=cols_to_transform\n",
    "        \n",
    "    def transform(self,df ):\n",
    "        data = pd.get_dummies(df, columns = self.cols_to_transform, drop_first=True)\n",
    "        return(data)\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols_to_transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-229-a220bcdf56b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols_to_transform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cols_to_transform' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.9 ms\n"
     ]
    }
   ],
   "source": [
    "pd.get_dummies(x_train, columns = cols_to_transform, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'any_vasoactive',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " \"('max', 'calcium')\",\n",
       " \"('max', 'sodium')\",\n",
       " \"('max', 'wbc')\",\n",
       " \"('min', 'calcium')\",\n",
       " \"('min', 'sodium')\",\n",
       " \"('min', 'wbc')\",\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'first_admit_age',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2',\n",
       " 'weight']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms\n"
     ]
    }
   ],
   "source": [
    "##sklearn example  https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py\n",
    "# We will train our classifier with the following features:\n",
    "# Numeric Features:\n",
    "# - age: float.\n",
    "# - fare: float.\n",
    "# Categorical Features:\n",
    "# - embarked: categories encoded as strings {'C', 'S', 'Q'}.\n",
    "# - sex: categories encoded as strings {'female', 'male'}.\n",
    "# - pclass: ordinal integers {1, 2, 3}.\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.13 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "pipeline=make_pipeline(onehot(categorical_variables),\n",
    "                       SimpleImputer(missing_values=np.nan, strategy='median'),\n",
    "                       \n",
    "                       #FactorExtractor('final_bin'),\n",
    "                       ConvertToDataFrame(),\n",
    "                       RandomForestClassifier(n_estimators=100, random_state=2065))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "#binarizing and poping outcome for training data\n",
    "train_data.loc[train_data['final_bin']==\"C_pos/A_full\",\"final_bin\"]=1\n",
    "train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"final_bin\"]=0\n",
    "train_data['final_bin']=pd.to_numeric(train_data['final_bin'])\n",
    "\n",
    "## establishing training data and labels\n",
    "x_train= train_data.drop(columns=[\"final_bin\",'icustay_id'])\n",
    "z_icustay_id=train_data[\"icustay_id\"].copy()\n",
    "y_train= train_data[\"final_bin\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RangeIndex' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-313-d5a070239d4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    229\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 616\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    617\u001b[0m     \u001b[0;31m# if we have a weight for this transformer, multiply output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-306-3a93eb3a1609>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m#return [{self.factor: self.normalize(tt)} for tt in data[self.factor]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RangeIndex' object is not callable"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 71 ms\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(x_train, y_train)\n",
    "pipeline.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['any_vasoactives',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'first_admit_age',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'weight',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " 'maxCalcium',\n",
       " 'maxSodium',\n",
       " 'maxWBC',\n",
       " 'minCalcium',\n",
       " 'minSodium',\n",
       " 'minWBC',\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2']"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.32 ms\n"
     ]
    }
   ],
   "source": [
    "x_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 5316, index implies 49",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-270-f39562bd6d56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#     return(topn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                             \u001b[0;34m'index implies {ind}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                             .format(val=len(data), ind=len(index)))\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 5316, index implies 49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 125 ms\n"
     ]
    }
   ],
   "source": [
    "# def var_imp(model,folder_name,model_name, n_var=4, save=True):\n",
    "#     model_name=type(model).__name__\n",
    "#     plot_title= \"Top {} {} {} Variable Importance\".format(n_var, folder_name,model_name)\n",
    "#     feat_importances = pd.Series(model.pipeline.predict_proba(x_train), index=x_train.columns)\n",
    "#     topn=feat_importances.nlargest(n_var).sort_values()\n",
    "#     ax=topn.plot(kind='barh', x='doop', title=plot_title)#.xlabel(\"xlab\")\n",
    "#     ax.set_xlabel(\"Variable Importance\")\n",
    "#     if save==True:\n",
    "#         saveplot(figure_name=plot_title, folder_name=folder_name)\n",
    "#     return(topn)\n",
    "\n",
    "pd.Series(pipeline.predict_proba(x_train)[:,:], index=x_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvertToDataFrame' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-305-1ba12f0d0d0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'converttodataframe'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConvertToDataFrame' object has no attribute 'columns'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "pipeline.named_steps['converttodataframe'].columns()#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 50, index implies 49",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-289-22739d883de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;31m#[-1][1].feature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'randomforestclassifier'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#pipeline.named_steps['randomforestclassifier'].feature_importances_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    247\u001b[0m                             \u001b[0;34m'Length of passed values is {val}, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                             \u001b[0;34m'index implies {ind}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                             .format(val=len(data), ind=len(index)))\n\u001b[0m\u001b[1;32m    250\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of passed values is 50, index implies 49"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "#x_train.columns\n",
    "pipeline.steps#[-1][1].feature_importances_\n",
    "\n",
    "pd.Series(pipeline.named_steps['randomforestclassifier'].feature_importances_, index=x_train.columns)\n",
    "#pipeline.named_steps['randomforestclassifier'].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>any_vasoactives</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>epinephrine</th>\n",
       "      <th>...</th>\n",
       "      <th>maxSodium</th>\n",
       "      <th>maxWBC</th>\n",
       "      <th>minCalcium</th>\n",
       "      <th>minSodium</th>\n",
       "      <th>minWBC</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>bands</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.013376</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.207728</td>\n",
       "      <td>0.098057</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>-0.079716</td>\n",
       "      <td>-0.504523</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.154377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.144949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.344496</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.227339</td>\n",
       "      <td>-0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009074</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.265449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.113897</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.332269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.851968</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>-0.038084</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721779</td>\n",
       "      <td>-0.227670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.009248</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.469035</td>\n",
       "      <td>0.386848</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.437333</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.812191</td>\n",
       "      <td>0.143949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.124529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.260704</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038870</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.025228</td>\n",
       "      <td>0.164484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.185770</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.155013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>-0.354673</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.167785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>-0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481072</td>\n",
       "      <td>0.266357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.427919</td>\n",
       "      <td>-0.350603</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>0.284418</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.058671</td>\n",
       "      <td>0.243696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>0.851968</td>\n",
       "      <td>1.160964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.252156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.536490</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.158956</td>\n",
       "      <td>-1.478712</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.050438</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.085892</td>\n",
       "      <td>0.049143</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.131249</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.020750</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.528634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.151932</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>-0.195868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.278222</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>0.055229</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.122043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.379634</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.323344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077740</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028296</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.370310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.159008</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.281303</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>0.251425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.018678</td>\n",
       "      <td>1.840472</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>-0.203555</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.296700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.170613</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.455340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>-0.379634</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.126568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.067573</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.687091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039548</td>\n",
       "      <td>2.441506</td>\n",
       "      <td>0.868483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>-0.504523</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.098572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109606</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.202063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.383373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.337591</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.446360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.122378</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.014897</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.510567</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.126568</td>\n",
       "      <td>-0.249229</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>-0.055701</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5288</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>2.106843</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.314609</td>\n",
       "      <td>0.291465</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.130725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.085892</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5290</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>-0.489433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.258973</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.038084</td>\n",
       "      <td>-0.061604</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5291</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.280640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689817</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042262</td>\n",
       "      <td>0.221881</td>\n",
       "      <td>-0.660735</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.005316</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5292</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>0.479095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004602</td>\n",
       "      <td>2.539874</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>0.087618</td>\n",
       "      <td>-0.980315</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.166180</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271847</td>\n",
       "      <td>-0.299794</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.122378</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.434142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>1.952073</td>\n",
       "      <td>1.251250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.315081</td>\n",
       "      <td>-2.061754</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-1.018842</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5295</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.952073</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032018</td>\n",
       "      <td>0.130725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.044086</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5296</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.028296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>-0.151932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>-0.195868</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5297</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.196365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.180817</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5298</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.273576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>-0.092141</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.133254</td>\n",
       "      <td>0.326242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>1.111196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018033</td>\n",
       "      <td>0.193190</td>\n",
       "      <td>-0.401659</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.324707</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.358787</td>\n",
       "      <td>0.219354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.035311</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>1.111196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314609</td>\n",
       "      <td>-0.249229</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.892552</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.179250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.182021</td>\n",
       "      <td>-0.198908</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.096522</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.371004</td>\n",
       "      <td>-0.141494</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.166755</td>\n",
       "      <td>-0.556336</td>\n",
       "      <td>-0.030238</td>\n",
       "      <td>-0.073610</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007394</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.321825</td>\n",
       "      <td>0.059885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>0.214851</td>\n",
       "      <td>-0.452965</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5305</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.788787</td>\n",
       "      <td>0.031305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.023463</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022510</td>\n",
       "      <td>0.398638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026360</td>\n",
       "      <td>0.118154</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510959</td>\n",
       "      <td>0.294328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.025814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018689</td>\n",
       "      <td>-0.104861</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5307</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382047</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076090</td>\n",
       "      <td>0.162151</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.242431</td>\n",
       "      <td>-1.766184</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.064685</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>-0.094492</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.237777</td>\n",
       "      <td>-0.292481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.134851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>-0.124529</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5309</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450237</td>\n",
       "      <td>0.219354</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.047912</td>\n",
       "      <td>-0.087265</td>\n",
       "      <td>0.937235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.162870</td>\n",
       "      <td>-0.148826</td>\n",
       "      <td>-0.011132</td>\n",
       "      <td>-0.481647</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>0.425264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056133</td>\n",
       "      <td>2.056801</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021565</td>\n",
       "      <td>0.196862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.049862</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241314</td>\n",
       "      <td>0.016026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.310183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>-0.159008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.235459</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.192135</td>\n",
       "      <td>0.508310</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031036</td>\n",
       "      <td>0.689817</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025073</td>\n",
       "      <td>-0.010685</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.254817</td>\n",
       "      <td>0.371619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.048130</td>\n",
       "      <td>2.884747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.211302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>-0.067573</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5314</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013547</td>\n",
       "      <td>-0.276493</td>\n",
       "      <td>0.207519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003658</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003684</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>asian</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5315</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.393801</td>\n",
       "      <td>0.273576</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017980</td>\n",
       "      <td>2.337099</td>\n",
       "      <td>0.611196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014477</td>\n",
       "      <td>0.030830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007289</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5316 rows Ã 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      any_vasoactives  bilirubin       bun  cancer_elix  chloride  creatinine  \\\n",
       "0                 1.0   2.013376  0.122043          0.0  0.031036    0.000000   \n",
       "1                 1.0        NaN -0.053381          1.0  0.017980   -0.276493   \n",
       "2                 0.0        NaN  0.154377          0.0  0.026723    0.000000   \n",
       "3                 0.0   1.227339 -0.073293          0.0  0.009074   -0.087265   \n",
       "4                 0.0  -0.077740  0.332269          0.0  0.017980    0.851968   \n",
       "5                 0.0   0.721779 -0.227670          0.0  0.026723   -0.379634   \n",
       "6                 1.0        NaN  0.031305          0.0 -0.009248    0.162151   \n",
       "7                 0.0   0.812191  0.143949          0.0  0.039548    0.000000   \n",
       "8                 0.0        NaN  0.122043          0.0  0.004558   -0.179250   \n",
       "9                 1.0  -0.025228  0.164484          0.0  0.000000    0.162151   \n",
       "10                1.0        NaN -0.034607          0.0  0.026723   -0.276493   \n",
       "11                0.0        NaN -0.167785          0.0  0.022371   -0.179250   \n",
       "12                0.0        NaN -0.167785          0.0  0.000000   -0.087265   \n",
       "13                0.0   0.481072  0.266357          0.0  0.004558    0.310183   \n",
       "14                1.0   1.058671  0.243696          1.0  0.013547    0.851968   \n",
       "15                0.0        NaN -0.073293          0.0  0.039548   -0.276493   \n",
       "16                0.0        NaN  0.122043          0.0  0.043748   -0.276493   \n",
       "17                0.0  -0.254817 -0.141494          0.0  0.000000   -0.276493   \n",
       "18                0.0        NaN -0.528634          1.0  0.022371   -0.379634   \n",
       "19                0.0        NaN -0.141494          0.0  0.039548   -0.179250   \n",
       "20                0.0        NaN  0.059885          0.0  0.043748   -0.087265   \n",
       "21                0.0        NaN  0.122043          0.0  0.017980    0.379634   \n",
       "22                0.0  -0.077740  0.016026          0.0 -0.028296   -0.276493   \n",
       "23                1.0        NaN -0.141494          0.0  0.004558   -0.379634   \n",
       "24                0.0  -0.192135  0.251425          0.0 -0.018678    1.840472   \n",
       "25                0.0  -0.192135 -0.053381          0.0  0.004558    0.083007   \n",
       "26                0.0        NaN -0.455340          0.0  0.031036   -0.379634   \n",
       "27                0.0  -0.321825  0.687091          0.0  0.039548    2.441506   \n",
       "28                0.0  -0.321825  0.098572          0.0 -0.004602    0.237777   \n",
       "29                1.0        NaN  0.202063          0.0  0.000000    0.083007   \n",
       "...               ...        ...       ...          ...       ...         ...   \n",
       "5286              0.0        NaN  0.073293          0.0  0.004558    0.446360   \n",
       "5287              1.0        NaN  0.193064          0.0  0.026723    0.510567   \n",
       "5288              1.0        NaN  0.143949          0.0 -0.004602    2.106843   \n",
       "5289              1.0        NaN  0.016026          0.0  0.047912    0.237777   \n",
       "5290              1.0        NaN -0.196365          0.0  0.017980   -0.489433   \n",
       "5291              0.0        NaN  0.280640          0.0  0.000000    0.689817   \n",
       "5292              0.0  -0.393801  0.479095          0.0 -0.004602    2.539874   \n",
       "5293              1.0        NaN  0.059885          0.0  0.026723    0.083007   \n",
       "5294              1.0  -0.321825  0.434142          0.0  0.026723    1.952073   \n",
       "5295              0.0        NaN  0.553912          0.0  0.031036    0.952073   \n",
       "5296              0.0        NaN  0.031305          0.0 -0.028296    0.000000   \n",
       "5297              0.0        NaN -0.196365          0.0  0.031036   -0.087265   \n",
       "5298              0.0        NaN  0.273576          0.0  0.017980    0.000000   \n",
       "5299              1.0  -0.133254  0.326242          0.0  0.064215    0.083007   \n",
       "5300              1.0   1.358787  0.219354          1.0  0.035311    0.083007   \n",
       "5301              1.0        NaN -0.053381          0.0  0.013547   -0.179250   \n",
       "5302              0.0   1.371004 -0.141494          0.0  0.004558   -0.087265   \n",
       "5303              1.0        NaN  0.332269          0.0  0.017980    0.310183   \n",
       "5304              0.0  -0.321825  0.059885          0.0  0.013547   -0.087265   \n",
       "5305              1.0   1.788787  0.031305          0.0 -0.023463    0.083007   \n",
       "5306              0.0   0.510959  0.294328          0.0  0.043748    0.000000   \n",
       "5307              0.0        NaN  0.382047          0.0  0.076090    0.162151   \n",
       "5308              0.0  -0.393801 -0.094492          0.0  0.000000    0.237777   \n",
       "5309              1.0   0.450237  0.219354          1.0  0.047912   -0.087265   \n",
       "5310              0.0  -0.254817  0.425264          0.0  0.056133    2.056801   \n",
       "5311              0.0   0.241314  0.016026          0.0  0.031036    0.310183   \n",
       "5312              0.0  -0.192135  0.508310          0.0  0.031036    0.689817   \n",
       "5313              0.0  -0.254817  0.371619          0.0 -0.048130    2.884747   \n",
       "5314              0.0        NaN -0.053381          0.0  0.013547   -0.276493   \n",
       "5315              0.0  -0.393801  0.273576          1.0  0.017980    2.337099   \n",
       "\n",
       "      daily_sofa  dobutamine  dopamine  epinephrine  ...  maxSodium    maxWBC  \\\n",
       "0       0.500000         1.0       0.0          0.0  ...   0.007289  0.207728   \n",
       "1      -0.292481         0.0       0.0          0.0  ...   0.021565 -0.079716   \n",
       "2      -0.292481         0.0       0.0          0.0  ...   0.007289 -0.144949   \n",
       "3       0.207519         0.0       0.0          0.0  ...   0.010896  0.265449   \n",
       "4       0.611196         0.0       0.0          0.0  ...   0.014477 -0.055701   \n",
       "5       0.368483         0.0       0.0          0.0  ...   0.000000  0.317537   \n",
       "6            NaN         0.0       0.0          0.0  ...  -0.014897  0.469035   \n",
       "7       0.500000         0.0       0.0          0.0  ...   0.010896 -0.124529   \n",
       "8       0.000000         0.0       0.0          0.0  ...   0.038870  0.185770   \n",
       "9       0.207519         0.0       0.0          0.0  ...   0.007289  0.185770   \n",
       "10      0.368483         0.0       0.0          0.0  ...  -0.003684  0.158956   \n",
       "11      0.207519         0.0       0.0          0.0  ...  -0.007394  0.155013   \n",
       "12     -0.792481         0.0       0.0          0.0  ...   0.003658  0.158956   \n",
       "13      0.368483         0.0       0.0          0.0  ...   0.007289  0.427919   \n",
       "14      1.160964         0.0       0.0          0.0  ...  -0.014897 -0.252156   \n",
       "15     -0.792481         0.0       0.0          0.0  ...   0.010896  0.158956   \n",
       "16           NaN         0.0       0.0          0.0  ...   0.007289 -0.085892   \n",
       "17     -0.292481         0.0       0.0          0.0  ...  -0.003684  0.064685   \n",
       "18           NaN         0.0       0.0          0.0  ...   0.007289 -0.055701   \n",
       "19      0.000000         0.0       0.0          0.0  ...   0.014477 -0.195868   \n",
       "20      0.207519         0.0       0.0          0.0  ...   0.028557  0.055229   \n",
       "21     -0.292481         0.0       0.0          0.0  ...   0.010896  0.323344   \n",
       "22     -0.292481         0.0       0.0          0.0  ...  -0.011132  0.370310   \n",
       "23      0.500000         0.0       0.0          0.0  ...  -0.007394  0.281303   \n",
       "24      0.500000         0.0       0.0          0.0  ...   0.000000  0.025814   \n",
       "25     -0.292481         0.0       0.0          0.0  ...   0.000000  0.296700   \n",
       "26     -0.292481         0.0       0.0          0.0  ...   0.007289  0.126568   \n",
       "27      0.868483         0.0       0.0          0.0  ...   0.010896  0.182021   \n",
       "28      0.368483         0.0       0.0          0.0  ...   0.000000  0.109606   \n",
       "29      0.207519         0.0       0.0          0.0  ...  -0.007394  0.383373   \n",
       "...          ...         ...       ...          ...  ...        ...       ...   \n",
       "5286    0.000000         0.0       0.0          0.0  ...  -0.007394  0.122378   \n",
       "5287    0.368483         0.0       0.0          0.0  ...  -0.003684  0.126568   \n",
       "5288    0.792481         0.0       0.0          0.0  ...   0.014477  0.314609   \n",
       "5289         NaN         0.0       0.0          0.0  ...   0.010896  0.130725   \n",
       "5290    0.000000         0.0       0.0          0.0  ...  -0.003684  0.258973   \n",
       "5291    0.368483         0.0       0.0          0.0  ...   0.042262  0.221881   \n",
       "5292    0.500000         0.0       0.0          0.0  ...  -0.011132  0.087618   \n",
       "5293    0.207519         0.0       0.0          0.0  ...   0.000000  0.271847   \n",
       "5294    1.251250         1.0       1.0          0.0  ...   0.010896 -0.315081   \n",
       "5295    0.368483         0.0       0.0          0.0  ...   0.032018  0.130725   \n",
       "5296    0.207519         0.0       0.0          0.0  ...   0.003658 -0.151932   \n",
       "5297    0.000000         0.0       0.0          0.0  ...   0.010896  0.105280   \n",
       "5298   -0.292481         0.0       0.0          0.0  ...   0.010896  0.025814   \n",
       "5299    1.111196         0.0       0.0          0.0  ...   0.018033  0.193190   \n",
       "5300    1.111196         0.0       0.0          1.0  ...   0.000000  0.314609   \n",
       "5301    0.000000         0.0       0.0          0.0  ...  -0.003684  0.182021   \n",
       "5302    0.207519         0.0       0.0          0.0  ...  -0.007394  0.166755   \n",
       "5303    0.611196         0.0       1.0          0.0  ...  -0.007394  0.239061   \n",
       "5304    0.207519         0.0       0.0          0.0  ...   0.028557  0.214851   \n",
       "5305    0.937235         0.0       0.0          0.0  ...  -0.022510  0.398638   \n",
       "5306    0.368483         0.0       0.0          0.0  ...   0.003658  0.025814   \n",
       "5307    0.368483         0.0       0.0          0.0  ...   0.025073  0.242431   \n",
       "5308   -0.292481         0.0       0.0          0.0  ...   0.014477  0.134851   \n",
       "5309    0.937235         0.0       0.0          0.0  ...   0.007289  0.162870   \n",
       "5310    0.500000         0.0       0.0          0.0  ...   0.021565  0.196862   \n",
       "5311    0.000000         0.0       0.0          0.0  ...   0.010896 -0.159008   \n",
       "5312    0.368483         0.0       0.0          0.0  ...   0.025073  0.030830   \n",
       "5313         NaN         0.0       0.0          0.0  ...   0.003658  0.211302   \n",
       "5314    0.207519         0.0       0.0          0.0  ...   0.003658  0.262221   \n",
       "5315    0.611196         0.0       0.0          0.0  ...   0.014477  0.030830   \n",
       "\n",
       "      minCalcium  minSodium    minWBC          ethnicity  gender  bands  \\\n",
       "0       0.098057  -0.003684  0.155013              black       1    NaN   \n",
       "1      -0.504523  -0.022510 -0.180817  white/nonhispanic       1    NaN   \n",
       "2            NaN  -0.011132 -0.344496  white/nonhispanic       1    NaN   \n",
       "3            NaN  -0.007394  0.113897      unknown/other       1    NaN   \n",
       "4      -0.660735  -0.038084 -0.092141      unknown/other       1    NaN   \n",
       "5            NaN  -0.014897  0.050438  white/nonhispanic       0    NaN   \n",
       "6       0.386848  -0.022510  0.437333  white/nonhispanic       1    NaN   \n",
       "7       0.000000   0.007289 -0.260704      unknown/other       1    NaN   \n",
       "8            NaN   0.010896  0.030830  white/nonhispanic       0    NaN   \n",
       "9      -0.660735  -0.007394 -0.180817      unknown/other       1    NaN   \n",
       "10     -0.401659  -0.022510  0.025814  white/nonhispanic       0    NaN   \n",
       "11           NaN  -0.022510 -0.354673  white/nonhispanic       0    NaN   \n",
       "12           NaN   0.003658  0.158956  white/nonhispanic       1    NaN   \n",
       "13     -0.350603  -0.018689  0.284418  white/nonhispanic       1    NaN   \n",
       "14           NaN  -0.030238 -0.536490              black       0    NaN   \n",
       "15     -1.478712  -0.022510  0.050438  white/nonhispanic       0    NaN   \n",
       "16      0.049143  -0.014897 -0.131249  white/nonhispanic       1    NaN   \n",
       "17           NaN  -0.026360  0.020750  white/nonhispanic       1    NaN   \n",
       "18           NaN  -0.003684 -0.151932              black       1    NaN   \n",
       "19           NaN   0.010896 -0.278222      unknown/other       1    NaN   \n",
       "20     -0.299794   0.007289 -0.166180      unknown/other       0    NaN   \n",
       "21           NaN  -0.014897  0.035800              black       1    NaN   \n",
       "22           NaN  -0.018689 -0.159008  white/nonhispanic       0    NaN   \n",
       "23     -0.299794  -0.014897  0.262221  white/nonhispanic       0    NaN   \n",
       "24           NaN  -0.014897 -0.203555  white/nonhispanic       0    NaN   \n",
       "25           NaN  -0.011132  0.170613              black       1    NaN   \n",
       "26           NaN   0.000000 -0.067573  white/nonhispanic       0    NaN   \n",
       "27     -0.504523   0.003658  0.182021  white/nonhispanic       0    NaN   \n",
       "28           NaN  -0.018689 -0.166180  white/nonhispanic       0    NaN   \n",
       "29           NaN  -0.022510  0.337591      unknown/other       1    NaN   \n",
       "...          ...        ...       ...                ...     ...    ...   \n",
       "5286         NaN  -0.014897  0.030830  white/nonhispanic       0    NaN   \n",
       "5287   -0.249229  -0.026360 -0.055701  white/nonhispanic       1    NaN   \n",
       "5288    0.291465   0.007289  0.015638           hispanic       0    NaN   \n",
       "5289         NaN  -0.007394 -0.085892  white/nonhispanic       0    NaN   \n",
       "5290   -0.401659  -0.038084 -0.061604  white/nonhispanic       0    NaN   \n",
       "5291   -0.660735   0.010896 -0.005316  white/nonhispanic       1    NaN   \n",
       "5292   -0.980315  -0.018689 -0.166180              black       1    NaN   \n",
       "5293   -0.299794  -0.030238  0.122378      unknown/other       1    NaN   \n",
       "5294   -2.061754  -0.030238 -1.018842      unknown/other       1    NaN   \n",
       "5295         NaN  -0.003684 -0.044086  white/nonhispanic       1    NaN   \n",
       "5296         NaN  -0.007394 -0.195868  white/nonhispanic       1    NaN   \n",
       "5297         NaN  -0.011132 -0.180817           hispanic       1    NaN   \n",
       "5298         NaN   0.003658 -0.092141  white/nonhispanic       1    NaN   \n",
       "5299   -0.401659  -0.003684 -0.324707  white/nonhispanic       0    NaN   \n",
       "5300   -0.249229  -0.030238 -0.892552  white/nonhispanic       0    NaN   \n",
       "5301   -0.198908  -0.030238  0.096522  white/nonhispanic       1    NaN   \n",
       "5302   -0.556336  -0.030238 -0.073610      unknown/other       1    NaN   \n",
       "5303         NaN  -0.022510  0.015638  white/nonhispanic       1    NaN   \n",
       "5304   -0.452965   0.025073  0.138945           hispanic       0    NaN   \n",
       "5305         NaN  -0.026360  0.118154  white/nonhispanic       1    NaN   \n",
       "5306         NaN  -0.018689 -0.104861      unknown/other       0    NaN   \n",
       "5307   -1.766184   0.010896  0.064685  white/nonhispanic       1    NaN   \n",
       "5308         NaN   0.003658 -0.124529              black       1    NaN   \n",
       "5309   -0.148826  -0.011132 -0.481647  white/nonhispanic       1    NaN   \n",
       "5310         NaN  -0.003684 -0.049862  white/nonhispanic       1    NaN   \n",
       "5311         NaN  -0.003684 -0.235459  white/nonhispanic       1    NaN   \n",
       "5312         NaN   0.025073 -0.010685  white/nonhispanic       1    NaN   \n",
       "5313         NaN  -0.003684 -0.067573              black       1    NaN   \n",
       "5314         NaN  -0.003684  0.015638              asian       0    NaN   \n",
       "5315         NaN   0.007289  0.010476  white/nonhispanic       1    NaN   \n",
       "\n",
       "      pao2fio2ratio  pco2  \n",
       "0               NaN   NaN  \n",
       "1               NaN   NaN  \n",
       "2               NaN   NaN  \n",
       "3               NaN   NaN  \n",
       "4               NaN   NaN  \n",
       "5               NaN   NaN  \n",
       "6               NaN   NaN  \n",
       "7               NaN   NaN  \n",
       "8               NaN   NaN  \n",
       "9               NaN   NaN  \n",
       "10              NaN   NaN  \n",
       "11              NaN   NaN  \n",
       "12              NaN   NaN  \n",
       "13              NaN   NaN  \n",
       "14              NaN   NaN  \n",
       "15              NaN   NaN  \n",
       "16              NaN   NaN  \n",
       "17              NaN   NaN  \n",
       "18              NaN   NaN  \n",
       "19              NaN   NaN  \n",
       "20              NaN   NaN  \n",
       "21              NaN   NaN  \n",
       "22              NaN   NaN  \n",
       "23              NaN   NaN  \n",
       "24              NaN   NaN  \n",
       "25              NaN   NaN  \n",
       "26              NaN   NaN  \n",
       "27              NaN   NaN  \n",
       "28              NaN   NaN  \n",
       "29              NaN   NaN  \n",
       "...             ...   ...  \n",
       "5286            NaN   NaN  \n",
       "5287            NaN   NaN  \n",
       "5288            NaN   NaN  \n",
       "5289            NaN   NaN  \n",
       "5290            NaN   NaN  \n",
       "5291            NaN   NaN  \n",
       "5292            NaN   NaN  \n",
       "5293            NaN   NaN  \n",
       "5294            NaN   NaN  \n",
       "5295            NaN   NaN  \n",
       "5296            NaN   NaN  \n",
       "5297            NaN   NaN  \n",
       "5298            NaN   NaN  \n",
       "5299            NaN   NaN  \n",
       "5300            NaN   NaN  \n",
       "5301            NaN   NaN  \n",
       "5302            NaN   NaN  \n",
       "5303            NaN   NaN  \n",
       "5304            NaN   NaN  \n",
       "5305            NaN   NaN  \n",
       "5306            NaN   NaN  \n",
       "5307            NaN   NaN  \n",
       "5308            NaN   NaN  \n",
       "5309            NaN   NaN  \n",
       "5310            NaN   NaN  \n",
       "5311            NaN   NaN  \n",
       "5312            NaN   NaN  \n",
       "5313            NaN   NaN  \n",
       "5314            NaN   NaN  \n",
       "5315            NaN   NaN  \n",
       "\n",
       "[5316 rows x 49 columns]"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 57.8 ms\n"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>glucose</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>inr</th>\n",
       "      <th>lactate</th>\n",
       "      <th>potassium</th>\n",
       "      <th>...</th>\n",
       "      <th>any_vasoactives_1.0</th>\n",
       "      <th>bands_&gt;10</th>\n",
       "      <th>bands_absent</th>\n",
       "      <th>pco2_&gt;50</th>\n",
       "      <th>pco2_absent</th>\n",
       "      <th>ethnicity_black</th>\n",
       "      <th>ethnicity_hispanic</th>\n",
       "      <th>ethnicity_unknown/other</th>\n",
       "      <th>ethnicity_white/nonhispanic</th>\n",
       "      <th>gender_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.159306</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.251584</td>\n",
       "      <td>-0.251173</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.082229</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.228115</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>-0.041188</td>\n",
       "      <td>-0.138959</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>-0.015701</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.251173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.466494</td>\n",
       "      <td>-0.101564</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.201190</td>\n",
       "      <td>0.064284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.103141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.148081</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.347709</td>\n",
       "      <td>0.030360</td>\n",
       "      <td>0.081233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.083992</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.898405</td>\n",
       "      <td>-0.251462</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>-0.321928</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>-0.072461</td>\n",
       "      <td>0.064284</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.065443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>-0.028174</td>\n",
       "      <td>0.115063</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.950384</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>0.107542</td>\n",
       "      <td>0.030582</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.068061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.292401</td>\n",
       "      <td>0.143325</td>\n",
       "      <td>1.412966</td>\n",
       "      <td>-0.571050</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166160</td>\n",
       "      <td>0.099906</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.128461</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.119956</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.581480</td>\n",
       "      <td>0.562882</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.193314</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043443</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.193314</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>-0.861353</td>\n",
       "      <td>-0.013683</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.228232</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>0.263034</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.102587</td>\n",
       "      <td>0.094684</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.150771</td>\n",
       "      <td>0.359500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.257984</td>\n",
       "      <td>0.157065</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.722466</td>\n",
       "      <td>0.821253</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.010532</td>\n",
       "      <td>1.927931</td>\n",
       "      <td>0.796161</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.193314</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.861353</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.055449</td>\n",
       "      <td>-0.415374</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.057372</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.198978</td>\n",
       "      <td>-0.167786</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.070037</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.065443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.635444</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>-0.321928</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>-0.009695</td>\n",
       "      <td>0.049416</td>\n",
       "      <td>-0.415374</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.371314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.167786</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.174991</td>\n",
       "      <td>0.128461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.144151</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.173344</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>-0.128543</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>0.321928</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.209421</td>\n",
       "      <td>0.183399</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.138959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>-0.035367</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>-0.017736</td>\n",
       "      <td>0.078472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.068061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.322629</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.321928</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.115978</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>0.688918</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.198543</td>\n",
       "      <td>-0.026264</td>\n",
       "      <td>1.378512</td>\n",
       "      <td>0.251930</td>\n",
       "      <td>0.149170</td>\n",
       "      <td>-0.037933</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.159116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.128543</td>\n",
       "      <td>-0.122147</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.035348</td>\n",
       "      <td>0.017360</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.472527</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>-0.321928</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.189183</td>\n",
       "      <td>0.097306</td>\n",
       "      <td>-0.415374</td>\n",
       "      <td>0.185420</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.274274</td>\n",
       "      <td>0.636759</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>2.070389</td>\n",
       "      <td>0.569323</td>\n",
       "      <td>0.020068</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>1.994721</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.332278</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.274274</td>\n",
       "      <td>0.065315</td>\n",
       "      <td>-0.012943</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.136497</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>0.128461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.165803</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.021858</td>\n",
       "      <td>0.279622</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4090</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.347709</td>\n",
       "      <td>0.204516</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>0.476541</td>\n",
       "      <td>0.185420</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4091</th>\n",
       "      <td>-0.442507</td>\n",
       "      <td>0.297978</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>1.536053</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.272579</td>\n",
       "      <td>0.092040</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4092</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.365216</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.032034</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>-0.415374</td>\n",
       "      <td>-0.504887</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4093</th>\n",
       "      <td>-0.198978</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.070553</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.834458</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>-0.442507</td>\n",
       "      <td>-0.167786</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.142882</td>\n",
       "      <td>0.092040</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>0.756471</td>\n",
       "      <td>0.464228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4095</th>\n",
       "      <td>0.059007</td>\n",
       "      <td>-0.144151</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>-0.223504</td>\n",
       "      <td>-0.103141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4096</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.030397</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.051279</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.077987</td>\n",
       "      <td>0.538749</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.109375</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.765535</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.102587</td>\n",
       "      <td>-0.014622</td>\n",
       "      <td>0.887125</td>\n",
       "      <td>1.372970</td>\n",
       "      <td>0.722853</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4098</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.449297</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>0.887525</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.232574</td>\n",
       "      <td>0.099906</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.189228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4099</th>\n",
       "      <td>1.349749</td>\n",
       "      <td>-0.167786</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.070389</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.135335</td>\n",
       "      <td>0.061366</td>\n",
       "      <td>0.126488</td>\n",
       "      <td>0.251584</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4100</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.128676</td>\n",
       "      <td>0.086684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>-0.198978</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-0.415037</td>\n",
       "      <td>-0.861353</td>\n",
       "      <td>-0.064915</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.981483</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.068061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4102</th>\n",
       "      <td>0.401319</td>\n",
       "      <td>-0.082229</td>\n",
       "      <td>-0.012943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.159306</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>2.947168</td>\n",
       "      <td>-0.274274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4103</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.340565</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>1.104337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162267</td>\n",
       "      <td>0.007061</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.332278</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4104</th>\n",
       "      <td>0.059007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>0.052447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219003</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4105</th>\n",
       "      <td>0.843826</td>\n",
       "      <td>0.286380</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.203688</td>\n",
       "      <td>0.024042</td>\n",
       "      <td>2.748960</td>\n",
       "      <td>1.502789</td>\n",
       "      <td>0.189228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4106</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.213733</td>\n",
       "      <td>-0.049372</td>\n",
       "      <td>1.608809</td>\n",
       "      <td>0.569323</td>\n",
       "      <td>0.120672</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.438644</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>0.442507</td>\n",
       "      <td>-0.030397</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.105077</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>2.536583</td>\n",
       "      <td>0.039690</td>\n",
       "      <td>-0.251173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4108</th>\n",
       "      <td>1.136598</td>\n",
       "      <td>0.297978</td>\n",
       "      <td>-0.008587</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>0.347709</td>\n",
       "      <td>0.308589</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>1.331535</td>\n",
       "      <td>0.853114</td>\n",
       "      <td>0.218816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4109</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.008428</td>\n",
       "      <td>-0.862496</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>-0.034657</td>\n",
       "      <td>0.083970</td>\n",
       "      <td>-0.270369</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.304614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.285064</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.018310</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>-0.415374</td>\n",
       "      <td>0.401319</td>\n",
       "      <td>0.097243</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4111</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.391149</td>\n",
       "      <td>0.044536</td>\n",
       "      <td>0.963474</td>\n",
       "      <td>0.569323</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.507877</td>\n",
       "      <td>0.438644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4112</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>-0.021780</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.089373</td>\n",
       "      <td>0.584626</td>\n",
       "      <td>0.372970</td>\n",
       "      <td>-0.175547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4113</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>0.432959</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>-0.050279</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.033690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4114</th>\n",
       "      <td>0.358515</td>\n",
       "      <td>-0.285064</td>\n",
       "      <td>-0.017340</td>\n",
       "      <td>-0.321928</td>\n",
       "      <td>0.430677</td>\n",
       "      <td>0.087093</td>\n",
       "      <td>0.160832</td>\n",
       "      <td>0.247811</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>-0.138959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067684</td>\n",
       "      <td>0.064284</td>\n",
       "      <td>0.887125</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.276493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4116</th>\n",
       "      <td>-0.355152</td>\n",
       "      <td>0.297978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.887525</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233310</td>\n",
       "      <td>0.072874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.128543</td>\n",
       "      <td>0.128461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.076914</td>\n",
       "      <td>-0.030793</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>-0.036856</td>\n",
       "      <td>0.081233</td>\n",
       "      <td>1.247811</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.033036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4118</th>\n",
       "      <td>-0.274274</td>\n",
       "      <td>0.325254</td>\n",
       "      <td>0.032816</td>\n",
       "      <td>0.137504</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0.061845</td>\n",
       "      <td>0.122373</td>\n",
       "      <td>-0.132111</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.276493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>-0.062380</td>\n",
       "      <td>0.165803</td>\n",
       "      <td>0.024831</td>\n",
       "      <td>0.536053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.508545</td>\n",
       "      <td>0.027329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.114986</td>\n",
       "      <td>0.656127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4120 rows Ã 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      bilirubin       bun  chloride  creatinine  daily_sofa   glucose  \\\n",
       "0     -0.062380  0.088105  0.020785    0.000000    0.138647  0.159306   \n",
       "1     -0.062380 -0.082229  0.004234   -0.234465   -0.430677  0.228115   \n",
       "2     -0.062380  0.119501  0.016704    0.000000   -0.430677 -0.015701   \n",
       "3      1.466494 -0.101564  0.000000   -0.074001    0.000000  0.201190   \n",
       "4     -0.062380  0.148081  0.004234    0.632268    0.347709  0.030360   \n",
       "5      0.898405 -0.251462  0.016704   -0.321928    0.138647 -0.072461   \n",
       "6     -0.062380  0.000000 -0.017340    0.137504    0.138647 -0.028174   \n",
       "7      0.950384  0.109375  0.028841    0.000000    0.251930  0.107542   \n",
       "8     -0.062380  0.088105 -0.004273   -0.152003   -0.178747  0.292401   \n",
       "9      0.059007  0.088105 -0.008587    0.070389    0.000000  0.166160   \n",
       "10    -0.062380 -0.064000  0.016704   -0.234465    0.138647  0.058872   \n",
       "11    -0.062380 -0.193314  0.012585   -0.152003    0.000000  0.043443   \n",
       "12    -0.062380 -0.193314 -0.008587   -0.074001   -0.861353 -0.013683   \n",
       "13    -0.062380  0.228232 -0.004273    0.263034    0.138647  0.102587   \n",
       "14     1.257984  0.157065  0.004234    0.722466    0.821253  0.009326   \n",
       "15    -0.062380 -0.193314  0.028841   -0.234465   -0.861353  0.105077   \n",
       "16    -0.062380  0.088105  0.032816   -0.234465    0.138647  0.057372   \n",
       "17    -0.198978 -0.167786 -0.008587   -0.234465   -0.430677  0.061845   \n",
       "18    -0.062380 -0.635444  0.012585   -0.321928    0.138647 -0.009695   \n",
       "19    -0.062380 -0.167786  0.028841   -0.152003   -0.178747  0.067684   \n",
       "20    -0.062380 -0.144151  0.032816   -0.234465    0.000000  0.018310   \n",
       "21    -0.062380  0.088105  0.008428    0.321928   -0.430677  0.209421   \n",
       "22     0.000000 -0.014837 -0.035367   -0.234465   -0.430677 -0.017736   \n",
       "23    -0.062380 -0.322629 -0.004273   -0.321928   -0.430677  0.115978   \n",
       "24    -0.062380  0.198543 -0.026264    1.378512    0.251930  0.149170   \n",
       "25    -0.128543 -0.122147 -0.017340    0.070389   -0.430677  0.035348   \n",
       "26    -0.062380 -0.472527  0.020785   -0.321928   -0.430677  0.189183   \n",
       "27    -0.274274  0.636759  0.028841    2.070389    0.569323  0.020068   \n",
       "28    -0.274274  0.065315 -0.012943    0.201634    0.000000  0.105077   \n",
       "29    -0.062380  0.165803 -0.008587   -0.152003    0.000000 -0.021858   \n",
       "...         ...       ...       ...         ...         ...       ...   \n",
       "4090  -0.062380  0.000000  0.044536    0.070389    0.347709  0.204516   \n",
       "4091  -0.442507  0.297978 -0.021780    1.536053    0.138647  0.272579   \n",
       "4092  -0.062380 -0.365216 -0.004273   -0.234465   -0.430677  0.032034   \n",
       "4093  -0.198978  0.076914  0.024831   -0.074001    0.138647  0.070553   \n",
       "4094  -0.442507 -0.167786 -0.004273   -0.234465   -0.430677  0.142882   \n",
       "4095   0.059007 -0.144151  0.004234   -0.234465    0.138647  0.001894   \n",
       "4096  -0.062380 -0.030397  0.020785   -0.074001    0.138647  0.051279   \n",
       "4097   0.059007  0.109375  0.020785    0.765535    0.138647  0.102587   \n",
       "4098  -0.062380  0.449297 -0.021780    0.887525    0.138647  0.232574   \n",
       "4099   1.349749 -0.167786  0.020785    0.070389    0.138647  0.135335   \n",
       "4100  -0.062380 -0.064000  0.008428   -0.152003   -0.178747  0.128676   \n",
       "4101  -0.198978 -0.014837  0.028841   -0.415037   -0.861353 -0.064915   \n",
       "4102   0.401319 -0.082229 -0.012943    0.000000    0.138647  0.159306   \n",
       "4103  -0.062380  0.340565 -0.004273    1.104337    0.000000  0.162267   \n",
       "4104   0.059007  0.000000 -0.008587   -0.074001    0.000000  0.067684   \n",
       "4105   0.843826  0.286380 -0.008587    0.632268    0.138647  0.203688   \n",
       "4106  -0.062380  0.213733 -0.049372    1.608809    0.569323  0.120672   \n",
       "4107   0.442507 -0.030397  0.016704    0.201634   -0.178747  0.105077   \n",
       "4108   1.136598  0.297978 -0.008587    0.137504    0.347709  0.308589   \n",
       "4109  -0.062380 -0.064000  0.008428   -0.862496   -0.430677 -0.034657   \n",
       "4110  -0.062380 -0.285064  0.004234   -0.152003   -0.178747  0.018310   \n",
       "4111  -0.062380  0.391149  0.044536    0.963474    0.569323  0.152255   \n",
       "4112  -0.062380 -0.014837 -0.021780   -0.074001   -0.178747  0.003773   \n",
       "4113  -0.062380  0.088105 -0.004273    0.432959    0.138647  0.021814   \n",
       "4114   0.358515 -0.285064 -0.017340   -0.321928    0.430677  0.087093   \n",
       "4115  -0.062380 -0.064000  0.028841    0.000000    0.000000  0.067684   \n",
       "4116  -0.355152  0.297978  0.000000    0.887525    0.000000  0.233310   \n",
       "4117  -0.062380  0.076914 -0.030793   -0.074001   -0.430677 -0.036856   \n",
       "4118  -0.274274  0.325254  0.032816    0.137504   -0.178747  0.061845   \n",
       "4119  -0.062380  0.165803  0.024831    0.536053    0.000000  0.508545   \n",
       "\n",
       "      heartrate       inr   lactate  potassium  ...  any_vasoactives_1.0  \\\n",
       "0      0.127153  0.476541  0.251584  -0.251173  ...                  1.0   \n",
       "1      0.094684 -0.132111 -0.041188  -0.138959  ...                  1.0   \n",
       "2      0.127153  0.126488  0.114986  -0.251173  ...                  0.0   \n",
       "3      0.064284  0.000000  0.114986  -0.103141  ...                  0.0   \n",
       "4      0.081233  0.000000 -0.083992   0.033036  ...                  0.0   \n",
       "5      0.064284  0.126488  0.114986   0.065443  ...                  0.0   \n",
       "6      0.115063  0.000000  0.114986   0.304614  ...                  1.0   \n",
       "7      0.030582  0.476541  0.114986  -0.068061  ...                  0.0   \n",
       "8      0.143325  1.412966 -0.571050  -0.033690  ...                  0.0   \n",
       "9      0.099906  0.247811  0.114986   0.128461  ...                  1.0   \n",
       "10     0.119956  0.476541  0.581480   0.562882  ...                  1.0   \n",
       "11     0.127153  0.000000 -0.223504   0.033036  ...                  0.0   \n",
       "12     0.007061 -0.132111  0.114986  -0.033690  ...                  0.0   \n",
       "13     0.094684  0.981483  0.150771   0.359500  ...                  0.0   \n",
       "14     0.010532  1.927931  0.796161   0.097243  ...                  1.0   \n",
       "15     0.055449 -0.415374  0.114986   0.033036  ...                  0.0   \n",
       "16    -0.026059 -0.270369  0.114986   0.000000  ...                  0.0   \n",
       "17     0.070037 -0.270369  0.114986   0.065443  ...                  0.0   \n",
       "18     0.049416 -0.415374  0.114986  -0.371314  ...                  0.0   \n",
       "19     0.078472  0.000000 -0.174991   0.128461  ...                  0.0   \n",
       "20     0.173344 -0.132111 -0.128543   0.033036  ...                  0.0   \n",
       "21     0.183399 -0.132111  0.114986  -0.138959  ...                  0.0   \n",
       "22     0.078472  0.000000  0.114986  -0.068061  ...                  0.0   \n",
       "23     0.007061  0.688918  0.000000   0.304614  ...                  1.0   \n",
       "24    -0.037933  0.126488  0.114986   0.159116  ...                  0.0   \n",
       "25     0.017360 -0.270369 -0.223504   0.097243  ...                  0.0   \n",
       "26     0.097306 -0.415374  0.185420   0.033036  ...                  0.0   \n",
       "27     0.033802  1.994721  0.077987   0.332278  ...                  0.0   \n",
       "28     0.136497 -0.132111 -0.223504   0.128461  ...                  0.0   \n",
       "29     0.279622  0.126488 -0.223504  -0.033690  ...                  1.0   \n",
       "...         ...       ...       ...        ...  ...                  ...   \n",
       "4090   0.075685  0.476541  0.185420   0.097243  ...                  0.0   \n",
       "4091   0.092040 -0.132111  0.114986   0.033036  ...                  0.0   \n",
       "4092   0.134187 -0.415374 -0.504887  -0.033690  ...                  0.0   \n",
       "4093   0.061366 -0.132111  0.834458   0.033036  ...                  0.0   \n",
       "4094   0.092040 -0.270369  0.756471   0.464228  ...                  0.0   \n",
       "4095   0.027329 -0.132111 -0.223504  -0.103141  ...                  0.0   \n",
       "4096   0.033802  0.126488  0.077987   0.538749  ...                  1.0   \n",
       "4097  -0.014622  0.887125  1.372970   0.722853  ...                  1.0   \n",
       "4098   0.099906 -0.270369  0.114986   0.189228  ...                  0.0   \n",
       "4099   0.061366  0.126488  0.251584  -0.033690  ...                  0.0   \n",
       "4100   0.086684  0.000000  0.114986   0.000000  ...                  0.0   \n",
       "4101   0.127153  0.981483  0.114986  -0.068061  ...                  0.0   \n",
       "4102  -0.026059  2.947168 -0.274274   0.000000  ...                  0.0   \n",
       "4103   0.007061 -0.132111  0.114986   0.332278  ...                  1.0   \n",
       "4104   0.052447  0.000000  0.219003   0.097243  ...                  0.0   \n",
       "4105   0.024042  2.748960  1.502789   0.189228  ...                  0.0   \n",
       "4106   0.107577  0.000000  0.114986   0.438644  ...                  1.0   \n",
       "4107   0.083970  2.536583  0.039690  -0.251173  ...                  0.0   \n",
       "4108   0.083970  1.331535  0.853114   0.218816  ...                  0.0   \n",
       "4109   0.083970 -0.270369  0.114986   0.304614  ...                  0.0   \n",
       "4110   0.075685 -0.415374  0.401319   0.097243  ...                  0.0   \n",
       "4111   0.107577  0.247811  0.507877   0.438644  ...                  0.0   \n",
       "4112   0.089373  0.584626  0.372970  -0.175547  ...                  0.0   \n",
       "4113  -0.050279 -0.132111  0.114986  -0.033690  ...                  0.0   \n",
       "4114   0.160832  0.247811  0.114986  -0.138959  ...                  0.0   \n",
       "4115   0.064284  0.887125  0.114986   0.276493  ...                  0.0   \n",
       "4116   0.072874  0.000000 -0.128543   0.128461  ...                  0.0   \n",
       "4117   0.081233  1.247811  0.114986   0.033036  ...                  0.0   \n",
       "4118   0.122373 -0.132111  0.114986   0.276493  ...                  0.0   \n",
       "4119   0.027329  0.000000  0.114986   0.656127  ...                  0.0   \n",
       "\n",
       "      bands_>10  bands_absent  pco2_>50  pco2_absent  ethnicity_black  \\\n",
       "0           0.0           1.0       0.0          0.0              1.0   \n",
       "1           0.0           1.0       0.0          1.0              0.0   \n",
       "2           0.0           1.0       0.0          1.0              0.0   \n",
       "3           0.0           1.0       0.0          1.0              0.0   \n",
       "4           0.0           1.0       0.0          1.0              0.0   \n",
       "5           0.0           1.0       0.0          1.0              0.0   \n",
       "6           0.0           1.0       0.0          0.0              0.0   \n",
       "7           0.0           1.0       0.0          0.0              0.0   \n",
       "8           0.0           1.0       0.0          1.0              0.0   \n",
       "9           0.0           1.0       0.0          0.0              0.0   \n",
       "10          0.0           1.0       0.0          1.0              0.0   \n",
       "11          0.0           1.0       0.0          1.0              0.0   \n",
       "12          0.0           1.0       0.0          1.0              0.0   \n",
       "13          0.0           1.0       0.0          1.0              0.0   \n",
       "14          1.0           0.0       0.0          1.0              1.0   \n",
       "15          0.0           1.0       0.0          0.0              0.0   \n",
       "16          0.0           1.0       0.0          1.0              0.0   \n",
       "17          0.0           1.0       0.0          1.0              0.0   \n",
       "18          0.0           1.0       0.0          1.0              1.0   \n",
       "19          0.0           1.0       0.0          1.0              0.0   \n",
       "20          0.0           1.0       0.0          1.0              0.0   \n",
       "21          0.0           1.0       0.0          1.0              1.0   \n",
       "22          0.0           0.0       0.0          1.0              0.0   \n",
       "23          0.0           1.0       1.0          0.0              0.0   \n",
       "24          0.0           1.0       0.0          1.0              0.0   \n",
       "25          0.0           1.0       0.0          1.0              1.0   \n",
       "26          0.0           1.0       0.0          0.0              0.0   \n",
       "27          0.0           1.0       0.0          0.0              0.0   \n",
       "28          0.0           1.0       0.0          0.0              0.0   \n",
       "29          0.0           1.0       0.0          1.0              0.0   \n",
       "...         ...           ...       ...          ...              ...   \n",
       "4090        0.0           1.0       0.0          1.0              0.0   \n",
       "4091        0.0           0.0       0.0          1.0              0.0   \n",
       "4092        0.0           1.0       1.0          0.0              0.0   \n",
       "4093        0.0           1.0       0.0          0.0              0.0   \n",
       "4094        0.0           1.0       0.0          1.0              0.0   \n",
       "4095        0.0           1.0       0.0          1.0              1.0   \n",
       "4096        0.0           1.0       0.0          1.0              0.0   \n",
       "4097        0.0           1.0       0.0          1.0              0.0   \n",
       "4098        0.0           1.0       0.0          1.0              0.0   \n",
       "4099        0.0           1.0       0.0          0.0              0.0   \n",
       "4100        1.0           0.0       0.0          1.0              0.0   \n",
       "4101        0.0           1.0       0.0          1.0              0.0   \n",
       "4102        0.0           1.0       0.0          1.0              0.0   \n",
       "4103        0.0           1.0       0.0          1.0              0.0   \n",
       "4104        0.0           1.0       1.0          0.0              0.0   \n",
       "4105        0.0           1.0       0.0          0.0              0.0   \n",
       "4106        0.0           1.0       0.0          1.0              0.0   \n",
       "4107        1.0           0.0       0.0          1.0              0.0   \n",
       "4108        1.0           0.0       0.0          1.0              0.0   \n",
       "4109        0.0           1.0       0.0          1.0              0.0   \n",
       "4110        0.0           1.0       0.0          0.0              0.0   \n",
       "4111        0.0           0.0       1.0          0.0              0.0   \n",
       "4112        0.0           1.0       0.0          1.0              0.0   \n",
       "4113        0.0           1.0       0.0          1.0              0.0   \n",
       "4114        0.0           1.0       0.0          1.0              0.0   \n",
       "4115        0.0           1.0       0.0          0.0              0.0   \n",
       "4116        0.0           0.0       0.0          0.0              0.0   \n",
       "4117        0.0           1.0       0.0          1.0              0.0   \n",
       "4118        0.0           1.0       0.0          1.0              0.0   \n",
       "4119        0.0           1.0       0.0          1.0              0.0   \n",
       "\n",
       "      ethnicity_hispanic  ethnicity_unknown/other  \\\n",
       "0                    0.0                      0.0   \n",
       "1                    0.0                      0.0   \n",
       "2                    0.0                      0.0   \n",
       "3                    0.0                      1.0   \n",
       "4                    0.0                      1.0   \n",
       "5                    0.0                      0.0   \n",
       "6                    0.0                      0.0   \n",
       "7                    0.0                      1.0   \n",
       "8                    0.0                      0.0   \n",
       "9                    0.0                      1.0   \n",
       "10                   0.0                      0.0   \n",
       "11                   0.0                      0.0   \n",
       "12                   0.0                      0.0   \n",
       "13                   0.0                      0.0   \n",
       "14                   0.0                      0.0   \n",
       "15                   0.0                      0.0   \n",
       "16                   0.0                      0.0   \n",
       "17                   0.0                      0.0   \n",
       "18                   0.0                      0.0   \n",
       "19                   0.0                      1.0   \n",
       "20                   0.0                      1.0   \n",
       "21                   0.0                      0.0   \n",
       "22                   0.0                      0.0   \n",
       "23                   0.0                      0.0   \n",
       "24                   0.0                      0.0   \n",
       "25                   0.0                      0.0   \n",
       "26                   0.0                      0.0   \n",
       "27                   0.0                      0.0   \n",
       "28                   0.0                      0.0   \n",
       "29                   0.0                      1.0   \n",
       "...                  ...                      ...   \n",
       "4090                 0.0                      0.0   \n",
       "4091                 0.0                      0.0   \n",
       "4092                 0.0                      0.0   \n",
       "4093                 0.0                      0.0   \n",
       "4094                 0.0                      1.0   \n",
       "4095                 0.0                      0.0   \n",
       "4096                 0.0                      1.0   \n",
       "4097                 0.0                      0.0   \n",
       "4098                 0.0                      0.0   \n",
       "4099                 0.0                      0.0   \n",
       "4100                 0.0                      0.0   \n",
       "4101                 0.0                      0.0   \n",
       "4102                 1.0                      0.0   \n",
       "4103                 0.0                      0.0   \n",
       "4104                 0.0                      1.0   \n",
       "4105                 0.0                      0.0   \n",
       "4106                 0.0                      0.0   \n",
       "4107                 0.0                      0.0   \n",
       "4108                 0.0                      0.0   \n",
       "4109                 0.0                      0.0   \n",
       "4110                 1.0                      0.0   \n",
       "4111                 0.0                      0.0   \n",
       "4112                 0.0                      0.0   \n",
       "4113                 0.0                      0.0   \n",
       "4114                 0.0                      0.0   \n",
       "4115                 0.0                      0.0   \n",
       "4116                 0.0                      0.0   \n",
       "4117                 0.0                      0.0   \n",
       "4118                 0.0                      0.0   \n",
       "4119                 0.0                      0.0   \n",
       "\n",
       "      ethnicity_white/nonhispanic  gender_1  \n",
       "0                             0.0       1.0  \n",
       "1                             1.0       1.0  \n",
       "2                             1.0       1.0  \n",
       "3                             0.0       1.0  \n",
       "4                             0.0       1.0  \n",
       "5                             1.0       0.0  \n",
       "6                             1.0       1.0  \n",
       "7                             0.0       1.0  \n",
       "8                             1.0       0.0  \n",
       "9                             0.0       1.0  \n",
       "10                            1.0       0.0  \n",
       "11                            1.0       0.0  \n",
       "12                            1.0       1.0  \n",
       "13                            1.0       1.0  \n",
       "14                            0.0       0.0  \n",
       "15                            1.0       0.0  \n",
       "16                            1.0       1.0  \n",
       "17                            1.0       1.0  \n",
       "18                            0.0       1.0  \n",
       "19                            0.0       1.0  \n",
       "20                            0.0       0.0  \n",
       "21                            0.0       1.0  \n",
       "22                            1.0       0.0  \n",
       "23                            1.0       0.0  \n",
       "24                            1.0       0.0  \n",
       "25                            0.0       1.0  \n",
       "26                            1.0       0.0  \n",
       "27                            1.0       0.0  \n",
       "28                            1.0       0.0  \n",
       "29                            0.0       1.0  \n",
       "...                           ...       ...  \n",
       "4090                          1.0       0.0  \n",
       "4091                          1.0       1.0  \n",
       "4092                          1.0       0.0  \n",
       "4093                          1.0       1.0  \n",
       "4094                          0.0       0.0  \n",
       "4095                          0.0       0.0  \n",
       "4096                          0.0       1.0  \n",
       "4097                          1.0       1.0  \n",
       "4098                          1.0       0.0  \n",
       "4099                          1.0       1.0  \n",
       "4100                          1.0       1.0  \n",
       "4101                          1.0       0.0  \n",
       "4102                          0.0       1.0  \n",
       "4103                          0.0       1.0  \n",
       "4104                          0.0       1.0  \n",
       "4105                          1.0       0.0  \n",
       "4106                          1.0       0.0  \n",
       "4107                          1.0       0.0  \n",
       "4108                          1.0       0.0  \n",
       "4109                          1.0       1.0  \n",
       "4110                          0.0       1.0  \n",
       "4111                          1.0       0.0  \n",
       "4112                          1.0       1.0  \n",
       "4113                          1.0       1.0  \n",
       "4114                          1.0       1.0  \n",
       "4115                          1.0       1.0  \n",
       "4116                          1.0       1.0  \n",
       "4117                          1.0       1.0  \n",
       "4118                          1.0       0.0  \n",
       "4119                          1.0       0.0  \n",
       "\n",
       "[4120 rows x 57 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 60.4 ms\n"
     ]
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# experimenting with pipelines end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>any_vasoactive</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>...</th>\n",
       "      <th>('min', 'sodium')</th>\n",
       "      <th>('min', 'wbc')</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>level_1</th>\n",
       "      <th>bands</th>\n",
       "      <th>first_admit_age</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088105</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.110911</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.19</td>\n",
       "      <td>(333, 475]</td>\n",
       "      <td>32.0</td>\n",
       "      <td>113.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.082229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>-0.213428</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.14</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>-0.180324</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.93</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200061.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.406299</td>\n",
       "      <td>-0.101564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008031</td>\n",
       "      <td>0.189444</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.75</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.347709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012090</td>\n",
       "      <td>-0.114485</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>value</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.07</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id  any_vasoactive  bilirubin       bun  cancer_elix  chloride  \\\n",
       "0    200030.0             1.0        NaN  0.088105          0.0  0.020785   \n",
       "1    200033.0             1.0        NaN -0.082229          1.0  0.004234   \n",
       "2    200036.0             0.0        NaN  0.119501          0.0  0.016704   \n",
       "3    200061.0             0.0   1.406299 -0.101564          0.0  0.000000   \n",
       "4    200063.0             0.0        NaN  0.148081          0.0  0.004234   \n",
       "\n",
       "   creatinine  daily_sofa  dobutamine  dopamine  ...  ('min', 'sodium')  \\\n",
       "0    0.000000    0.138647         1.0       0.0  ...           0.003972   \n",
       "1   -0.234465   -0.430677         0.0       0.0  ...          -0.024447   \n",
       "2    0.000000   -0.430677         0.0       0.0  ...           0.007917   \n",
       "3   -0.074001    0.000000         0.0       0.0  ...          -0.008031   \n",
       "4    0.632268    0.347709         0.0       0.0  ...          -0.012090   \n",
       "\n",
       "   ('min', 'wbc')          ethnicity  gender  level_1  bands  first_admit_age  \\\n",
       "0        0.110911              black       1    value    NaN            54.19   \n",
       "1       -0.213428  white/nonhispanic       1    value    NaN            67.14   \n",
       "2       -0.180324  white/nonhispanic       1    value    NaN            74.93   \n",
       "3        0.189444      unknown/other       1    value    NaN            45.75   \n",
       "4       -0.114485      unknown/other       1    value    NaN            37.07   \n",
       "\n",
       "   pao2fio2ratio  pco2  weight  \n",
       "0     (333, 475]  32.0   113.6  \n",
       "1    (475, 3000]   NaN    74.0  \n",
       "2    (475, 3000]   NaN    79.0  \n",
       "3    (475, 3000]   NaN   250.0  \n",
       "4    (475, 3000]   NaN     NaN  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.1 ms\n"
     ]
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### optional qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.iloc[1:5, 25:45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.iloc[1:5, 35:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train.iloc[1:5, 10:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at correlation of all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = x_train.corr().abs()\n",
    "\n",
    "plt.figure(figsize=(25, 20))\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol = (corr.where(np.triu(np.ones(corr.shape), k=1).astype(np.bool)).stack().sort_values(ascending=False))\n",
    "cor_df=pd.DataFrame(sol)#.sort_values(kind=\"quicksort\") #[-10:0])\n",
    "cor_df=cor_df.reset_index()\n",
    "cor_df=cor_df.rename(columns={'level_0': 'corx', 'level_1': 'cory', 0:'corr'})\n",
    "cor_df2=cor_df[(cor_df['corx']!=cor_df['cory']) & (cor_df['corr']>0.7)].sort_values('corr', ascending=False)\n",
    "cor_df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DROPING one of the 2 columns with correlation >0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\tcorx\tcory\tcorr\n",
    "0\tipco2_absent\tpao2fio2Ratio_(475, 3000]\t0.872418\n",
    "1\tmaxWBC\tminWBC\t0.802373\n",
    "2\tbun\tcreatinine\t0.720861\n",
    "3\tmaxSodium\tminSodium\t0.704233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.drop(columns=list(cor_df2['corx']), inplace=True, errors='raise')\n",
    "x_test.drop(columns=list(cor_df2['corx']), inplace=True, errors='raise')\n",
    "# all_xy.drop(columns=list(cor_df2['corx']), inplace=True, errors='raise')\n",
    "# all_xy_test.drop(columns=list(cor_df2['corx']), inplace=True, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting x and y for modleing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x=np.array(x_train.iloc[:,[1,2,3,4,5,6,7,8,9,38,39,40,41]]).copy() #copy of x_train\n",
    "x=np.array(x_train.copy())\n",
    "\n",
    "#x=np.array(train_data.iloc[:,[1,2,3,4]]).copy() #copy of x_train\n",
    "#train_data.iloc[:,[1,2,3,4,5]] ###drastically reducing my dataframe size to test algorithm\n",
    "y=y_train.copy() #copy of y_train\n",
    "y=y.astype('int')\n",
    "##all_xy: train data with finalbin:label and index=icustay_id\n",
    "#all_xy=train_data.copy().set_index(\"icustay_id\").rename(columns={'final_bin':\"label\"}) #\n",
    "\n",
    "time_interval=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train),len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelbuilding\n",
    "* step1) hypertune xgb on 5fold cv.\n",
    "* step2) test entire trainset and predict trainset.\n",
    "* step3) run hypertuned model on 5fold cv with lr and get overall metrics.\n",
    "* step4) local model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## step1) XGB hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    from sklearn.metrics import log_loss\n",
    "    \n",
    "    y_hat = model.predict(test_features)\n",
    "    errors = abs(y_hat - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    auc=roc_auc_score(test_labels, y_hat)\n",
    "    loss= log_loss(test_labels, y_hat)\n",
    "    \n",
    "    print ('the AUC is: {:0.2f}'.format(auc))\n",
    "    print ('the logloss is: {:0.2f}'.format(loss))\n",
    "    print(confusion_matrix(test_labels, y_hat))\n",
    "    \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypertuning_fxn(X, y, nfolds, model , param_grid, base_model, scoring=\"neg_log_loss\", gridsearch=True, n_iter=20): \n",
    "    if gridsearch==True:\n",
    "        grid_search = GridSearchCV(estimator= model,\n",
    "                                         param_grid=param_grid,\n",
    "                                         cv=nfolds,\n",
    "                                         scoring=scoring,\n",
    "                                         return_train_score=True,\n",
    "                                         n_jobs = -1)\n",
    "    else:\n",
    "        grid_search = RandomizedSearchCV(estimator= model,\n",
    "                                         param_distributions= param_grid,\n",
    "                                         n_iter=n_iter,\n",
    "                                         cv=nfolds,\n",
    "                                         scoring=scoring,\n",
    "                                         return_train_score=True,\n",
    "                                         n_jobs = -1)\n",
    "    grid_search.fit(X, y)    \n",
    "    \n",
    "    print(\"Grid scores on development set:\")\n",
    "    means = grid_search.cv_results_['mean_test_score']\n",
    "    stds = grid_search.cv_results_['std_test_score']\n",
    "    \n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "        \n",
    "    #grid_search.best_params_\n",
    "    print(grid_search.best_score_)\n",
    "    print(\"\\n\")\n",
    "    print(grid_search.best_params_)\n",
    "    \n",
    "    print('\\n base model:')\n",
    "    base_model = base_model#(random_state = 42)\n",
    "    base_model.fit(x, y)\n",
    "    base_auc = evaluate(base_model, x, y)\n",
    "    \n",
    "    print('\\n hypertuned model:')\n",
    "    best_random = grid_search.best_estimator_\n",
    "    random_auc = evaluate(best_random, x, y)\n",
    "\n",
    "    print('logloss change of {:0.2f}%. after hypertuning on training set (may be overfit)'.format( 100 * (random_auc - base_auc) / base_auc))\n",
    "    \n",
    "    print(grid_search.best_estimator_)\n",
    "    \n",
    "    return(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###xgboost\n",
    "model= XGBClassifier(n_estimators=100, min_child_weight=2, #changed: GridSearchCV ->RandomizedSearchCV\n",
    "                                              gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                              objective='binary:logistic', n_jobs=-1, seed=27)\n",
    "scale_pos_weight = [0.1, 1, 5, 10]\n",
    "max_depth = [1, 2, 3, 4, 5]\n",
    "learning_rate=[0.01, 0.1, 0.5, 1]\n",
    "param_grid = {'scale_pos_weight': scale_pos_weight, 'max_depth' : max_depth, \"learning_rate\":learning_rate}\n",
    "\n",
    "base_model=XGBClassifier(random_state = 42)\n",
    "xgboost_hyper=hypertuning_fxn(x, y, nfolds=5, model=model , param_grid=param_grid, base_model= base_model, scoring=\"neg_log_loss\", n_iter=20, gridsearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###rf\n",
    "# Number of trees in random forest\n",
    "#n_estimators = [100, 1000]#[int(x) for x in np.linspace(start = 10, stop = 1000, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [3,'auto', 10 ]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5,10, 25]#[int(x) for x in np.linspace(5, 110, num = 5)]\n",
    "#max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2, 5, 10]\n",
    "# Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]\n",
    "\n",
    "#class_weight is either a dictionary of each class to a uniform weight for that class (e.g., {1:.9, 2:.5, 3:.01}), or is a string telling sklearn how to automatically determine this dictionary.\n",
    "class_weight= [None,{0:1, 1:4}, {0:(1/np.bincount(y))[0], 1:(1/np.bincount(y))[1]}]\n",
    "\n",
    "\n",
    "param_grid = {#'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'class_weight': class_weight}\n",
    "\n",
    "\n",
    "model= RandomForestClassifier(criterion='entropy')\n",
    "base_model=RandomForestClassifier(random_state = 42, criterion='entropy')\n",
    "\n",
    "rf_hyper=hypertuning_fxn(x, y, nfolds=10, model=model , param_grid=param_grid, base_model= base_model, scoring=\"neg_log_loss\",n_iter = 30, gridsearch=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertune SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= svm.SVC(probability=True)\n",
    "kernel = ['linear', 'rbf', 'poly']\n",
    "gamma = [0.1, 1, 'auto'] #Kernel coefficient for ârbfâ, âpolyâ and âsigmoidâ. default=âautoâ uses 1 / n_features\n",
    "C = [0.1, 1, 10, 100] #Penalty parameter C of the error term.\n",
    "degree = [0, 1, 2]\n",
    "class_weight=['balanced', None]\n",
    "\n",
    "param_grid = {'kernel': kernel,\n",
    "              'gamma': gamma,\n",
    "              'C': C,\n",
    "              'degree': degree,\n",
    "              'class_weight':class_weight}\n",
    "\n",
    "base_model=svm.SVC(probability=True)\n",
    "\n",
    "svc_hyper=hypertuning_fxn(x, y, nfolds=4, model=model , param_grid=param_grid, base_model= base_model, scoring=\"neg_log_loss\", n_iter=10, gridsearch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model= KNeighborsClassifier()\n",
    "\n",
    "n_neighbors = [3,4,5, 8, 10, 25]\n",
    "weights=['uniform']\n",
    "p=[1,2] #1= mmanhattan, 2= euclidian\n",
    "\n",
    "\n",
    "param_grid = {'n_neighbors': n_neighbors,\n",
    "              'weights': weights,\n",
    "              'p': p}\n",
    "\n",
    "base_model=KNeighborsClassifier()\n",
    "\n",
    "knn_hyper=hypertuning_fxn(x, y, nfolds=10, model=model , param_grid=param_grid, base_model= base_model, scoring=\"neg_log_loss\", n_iter=40, gridsearch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_hyper.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuned Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_model(model_name, hardcode=True):\n",
    "    if hardcode==True:\n",
    "        if model_name== 'xgboost':\n",
    "            model = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "               colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "               max_depth=4, min_child_weight=2, missing=None, n_estimators=100,\n",
    "               n_jobs=-1, nthread=None, objective='binary:logistic',\n",
    "               random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "               seed=27, silent=True, subsample=0.8)\n",
    "            \n",
    "\n",
    "        elif model_name== 'logreg':\n",
    "            model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "                                    intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "\n",
    "        elif model_name== 'rf':\n",
    "            model = RandomForestClassifier(bootstrap=False, class_weight={0: 1, 1: 4},\n",
    "                criterion='entropy', max_depth=10, max_features='auto',\n",
    "                max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "                min_impurity_split=None, min_samples_leaf=2,\n",
    "                min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                n_estimators=600, n_jobs=None, oob_score=False,\n",
    "                random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "        elif model_name== 'svc':\n",
    "            model = svm.SVC(C=100, cache_size=200, class_weight='balanced', coef0=0.0,\n",
    "                  decision_function_shape='ovr', degree=0, gamma=1, kernel='linear',\n",
    "                  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "                  tol=0.001, verbose=False)\n",
    "            \n",
    "        elif model_name== 'knn':\n",
    "            model = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "                   metric_params=None, n_jobs=None, n_neighbors=25, p=1,\n",
    "                   weights='uniform')\n",
    "    \n",
    "    else:\n",
    "            if model_name== 'xgboost':\n",
    "                model = xgboost_hyper.best_estimator_\n",
    "\n",
    "            elif model_name== 'logreg':\n",
    "                model = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "                                        intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "\n",
    "            elif model_name== 'rf':\n",
    "                model = rf_hyper.best_estimator_\n",
    "\n",
    "            elif model_name== 'svc':\n",
    "                model = svc_hyper.best_estimator_\n",
    "                \n",
    "            elif model_name== 'knn':\n",
    "                model = knn_hyper.best_estimator_\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test entire trainset and predict testset.\n",
    "*<del> step1) hypertune xgb on 5fold cv.\n",
    "* step2) test entire trainset and predict testset.\n",
    "* step3) local model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc_score(model,train_index, x=x,y=y):\n",
    "    y_pred_proba = model.predict_proba(x[train_index])[:, 1] \n",
    "    roc_score=roc_auc_score(y[train_index], y_pred_proba)\n",
    "    return(roc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## youden index and plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_youden_index(fpr, tpr, thresholds, tp90=True):\n",
    "    \"\"\"\n",
    "    inputs fpr, tpr, thresholds from metrics.roc(),\n",
    "    outputs the clasification threshold, roc dataframe, and the index of roc dataframe for optimal youden index\n",
    "    \"\"\"\n",
    "    #making dataframe out of the thresholds\n",
    "    roc_df= pd.DataFrame({\"thresholds\": thresholds,\"fpr\":fpr, \"tpr\": tpr})\n",
    "    roc_df.iloc[0,0] =1\n",
    "    roc_df['yuden']= roc_df['tpr']-roc_df['fpr']\n",
    "    \n",
    "    if tp90==True:\n",
    "        idx= roc_df[roc_df['tpr']>=0.9]['yuden'].idxmax() #changed this so now finds optimial yuden threshold but tp>=90%\n",
    "    else:\n",
    "        idx=roc_df['yuden'].idxmax() #MAX INDEX\n",
    "    \n",
    "    youden_threshold=roc_df.iloc[idx,0] #threshold for max youden\n",
    "    return(youden_threshold, roc_df, idx)\n",
    "    \n",
    "def plot_roc(fpr, tpr, roc_auc, roc_df, idx, save=False,model_name=None, folder_name=None, file_name=None):\n",
    "    plt.title('ROC with optimal Youden Index')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    \n",
    "    #finding the point on the line given threshold 0.5 (finding closest row in roc_df)\n",
    "    og_idx=roc_df.iloc[(roc_df['thresholds']-0.5).abs().argsort()[:1]].index[0]\n",
    "    plt.plot(roc_df.iloc[og_idx,1], roc_df.iloc[og_idx,2],marker='x', markersize=5, color=\"g\")\n",
    "    plt.annotate(s=\"P(>=0.5)\",xy=(roc_df.iloc[og_idx,1]+0.02, roc_df.iloc[og_idx,2]-0.04),color='g') #textcoords\n",
    "    \n",
    "    \n",
    "    plt.plot(roc_df.iloc[idx,1], roc_df.iloc[idx,2],marker='o', markersize=5, color=\"r\") ##\n",
    "    plt.annotate(s=\"M_Youden\",xy=(roc_df.iloc[idx,1]+0.02, roc_df.iloc[idx,2]-0.04),color='r' ) #textcoords\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    \n",
    "    if save==True:\n",
    "        if folder_name != None:\n",
    "            address = 'figures/{}/'.format(folder_name)\n",
    "        else:\n",
    "            address = 'figures/'\n",
    "        if not os.path.exists(address):\n",
    "            os.makedirs(address)\n",
    "        plt.savefig(address+\"/{}_{}.png\".format(model_name,file_name),bbox_inches='tight')\n",
    "    else: pass\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def plot_table_as_fig(table_in, col_labels, row_labels, save=False,model_name=None,folder_name=None, file_name=None,figsize=(6,1)):\n",
    "    \n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    table = plt.table(cellText = table_in, \n",
    "                  colLabels = col_labels,\n",
    "                  rowLabels = row_labels,\n",
    "                  loc='best')\n",
    "    plt.axis(\"tight\")\n",
    "    plt.axis('off')\n",
    "    if save==True:\n",
    "        if folder_name != None:\n",
    "            address = 'figures/{}/'.format(folder_name)\n",
    "        else:\n",
    "            address = 'figures/'\n",
    "        if not os.path.exists(address):\n",
    "            os.makedirs(address)\n",
    "        plt.savefig(address+\"/{}_{}.png\".format(model_name,file_name),bbox_inches='tight')\n",
    "    else: pass\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_eval(model, x=x, y=y, proba_input=False,pos_label=1, print_default=True, save=False,model_name=None, folder_name=None):\n",
    "    import sklearn.metrics as metrics\n",
    "    from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "\n",
    "    \"\"\"\n",
    "    catchall classification evaluation function. will print/save the following:\n",
    "    \n",
    "    print/save the following:\n",
    "        ROC curve marked with threshold for optimal youden (maximizing tpr+fpr with constraint that tpr>0.9)\n",
    "\n",
    "        using 0.5 threshold:\n",
    "            confusion matrix\n",
    "            classification report\n",
    "            npv\n",
    "            accuracy\n",
    "\n",
    "\n",
    "        using optimal youden (maximizing tpr+fpr with constraint that tpr>0.9):\n",
    "            confusion matrix\n",
    "            classification report\n",
    "            npv\n",
    "            accuracy\n",
    "    \n",
    "    output: \n",
    "        outputs modelname, auc, precision, recall, f1, and npv to a dictionary. \n",
    "    \n",
    "    notes:\n",
    "    youden's J statistic:\n",
    "    J= sensitivity + specificity -1\n",
    "    (truepos/ truepos+falseneg) + (true neg/ trueneg + falsepos) -1\n",
    "    \n",
    "    \"\"\"\n",
    "    if save==True: #making folder if one doesn't exist\n",
    "        if folder_name != None:\n",
    "            address = '../figures/{}/'.format(folder_name)\n",
    "        else:\n",
    "            address = 'train/'\n",
    "        if not os.path.exists(address):\n",
    "            os.makedirs(address)\n",
    "    \n",
    "    if proba_input==True:  #incorporating classifier_eval2() functionality into this (ie allowing user to input a y_proba instead of a model)\n",
    "        y_proba= model\n",
    "        y_pred=[1 if y >= 0.5 else 0 for y in y_proba]\n",
    "    \n",
    "    else:\n",
    "        model_name=type(model).__name__\n",
    "\n",
    "        y_pred = model.predict(x)\n",
    "        y_proba = model.predict_proba(x)[:,1]\n",
    "        \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, y_proba, pos_label=pos_label)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    #gathering the optimal youden_index and df of tpr/fpr for auc and index of that optimal youden. idx is needed in the roc\n",
    "    youden_threshold, roc_df, idx= optimal_youden_index(fpr, tpr, thresholds,tp90=True)\n",
    "\n",
    "    #plotting roc\n",
    "    plot_roc(fpr, tpr, roc_auc, roc_df, idx, save=save, model_name=model_name,folder_name=folder_name, file_name='roc')\n",
    "    plt.show(), plt.close()\n",
    "    \n",
    "    #printing npv, recall, precision, accuracy\n",
    "    npv=confusion_matrix(y, y_pred)[0,0]/sum(np.array(y_pred)==0)*100\n",
    "    prec= precision_score(y_true=y, y_pred= y_pred, pos_label=pos_label)\n",
    "    recall= recall_score(y_true=y, y_pred= y_pred, pos_label=pos_label)\n",
    "    f1= f1_score(y_true=y, y_pred= y_pred, pos_label=pos_label)\n",
    "    \n",
    "    if print_default==True: ###can opt to not print the 0.5 classification threshold classification report/conf matrix\n",
    "        #plotting confusion matrixs\n",
    "        print(\"\\n******* Using 0.5 Classification Threshold *******\\n\")\n",
    "        print(confusion_matrix(y, y_pred))\n",
    "        print ('the Accuracy is: {:01.2f}'.format(accuracy_score(y, y_pred)))\n",
    "        print (\"npv: {:01.2f}\".format(npv))\n",
    "        print ('the classification_report:\\n', classification_report(y,y_pred))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    #### YOUDEN ADJUSTMENT #####\n",
    "\n",
    "    print(\"\\n******* Using Optimal Youden Classification Threshold *******\\n\")\n",
    "    print(\"\\nthe Youden optimal index is : {:01.2f}\".format(youden_threshold))\n",
    "\n",
    "    y_pred_youden = [1 if y >= youden_threshold else 0 for y in y_proba]\n",
    "\n",
    "    npv_y=confusion_matrix(y, y_pred_youden)[0,0]/sum(np.array(y_pred_youden)==0)*100\n",
    "    prec_y= precision_score(y_true=y, y_pred= y_pred_youden, pos_label=pos_label)*100\n",
    "    recall_y= recall_score(y_true=y, y_pred= y_pred_youden, pos_label=pos_label)*100\n",
    "    f1_y= f1_score(y_true=y, y_pred= y_pred_youden, pos_label=pos_label)*100\n",
    "    auc_y=roc_auc_score(y_true=y, y_score= y_proba)*100\n",
    "    \n",
    "    ##plotting and saving confusion matrix\n",
    "    confusion_youden=confusion_matrix(y, y_pred_youden)\n",
    "    \n",
    "    plot_table_as_fig(confusion_youden,\n",
    "                  col_labels=['predicted_neg','predicted_pos'],\n",
    "                  row_labels=['true_neg',\"true_pos\"],\n",
    "                  save=save,\n",
    "                  figsize=(6,1),\n",
    "                  model_name=model_name,\n",
    "                  folder_name=folder_name,\n",
    "                  file_name='y_confusion')\n",
    "    plt.show(), plt.close()\n",
    "   \n",
    "    #print(confusion_matrix(y, y_pred_youden))\n",
    "    print(\"the Accuracy is: {:01.2f}\".format(accuracy_score(y, y_pred_youden)))\n",
    "    print(\"npv: {:01.2f}\".format(npv_y))\n",
    "    \n",
    "    ###formatting classification report to be compatable with matplotlib table\n",
    "    report_youden=classification_report(y,y_pred_youden,output_dict=True)  \n",
    "    report_youden = pd.DataFrame.from_dict(report_youden).transpose()[['precision','recall','f1-score','support']]\n",
    "    report_youden = np.round(report_youden,2)\n",
    "    \n",
    "    ##plotting and saving classification report\n",
    "    plot_table_as_fig(table_in=np.array(report_youden),#classification_report(y, xgboost.predict(x))),\n",
    "                      col_labels=['precision','recall','f1-score','support'],\n",
    "                      row_labels=['neg',\"pos\",\"micro_avg\",\"macro_avg\",'weighted_avg'],\n",
    "                      figsize=(15,5),\n",
    "                      save=save,\n",
    "                      model_name=model_name,\n",
    "                      folder_name=folder_name,\n",
    "                      file_name='y_report')\n",
    "    plt.show(), plt.close()\n",
    "    \n",
    "    youden_dic= {'model':model_name, 'auc':auc_y, 'precision':prec_y, 'recall':recall_y, 'f1':f1_y, 'npv':npv_y}\n",
    "    return(youden_dic)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### label youden index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing global model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test entire trainset and predict trainset.\n",
    "<del> * step1) hypertune xgb on 5fold cv.\n",
    "\n",
    "* step2) test entire train set and predict testset.\n",
    "* step3) local model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thresholds: \n",
    "* Decreasing thresholds on the decision function used to compute\n",
    "    fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
    "    and is arbitrarily set to `max(y_score) + 1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up test table\n",
    "test_summary_df= pd.DataFrame({'model':[],'auc':[], 'precision':[], 'recall':[], 'f1':[], 'npv':[]})\n",
    "test_summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = reset_model('xgboost', hardcode=False)\n",
    "xgboost.fit(x, y)\n",
    "\n",
    "logreg = reset_model('logreg', hardcode=False)\n",
    "logreg.fit(x, y)\n",
    "\n",
    "rf= reset_model('rf', hardcode=False)\n",
    "rf.fit(x,y)\n",
    "\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb =GaussianNB()\n",
    "# nb_y_pred = gnb.fit(x, y)\n",
    "\n",
    "from sklearn import svm\n",
    "svc= reset_model('svc', hardcode=False)\n",
    "svc.fit(x, y)\n",
    "\n",
    "knn= reset_model('knn', hardcode=False)\n",
    "knn.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### global model test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_eval= classifier_eval(svc, x=np.array(x_test), y=y_test, save=True, model_name='svc', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_eval= classifier_eval(xgboost, x=np.array(x_test), y=y_test, save=True, model_name='xgboost', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_eval= classifier_eval(rf, x=np.array(x_test), y=y_test, save=True, model_name='rf', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logreg_eval= classifier_eval(logreg, x=np.array(x_test), y=y_test)\n",
    "logreg_eval= classifier_eval(logreg, x=np.array(x_test), y=y_test, save=True, model_name='logreg', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_eval= classifier_eval(knn, x=np.array(x_test), y=y_test, save=True, model_name='knn', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble of all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "#create a dictionary of our models\n",
    "estimators=[(\"xgboost\", xgboost), ('rf', rf), ('log_reg', logreg), ('svc',svc)]\n",
    "#create our voting classifier, inputting our models\n",
    "ensemble = VotingClassifier(estimators, voting='soft', n_jobs=-1)\n",
    "# If âhardâ, uses predicted class labels for majority rule voting.\n",
    "# Else if âsoftâ, predicts the class label based on the argmax of the sums of the predicted probabilities,\n",
    "# which is recommended for an ensemble of well-calibrated classifiers.\n",
    "\n",
    "#weights: array-like, shape (n_classifiers,), optional (default=`None`)\n",
    "#Sequence of weights (float or int) to weight the occurrences of predicted class labels (hard voting) or class probabilities before averaging (soft voting).\n",
    "#Uses uniform weights if None.\n",
    "ensemble.fit(x, y)#, sample_weight=np.array([0.67289604, 1.94595562]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble2 = VotingClassifier(estimators, voting='hard', n_jobs=-1)\n",
    "ensemble2.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ensemble2.predict(np.array(x_test))\n",
    "#y_proba = ensemble2.predict_proba(np.array(x_test))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, roc_auc_score, f1_score, recall_score\n",
    "pos_label=1\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred, pos_label=pos_label)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "#gathering the optimal youden_index and df of tpr/fpr for auc and index of that optimal youden. idx is needed in the roc\n",
    "youden_threshold, roc_df, idx= optimal_youden_index(fpr, tpr, thresholds,tp90=True)\n",
    "\n",
    "#plotting roc\n",
    "plot_roc(fpr, tpr, roc_auc, roc_df, idx, save=False, model_name=ensemble2,folder_name=None, file_name='roc')\n",
    "plt.show(), plt.close()\n",
    "\n",
    "#printing npv, recall, precision, accuracy\n",
    "npv=confusion_matrix(y_test, y_pred)[0,0]/sum(np.array(y_pred)==0)*100\n",
    "prec= precision_score(y_true=y_test, y_pred= y_pred, pos_label=pos_label)*100\n",
    "recall= recall_score(y_true=y_test, y_pred= y_pred, pos_label=pos_label)*100\n",
    "f1= f1_score(y_true=y_test, y_pred= y_pred, pos_label=pos_label)*100\n",
    "acc=accuracy_score(y_test, y_pred)*100\n",
    "\n",
    "print(\"npv:\", npv,'\\n')\n",
    "print(\"prec:\", prec,'\\n')\n",
    "print(\"recall:\", recall,'\\n')\n",
    "print(\"f1:\", f1,'\\n')\n",
    "print(\"acc:\", acc,'\\n')\n",
    "\n",
    "hard_vote_summary={'model':\"hard_voting_classifier\",'auc':acc, 'precision':prec, 'recall':recall, 'f1':f1, 'npv':npv}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_eval= classifier_eval(ensemble, x=np.array(x_test), y=y_test, save=True, model_name='model_ensemble', folder_name='clinical_agg_elix72')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "compute_class_weight('balanced', np.unique(y), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_eval(gnb, x=x_test, y=y_test)\n",
    "test_summary_df= pd.DataFrame([rf_eval,\n",
    "                             logreg_eval,\n",
    "                             xgboost_eval,\n",
    "                             svc_eval,\n",
    "                            ensemble_eval])\n",
    "test_summary_df.set_index('model').round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variable importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveplot(figure_name,folder_name=None):\n",
    "    \"\"\"\n",
    "    simple function for saving plots\n",
    "    \"\"\"\n",
    "    if folder_name != None:\n",
    "        address = 'figures/{}/'.format(folder_name)\n",
    "    else:\n",
    "        address = 'figures/'\n",
    "    if not os.path.exists(address):\n",
    "        os.makedirs(address)\n",
    "    plt.savefig(address+\"/{}.png\".format(figure_name),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_imp(model,folder_name,model_name, n_var=4, save=True):\n",
    "    model_name=type(model).__name__\n",
    "    plot_title= \"Top {} {} {} Variable Importance\".format(n_var, folder_name,model_name)\n",
    "    feat_importances = pd.Series(model.pipeline.predict_proba(x_train), index=x_train.columns)\n",
    "    topn=feat_importances.nlargest(n_var).sort_values()\n",
    "    ax=topn.plot(kind='barh', x='doop', title=plot_title)#.xlabel(\"xlab\")\n",
    "    ax.set_xlabel(\"Variable Importance\")\n",
    "    if save==True:\n",
    "        saveplot(figure_name=plot_title, folder_name=folder_name)\n",
    "    return(topn)\n",
    "\n",
    "#     ###\n",
    "#     imp= model.feature_importances_\n",
    "#     var_index=[ x for x in range(0,len(rf.feature_importances_))]\n",
    "#     variables=list(x_train)\n",
    "#     return(pd.DataFrame({\"imp\":imp, 'index':var_index, 'variable': variables}).sort_values('imp', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#var_imp(rf,plot_title='RF_' n_var=4)\n",
    "#var_imp(rf,\"clinical_agg\",\"RF\", n_var=6, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp(rf,\"clinical_agg_elix\",\"RF\", n_var=20, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp(xgboost2,\"clinical_agg\",\"xgboost\", n_var=10, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_imp(xgboost,\"clinical_agg_elix_72\",\"xgboost\", n_var=10, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_summary_df['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train),len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import model_selection\n",
    "\n",
    "# save the model to disk\n",
    "model_list=[rf,logreg, xgboost,svc ]\n",
    "for element in model_list:#test_summary_df['model']:\n",
    "    filename = 'models/{}_{}_{}.sav'.format(date,dataset,type(element).__name__)\n",
    "    #os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "    pickle.dump(element, open(filename, 'wb'))\n",
    "    \n",
    "    \n",
    "# xgboost = reset_model('xgboost')\n",
    "# xgboost.fit(x, y)\n",
    "\n",
    "# logreg = reset_model('logreg')\n",
    "# logreg.fit(x, y)\n",
    "\n",
    "# rf= reset_model('rf')\n",
    "# rf.fit(x,y)\n",
    "\n",
    "# # from sklearn.naive_bayes import GaussianNB\n",
    "# # gnb =GaussianNB()\n",
    "# # nb_y_pred = gnb.fit(x, y)\n",
    "\n",
    "# from sklearn import svm\n",
    "# svc= reset_model('svc')\n",
    "# svc.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#$dataset= \"clinagg_elix\"\n",
    "filename\n",
    "os.path.exists(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import model_selection\n",
    "\n",
    "# save the model to disk\n",
    "model_list=[rf,logreg, xgboost,svc ]\n",
    "for element in model_list:#test_summary_df['model']:  \n",
    "    filename = 'models/{}_{}_{}.sav'.format(date,dataset,type(element).__name__)\n",
    "    pickle.dump(element, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tSNE visualization\n",
    "* 5-29-19 changes: changed x_full to x_train, ie dimension reduction will be performed on train set since grower samples will only come from train set (since all_xy is made from trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_filter(df):   \n",
    "    #global all_xy\n",
    "    categorical=['gender',\n",
    "     'ethnicity_black',\n",
    "     'ethnicity_hispanic',\n",
    "     'ethnicity_unknown/other',\n",
    "     'ethnicity_white/nonhispanic',\n",
    "     'ibands_absent',\n",
    "     'any_vasoactive_True',\n",
    "     'leukocyte_1',\n",
    "     'nitrite_1',\n",
    "     'pao2fio2ratio(200, 333]',\n",
    "     'pao2fio2ratio_(333, 475]',\n",
    "     'pao2fio2ratio_(475, 3000]',\n",
    "     'vent_recieved_1',\n",
    "     'vent_recieved_2',\n",
    "     'dobutamine_True',\n",
    "     'dopamine_True',\n",
    "     'epinephrine_True',\n",
    "     'norepinephrine_True',\n",
    "     'phenylephrine_True',\n",
    "     'rrt_True',\n",
    "     'vasopressin_True',\n",
    "     'ipco2_absent',\n",
    "     \"cancer_elix_True\"]\n",
    "    all_xy_label= list(all_xy)\n",
    "    in_both= list(set(categorical)& set(all_xy))\n",
    "\n",
    "    ##restricting all_xy to only continuous variables\n",
    "    all_xy_cont = df.drop(in_both, axis=1)\n",
    "    return(all_xy_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveplot(figure_name,folder_name=None):\n",
    "    \"\"\"\n",
    "    simple function for saving plots\n",
    "    \"\"\"\n",
    "    if folder_name != None:\n",
    "        address = 'figures/{}/'.format(folder_name)\n",
    "    else:\n",
    "        address = 'figures/'\n",
    "    if not os.path.exists(address):\n",
    "        os.makedirs(address)\n",
    "    plt.savefig(address+\"/{}.png\".format(figure_name),bbox_inches='tight')\n",
    "    #plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataprep\n",
    "####### 5-29-19: changed this here for an easy fix and to realign the dimension reduction to be only on train data\n",
    "x_full=x_train.copy()#pd.concat([x_train,x_test]) \n",
    "#x_full=pd.concat([x_train,x_test]) \n",
    "icu_full= z_icustay_id.copy()#icu_full= pd.concat([z_icustay_id,z_icustay_id_test])\n",
    "y_full=pd.DataFrame(y_train)#pd.concat([pd.DataFrame(y_train), pd.DataFrame(y_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "time_start = time.time()\n",
    "pca = PCA(n_components=4)\n",
    "#continuous_filter(x_train)\n",
    "pca_result = pca.fit_transform(continuous_filter(x_train)) #x_train\n",
    "\n",
    "print('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "pca_df = pd.DataFrame(columns = ['pca1','pca2','pca3','pca4'])\n",
    "pca_df['pca1'] = pca_result[:,0]\n",
    "pca_df['pca2'] = pca_result[:,1]\n",
    "pca_df['pca3'] = pca_result[:,2]\n",
    "pca_df['pca4'] = pca_result[:,3]\n",
    "\n",
    "print ('Variance explained per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA plot and grower labeling\n",
    "* what is a good m value?\n",
    "* do patients with different profiles: index 1 and 3457 differ in their grower samples on tsne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m=50\n",
    "# loc_sample=z_icustay_id[1]\n",
    "# grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "# pca_df['y']= y_full.values\n",
    "\n",
    "# ##added to color grower\n",
    "# pd.DataFrame(pca_df)['icustay_id']=icu_full.values\n",
    "# pca_df['grower']=pca_df['icustay_id'].isin(list(grower_samples))\n",
    "# pca_df['sample']=pca_df['icustay_id']==(testing_sample_icu)\n",
    "\n",
    "# pal = sns.dark_palette(\"palegreen\", as_cmap=True)\n",
    "# plt.figure(figsize=(16,10))\n",
    "# # sns.scatterplot(x=\"pca1\",\n",
    "# #                 y=\"pca2\",\n",
    "# #                 hue='grower',\n",
    "# #                 size='grower',\n",
    "# #                 sizes=[25, 25],\n",
    "# #                 style='y',\n",
    "# #                 palette=sns.color_palette(n_colors=2, desat=0.9),\n",
    "# #                 data=pca_df,\n",
    "# #                 legend=\"full\",\n",
    "# #                 alpha=[0.8,0.6]\n",
    "# # )\n",
    "\n",
    "# ax= sns.scatterplot(x=\"pca1\",\n",
    "#                 y=\"pca2\",\n",
    "#                 data= pca_df[pca_df.grower==True],\n",
    "#                 #hue='y',\n",
    "# #                 size='grower',\n",
    "# #                 sizes=[15, 50],\n",
    "# #                 style='y',\n",
    "#                 palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "#                 alpha=1,\n",
    "#                 legend=\"full\",\n",
    "# #                 alpha=[0.8,0.6]\n",
    "# )\n",
    "\n",
    "# sns.scatterplot(x=\"pca1\",\n",
    "#                 y=\"pca2\",\n",
    "#                 data= pca_df[pca_df.grower==False],\n",
    "#                 alpha=0.2,\n",
    "#                 #hue='y',\n",
    "#                 #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "#                 legend='full',\n",
    "#                 ax=ax)\n",
    "\n",
    "# # sns.scatterplot(x=\"pca1\",\n",
    "# #                 y=\"pca2\",\n",
    "# #                 data= pca_df[pca_df.grower==False],\n",
    "# #                 alpha=0.1,\n",
    "# #                 hue='y',\n",
    "# #                 palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "# #                 #legend='full',\n",
    "# #                 ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df['y']= y_full.values\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                hue='y',\n",
    "                data= pca_df,#[pca_df.grower==False],\n",
    "                alpha=0.7)\n",
    "\n",
    "ax.set_title('global training PCA of pos vs neg patients')\n",
    "saveplot(figure_name='global_training_PCA', folder_name='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## pcaplot and grower labeling  [different style]\n",
    "# m=100\n",
    "# loc_sample=z_icustay_id[3457]\n",
    "# grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "# pca_df['y']= y_full.values\n",
    "\n",
    "# ##added to color grower\n",
    "# pd.DataFrame(pca_df)['icustay_id']=icu_full.values\n",
    "# pca_df['grower']=pca_df['icustay_id'].isin(list(grower_samples))\n",
    "# pca_df['sample']=pca_df['icustay_id']==(testing_sample_icu)\n",
    "\n",
    "# plt.figure(figsize=(16,10))\n",
    "# sns.scatterplot(x=\"pca1\",\n",
    "#                 y=\"pca2\",\n",
    "#                 hue='grower',\n",
    "#                 size='grower',\n",
    "#                 sizes=[15, 80],\n",
    "#                 #style='grower',\n",
    "#                 #palette=sns.color_palette(\"hls\", 2),\n",
    "#                 data=pca_df,\n",
    "#                 legend=\"full\",\n",
    "#                 alpha=0.6\n",
    "# )\n",
    "\n",
    "# ax.set_title('PCA of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "# ax.set(xlabel='PCA1 ({:.2f}% variance)'.format(pca.explained_variance_ratio_[:1][0]), ylabel='PCA2({:.2f}% variance)'.format(pca.explained_variance_ratio_[1:2][0]))\n",
    "# saveplot(figure_name='local_training_PCA_m{}_icu{}'.format(m,index), folder_name='tsne')\n",
    "\n",
    "## pcaplot and grower labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and grower labeling\n",
    "m=100\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "pca_df['y']= y_full.values\n",
    "\n",
    "##added to color grower\n",
    "pd.DataFrame(pca_df)['icustay_id']=icu_full.values\n",
    "pca_df['grower']=pca_df['icustay_id'].isin(list(grower_samples))\n",
    "pca_df['sample']=pca_df['icustay_id']==(testing_sample_icu)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                style=\"y\",\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('PCA of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "ax.set(xlabel='PCA1 ({:.2f}% variance)'.format(pca.explained_variance_ratio_[:1][0]), ylabel='PCA2({:.2f}% variance)'.format(pca.explained_variance_ratio_[1:2][0]))\n",
    "\n",
    "saveplot(figure_name='local_training_PCA_m{}_icu{}'.format(m,index), folder_name='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and grower labeling\n",
    "m=100\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "pca_df['y']= y_full.values\n",
    "\n",
    "##added to color grower\n",
    "pd.DataFrame(pca_df)['icustay_id']=icu_full.values\n",
    "pca_df['grower']=pca_df['icustay_id'].isin(list(grower_samples))\n",
    "#pca_df['sample']=pca_df['icustay_id']==(testing_sample_icu)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                style=\"y\",\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('PCA of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "ax.set(xlabel='PCA1 ({:.2f}% variance)'.format(pca.explained_variance_ratio_[:1][0]), ylabel='PCA2({:.2f}% variance)'.format(pca.explained_variance_ratio_[1:2][0]))\n",
    "\n",
    "saveplot(figure_name='local_training_PCA_m{}_icu{}_allcont'.format(m,index), folder_name='PCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and grower labeling\n",
    "m=100\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "euc_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "pca_df['y']= y_full.values\n",
    "\n",
    "\n",
    "##added to color grower\n",
    "pd.DataFrame(pca_df)['icustay_id']=icu_full.values\n",
    "pca_df['euc']=pca_df['icustay_id'].isin(list(euc_samples))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.euc==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                data=pca_df[pca_df.euc==False],\n",
    "                alpha=0.1,\n",
    "                style=\"y\",\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax1.set_title('PCA of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "ax1.set(xlabel='PCA1 ({:.2f}% variance)'.format(pca.explained_variance_ratio_[:1][0]), ylabel='PCA2({:.2f}% variance)'.format(pca.explained_variance_ratio_[1:2][0]))\n",
    "\n",
    "saveplot(figure_name='euc_training_PCA_m{}_icu{}_allcont'.format(m,index), folder_name='PCA')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tSNE plot and grower labeling\n",
    "* what is a good m value?\n",
    "* do patients with different profiles: index 1 and 3457 differ in their grower samples on tsne?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TSNE fit, run once\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=500)\n",
    "tsne_results = tsne.fit_transform(continuous_filter(x_train))#x_full)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##plotting all trainset labeling y==true, y==false. \n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax= sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                hue='y',\n",
    "                data=tsne_df,\n",
    "                legend=\"full\",\n",
    "                alpha=0.7\n",
    ")\n",
    "\n",
    "ax.set_title('global training t-SNE of pos vs neg patients')\n",
    "\n",
    "#saveplot(figure_name='global_training_tsne', folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=100 tsne w patient at index 1: a y=0 patient and gender=1\n",
    "m=100\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "\n",
    "#saveplot(figure_name='local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=100 tsne w patient at index 3457: a y=1 patient and gender=0\n",
    "m=100\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "#saveplot(figure_name='local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####duplcicate plot with different style\n",
    "#m=100 tsne w patient at index 3457: a y=1 patient and gender=0\n",
    "# m=100\n",
    "# loc_sample=z_icustay_id[3457]\n",
    "# grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "\n",
    "# tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "# tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "# tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "# tsne_df['y']= y_full.values\n",
    "# ##added to color grower\n",
    "# pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "# tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "# tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "# plt.figure(figsize=(16,10))\n",
    "# sns.scatterplot(x=\"tsne-2d-one\",\n",
    "#                 y=\"tsne-2d-two\",\n",
    "#                 hue='grower',\n",
    "#                 size='grower',\n",
    "#                 sizes=[30, 100],\n",
    "#                 style='y',\n",
    "#                 #palette=sns.color_palette(\"hls\", 2),\n",
    "#                 data=tsne_df,\n",
    "#                 legend=\"full\",\n",
    "#                 alpha=0.7\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=250 tsne w patient at index 1 \n",
    "m=250\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='gower_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=250 tsne w patient at index 3457\n",
    "m=250\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='gower_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=50 tsne w patient at index 1\n",
    "m=50\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='gower_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m=50 tsne w patient at index 3457\n",
    "m=50\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.grower==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='gower_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and euclidean labeling\n",
    "m=100\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "euc_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "\n",
    "#grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['euc']=tsne_df['icustay_id'].isin(list(euc_samples))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='euc_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and euclidean labeling\n",
    "m=100\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "euc_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "\n",
    "#grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['euc']=tsne_df['icustay_id'].isin(list(euc_samples))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='euc_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and euclidean labeling\n",
    "m=250\n",
    "index=1\n",
    "loc_sample=z_icustay_id[index]\n",
    "euc_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "\n",
    "#grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['euc']=tsne_df['icustay_id'].isin(list(euc_samples))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='euc_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and euclidean labeling\n",
    "m=250\n",
    "index=3457\n",
    "loc_sample=z_icustay_id[index]\n",
    "euc_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "\n",
    "#grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full.values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full.values\n",
    "tsne_df['euc']=tsne_df['icustay_id'].isin(list(euc_samples))\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "ax=sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==True],\n",
    "                style=\"y\",\n",
    "                size=\"y\",\n",
    "                sizes=[80,80],\n",
    "                palette=sns.color_palette(\"Set2\", n_colors=1, desat=.2),#sns.color_palette(sns.hls_palette(2, l=.3, s=.9)),#\"hls\",n_colors=2, desat=0.9),\n",
    "                alpha=1,\n",
    "                legend=\"full\"\n",
    ")\n",
    "\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                data=tsne_df[tsne_df.euc==False],\n",
    "                alpha=0.2,\n",
    "                #hue='y',\n",
    "                #palette=sns.color_palette(sns.color_palette(\"Set1\", n_colors=2, desat=.9)),#sns.color_palette(sns.hls_palette(2, l=.5, s=.9)),#sns.color_palette(\"hls\",n_colors=2, desat=0.8),\n",
    "                legend='full',\n",
    "                ax=ax)\n",
    "\n",
    "ax.set_title('t-SNE of m={} gower closest ICU stay vs rest for icu_index={}'.format(m,index))\n",
    "saveplot(figure_name='euc_local_training_tsne_m{}_icu{}'.format(m,index), folder_name='tsne')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## takeaway: the two patients do have similar tsne, however patient at index 1 is more dispersed across the reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problem, currently select_train_samples are all producing the same m*2 cases regardless of the sample being input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=10\n",
    "loc_sample=z_icustay_id[1]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "grower_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=10\n",
    "loc_sample=z_icustay_id[3457]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "grower_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## flip the script, perform a pca and tsne on only the grower samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5/23/19 \n",
    "need to redo with only focusing on continuous variables for tsne and pca both (1) dimension reduction -> subset   and (2) subset -> dimension reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pcaplot and gower labeling\n",
    "m=50\n",
    "loc_sample=z_icustay_id[3457]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "\n",
    "\n",
    "##PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "time_start = time.time()\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "##limiting xfull to just grower_samples\n",
    "grower_index=icu_full.isin(grower_samples) \n",
    "\n",
    "pca_result = pca.fit_transform(x_full[grower_index])\n",
    "\n",
    "print('PCA done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "pca_df = pd.DataFrame(columns = ['pca1','pca2','pca3','pca4'])\n",
    "pca_df['pca1'] = pca_result[:,0]\n",
    "pca_df['pca2'] = pca_result[:,1]\n",
    "pca_df['pca3'] = pca_result[:,2]\n",
    "pca_df['pca4'] = pca_result[:,3]\n",
    "\n",
    "print ('Variance explained per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "# ## pcaplot and grower labeling\n",
    "pca_df['y']= y_full[grower_index].values\n",
    "\n",
    "##added to color grower\n",
    "pd.DataFrame(pca_df)['icustay_id']=icu_full[grower_index].values\n",
    "pca_df['grower']=pca_df['icustay_id'].isin(list(grower_samples))\n",
    "pca_df['sample']=pca_df['icustay_id']==(testing_sample_icu)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(x=\"pca1\",\n",
    "                y=\"pca2\",\n",
    "                hue='y',\n",
    "                #size='grower',\n",
    "                #sizes=[30, 70],\n",
    "                #style='grower',\n",
    "                #palette=sns.color_palette(\"hls\", 2),\n",
    "                data=pca_df,\n",
    "                legend=\"full\",\n",
    "                alpha=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## pcaplot and gower labeling\n",
    "m=50\n",
    "loc_sample=z_icustay_id[3457]\n",
    "grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "\n",
    "##limiting xfull to just grower_samples\n",
    "grower_index=icu_full.isin(grower_samples) \n",
    "\n",
    "##TSNE fit\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "tsne_results = tsne.fit_transform(x_full[grower_index])\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "\n",
    "\n",
    "tsne_df = pd.DataFrame(columns = ['tsne-2d-one','tsne-2d-two'])\n",
    "tsne_df['tsne-2d-one'] = tsne_results[:,0]\n",
    "tsne_df['tsne-2d-two'] = tsne_results[:,1]\n",
    "tsne_df['y']= y_full[grower_index].values\n",
    "##added to color grower\n",
    "pd.DataFrame(tsne_df)['icustay_id']=icu_full[grower_index].values\n",
    "tsne_df['grower']=tsne_df['icustay_id'].isin(list(grower_samples))\n",
    "tsne_df['sample']=tsne_df['icustay_id']==(loc_sample)\n",
    "\n",
    "plt.figure(figsize=(16,10))\n",
    "sns.scatterplot(x=\"tsne-2d-one\",\n",
    "                y=\"tsne-2d-two\",\n",
    "                hue='y',\n",
    "                data=tsne_df,\n",
    "                legend=\"full\",\n",
    "                alpha=0.7\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5-29-19: \n",
    "\n",
    "### issue: tsne not in agreement with grower distance labeling. need to investigate\n",
    "* Debug my t-sne visualization w/ grower labeling\n",
    " * T-sne plot on only continuous variables\n",
    "* Debug my grower distance:\n",
    " * Grower can be an ensemble of distance:\n",
    "  *  IE: Euclidian for continuous, count diff for categorical.\n",
    "todo:\n",
    "* How is it computing for continuous vs categorical?\n",
    "* Maybe define own distance metric?\n",
    "* Hamming distance? Can look into lots of different distance metrics. \n",
    "* Can look into R package for grower distance. *probably fastest starting point for looking at other possibilities. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## local model testing\n",
    "*<del> step1) hypertune xgb on 5fold cv.\n",
    "\n",
    "*<del> step2) test entire trainset and predict trainset.\n",
    "    \n",
    "*<del> step3) run hypertuned model on 5fold cv with lr and get overall metrics.\n",
    "* step4) local model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_icustay_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_split_training(m=250, n_sfk_split=5):\n",
    "       \n",
    "    #######\n",
    "    skf = StratifiedKFold(n_splits=n_sfk_split) #Stratified K-Folds cross-validator\n",
    "    num_fold = 0\n",
    "    \n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        X_train_0, X_test_0 = x[train_index], x[test_index] #assigning x_train and x_test sets within this cv fold\n",
    "        y_train_0, y_test_0 = y[train_index], y[test_index] #assigning y_train and y_test sets within this cv fold\n",
    "    \n",
    "    #######\n",
    "\n",
    "        num_fold = num_fold + 1 ##silly to keep but it's from the loop\n",
    "        print('this is the results of the {} fold in 5 folds:'.format(num_fold)) \n",
    "\n",
    "        print('the number of testing samples in this fold:', test_index.size)\n",
    "\n",
    "        train_z_icustay_id = z_icustay_id[train_index] # the icustay_id of samples in training set from 5 fold\n",
    "        test_z_icustay_id = z_icustay_id[test_index] # the icustay_id of samples in testing set from 5 fold\n",
    "\n",
    "        xg_one_fold_pred = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "        xg_one_fold_proba = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "        lr_one_fold_pred = [] # obtain the pred label of testing samples for one fold using lr\n",
    "        lr_one_fold_proba = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "        ######\n",
    "    \n",
    "        indicator_time = 0 # the indicator\n",
    "        for i, j in zip(test_z_icustay_id, test_index):  #looping through the zipped indicies of the test indicies/test icustay_id\n",
    "\n",
    "            testing_sample_id = i #numerical index of first 1/2 of data ##??? this seems to be instead the    \n",
    "            all_xy_0 = all_xy.loc[train_z_icustay_id] # select all TRAINING samples from  the current fold using icustay_id index\n",
    "            all_xy_training = all_xy_0.append(all_xy.loc[i]) # append the current ith testing sample to the training set. \n",
    "\n",
    "            ###important parameter. was at 400, i changed to X\n",
    "            m = m  # m is the number of similar cases or similar controls\n",
    "\n",
    "            X_test_00 = x[j]\n",
    "            y_test = y[j]\n",
    "\n",
    "            X_test = X_test_00.reshape(1, -1)\n",
    "\n",
    "            # print 'start selecting......'\n",
    "\n",
    "            Id_train_set = select_train_samples(testing_sample_id, all_xy_training, m, time_interval)  #  individulization\n",
    "\n",
    "            ix = np.isin(z_icustay_id, Id_train_set)\n",
    "            Id_train_set_index = list(np.where(ix))\n",
    "\n",
    "            # Id_train_set_index = np.argwhere(z_icustay_id == Id_train_set)\n",
    "\n",
    "            X_train = x[Id_train_set_index]\n",
    "            y_train = y[Id_train_set_index]\n",
    "\n",
    "            #print('start training......')\n",
    "\n",
    "            # scoring = 'roc_auc'\n",
    "\n",
    "        # xgboost\n",
    "        \n",
    "            #hyper parameter tuning F1 from gridsearchCV on 5cv:{'learning_rate': 0.1, 'max_depth': 5, 'scale_pos_weight': 5}\n",
    "            #hyper parameter tuning F1_macro from gridsearchCV on 5cv:{'learning_rate': 0.1, 'max_depth': 4, 'scale_pos_weight': 1}\n",
    "            #hyper parameter tuning recall_macro from gridsearchCV on 5cv:{'learning_rate': 0.1, 'max_depth': 5, 'scale_pos_weight': 5}\n",
    "            #hyper parameter tuning neg_log_loss from gridsearchCV on 5cv:{'learning_rate': 0.1, 'max_depth': 2, 'scale_pos_weight': 1}\n",
    "\n",
    "\n",
    "#             xgboost_mod = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=2,\n",
    "#                           min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#                           objective='binary:logistic', nthread=-1, scale_pos_weight=1, seed=27)\n",
    "            xgboost_mod= reset_model('xgboost')\n",
    "            xgboost_mod.fit(x[Id_train_set_index], y[Id_train_set_index])\n",
    "            xg_y_pred = xgboost_mod.predict(X_test)\n",
    "            xg_y_pred_proba = xgboost_mod.predict_proba(X_test)[:,1]\n",
    "\n",
    "            xg_one_fold_pred.append(xg_y_pred)\n",
    "            xg_one_fold_proba.append(xg_y_pred_proba)\n",
    "\n",
    "        # lr \n",
    "\n",
    "            logreg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "                                        intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "            logreg.fit(x[Id_train_set_index], y[Id_train_set_index])\n",
    "            lr_y_pred = logreg.predict(X_test)\n",
    "            lr_y_pred_proba = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "            lr_one_fold_pred.append(lr_y_pred)\n",
    "            lr_one_fold_proba.append(lr_y_pred_proba)\n",
    "\n",
    "            indicator_time = indicator_time + 1\n",
    "            # print 'the next testing sample and total samples:', indicator_time, test_index.size\n",
    "\n",
    "        xg_y_individual_pred = np.array(xg_one_fold_pred)\n",
    "        xg_y_individual_proba = np.array(xg_one_fold_proba)\n",
    "\n",
    "        lr_y_individual_pred = np.array(lr_one_fold_pred)\n",
    "        lr_y_individual_proba = np.array(lr_one_fold_proba)\n",
    "\n",
    "        one_fold_y_test = y[test_index]\n",
    "\n",
    "        print ('---------new fold---------------')\n",
    "        print ('**** result of non-individual predictor using xgboost:')\n",
    "        print ('the Accuracy of one fold:', accuracy_score(y[test_index], xg_y_individual_pred))\n",
    "        print ('the AUC of one fold:', roc_auc_score(y[test_index], xg_y_individual_pred))\n",
    "        print ('the classification_report :', classification_report(y[test_index], xg_y_individual_pred))\n",
    "        print(confusion_matrix(y[test_index], xg_y_individual_pred))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        print ('****this is the result of individual predictor using lr:')\n",
    "        print ('the Accuracy of one fold:', accuracy_score(y[test_index], lr_y_individual_pred))\n",
    "        print ('the AUC of one fold:', roc_auc_score(y[test_index], lr_y_individual_pred))\n",
    "        print ('the classification_report :', classification_report(y[test_index], lr_y_individual_pred))\n",
    "        print(confusion_matrix(y[test_index], lr_y_individual_pred))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we have multiple models for each patient? if so how do we aggregate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_split_training(m=100,n_sfk_split=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single_split_training(m=500,n_sfk_split=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M=50 Gower Local Modeling on entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=50\n",
    "\n",
    "xg_fold_pred = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "xg_fold_proba = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "lr_fold_pred = [] # obtain the pred label of testing samples for one fold using lr\n",
    "lr_fold_proba = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "for i in range(0, len(z_icustay_id)):\n",
    "    if i%500==0:\n",
    "        print(\"iteration: \", i)\n",
    "        \n",
    "    loc_sample=z_icustay_id[i]\n",
    "    test_index= z_icustay_id.index[z_icustay_id==loc_sample].tolist()[0]\n",
    "    test_sample= x[test_index].reshape((1,-1))\n",
    "    \n",
    "    grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "    train_indices= z_icustay_id.index[z_icustay_id.isin(grower_samples)].tolist()\n",
    "    train_samples= x[train_indices].reshape((1,-1))\n",
    "   \n",
    "    # xgboost\n",
    "    xgboost_mod= reset_model('xgboost')\n",
    "    xgboost_mod.fit(x[train_indices], y[train_indices])\n",
    "    xg_y_pred = xgboost_mod.predict(test_sample)\n",
    "    xg_y_proba = xgboost_mod.predict_proba(test_sample)[:,1]\n",
    "    xg_fold_pred.append(xg_y_pred)\n",
    "    xg_fold_proba.append(xg_y_proba)\n",
    "\n",
    "    # lr \n",
    "    lr_mod= reset_model('logreg')\n",
    "    lr_mod.fit(x[train_indices], y[train_indices])\n",
    "    lr_y_pred = lr_mod.predict(test_sample)\n",
    "    lr_y_proba = lr_mod.predict_proba(test_sample)[:,1]\n",
    "    lr_fold_pred.append(lr_y_pred)\n",
    "    lr_fold_proba.append(lr_y_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(np.concatenate(xg_fold_proba), proba_input=True, x=x, y=y, save=False, model_name='local_xg', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(lr_fold_proba, proba_input=True, x=x, y=y, save=False, model_name='local_lr', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{'auc': 0.689467706613181,\n",
    " 'f1': 0.45111980092428017,\n",
    " 'model': 'local_xg',\n",
    " 'npv': 89.40397350993378,\n",
    " 'precision': 0.30007093875620716,\n",
    " 'recall': 0.9083750894774517}\n",
    "\n",
    "{'auc': 0.6868647100930566,\n",
    " 'f1': 0.43407917383820993,\n",
    " 'model': 'local_lr',\n",
    " 'npv': 86.71875,\n",
    " 'precision': 0.285746657602538,\n",
    " 'recall': 0.9026485325697924}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M=100 Gower Local Modeling on entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=100\n",
    "\n",
    "xg_fold_pred_g100 = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "xg_fold_proba_g100 = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "lr_fold_pred_g100 = [] # obtain the pred label of testing samples for one fold using lr\n",
    "lr_fold_proba_g100 = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "for i in range(0, len(z_icustay_id)):\n",
    "    if i%500==0:\n",
    "        print(\"iteration: \", i)        \n",
    "    loc_sample=z_icustay_id[i]\n",
    "    test_index= z_icustay_id.index[z_icustay_id==loc_sample].tolist()[0]\n",
    "    test_sample= x[test_index].reshape((1,-1))\n",
    "    \n",
    "    grower_samples=select_train_samples(loc_sample, all_xy, m, time_interval)\n",
    "    train_indices= z_icustay_id.index[z_icustay_id.isin(grower_samples)].tolist()\n",
    "    train_samples= x[train_indices].reshape((1,-1))  \n",
    "    # xgboost\n",
    "    xgboost_mod= reset_model('xgboost')\n",
    "    xgboost_mod.fit(x[train_indices], y[train_indices])\n",
    "    xg_y_pred = xgboost_mod.predict(test_sample)\n",
    "    xg_y_proba = xgboost_mod.predict_proba(test_sample)[:,1]\n",
    "    xg_fold_pred_g100.append(xg_y_pred)\n",
    "    xg_fold_proba_g100.append(xg_y_proba)\n",
    "    # lr \n",
    "    lr_mod= reset_model('logreg')\n",
    "    lr_mod.fit(x[train_indices], y[train_indices])\n",
    "    lr_y_pred = lr_mod.predict(test_sample)\n",
    "    lr_y_proba = lr_mod.predict_proba(test_sample)[:,1]\n",
    "    lr_fold_pred_g100.append(lr_y_pred)\n",
    "    lr_fold_proba_g100.append(lr_y_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(np.concatenate(xg_fold_proba_g100), proba_input=True, x=x, y=y, save=True, model_name='local_xg_g100', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(np.concatenate(lr_fold_proba_g100), proba_input=True, x=x, y=y, save=True, model_name='local_lr_g100', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# euclidean local method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=50\n",
    "\n",
    "xg_fold_pred2 = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "xg_fold_proba2 = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "lr_fold_pred2 = [] # obtain the pred label of testing samples for one fold using lr\n",
    "lr_fold_proba2 = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "for i in range(0, len(z_icustay_id)):\n",
    "    if i%1000==0:\n",
    "        print(\"iteration: \", i)\n",
    "        \n",
    "    loc_sample=z_icustay_id[i]\n",
    "    test_index= z_icustay_id.index[z_icustay_id==loc_sample].tolist()[0]\n",
    "    test_sample= x[test_index].reshape((1,-1))\n",
    "    \n",
    "    grower_samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "    train_indices= z_icustay_id.index[z_icustay_id.isin(grower_samples)].tolist()\n",
    "    train_samples= x[train_indices].reshape((1,-1))\n",
    "   \n",
    "    # xgboost\n",
    "    xgboost_mod= reset_model('xgboost')\n",
    "    xgboost_mod.fit(x[train_indices], y[train_indices])\n",
    "    xg_y_pred = xgboost_mod.predict(test_sample)\n",
    "    xg_y_proba = xgboost_mod.predict_proba(test_sample)[:,1]\n",
    "    xg_fold_pred2.append(xg_y_pred)\n",
    "    xg_fold_proba2.append(xg_y_proba)\n",
    "\n",
    "    # lr \n",
    "    lr_mod= reset_model('logreg')\n",
    "    lr_mod.fit(x[train_indices], y[train_indices])\n",
    "    lr_y_pred = lr_mod.predict(test_sample)\n",
    "    lr_y_proba = lr_mod.predict_proba(test_sample)[:,1]\n",
    "    lr_fold_pred2.append(lr_y_pred)\n",
    "    lr_fold_proba2.append(lr_y_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test#.loc[z_icustay_id_test[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in data saved from past night\n",
    "xg_fold_proba2=pd.read_csv(\"models/xg_fold_proba2.csv\") #two class training data\n",
    "lr_fold_proba2=pd.read_csv(\"models/lr_fold_proba2.csv\") #two class training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_fold_proba2['0'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(np.array(xg_fold_proba2['0']), proba_input=True, x=x, y=y, save=True, model_name='local_xg_euc', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_eval(np.array(lr_fold_proba2['0']), proba_input=True, x=x, y=y, save=True, model_name='local_lr_euc', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.concatenate(xg_fold_proba2)).to_csv('models/xg_fold_proba2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.concatenate(lr_fold_proba2)).to_csv('models/lr_fold_proba2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_gow_50={'auc': 0.689467706613181,\n",
    " 'f1': 0.45111980092428017,\n",
    " 'model': 'local_xg_g50',\n",
    " 'npv': 89.40397350993378,\n",
    " 'precision': 0.30007093875620716,\n",
    " 'recall': 0.9083750894774517}\n",
    "\n",
    "lr_gow_50={'auc': 0.6868647100930566,\n",
    " 'f1': 0.43407917383820993,\n",
    " 'model': 'local_lr_g50',\n",
    " 'npv': 86.71875,\n",
    " 'precision': 0.285746657602538,\n",
    " 'recall': 0.9026485325697924}\n",
    "\n",
    "xg_gow_100={'auc': 0.7206768216191698,\n",
    " 'f1': 0.45500542103361047,\n",
    " 'model': 'local_xg_g100',\n",
    " 'npv': 89.38461538461539,\n",
    " 'precision': 0.30432680686487795,\n",
    " 'recall': 0.9012168933428776}\n",
    "\n",
    "lr_gow_100={'auc': 0.6788229905667733,\n",
    " 'f1': 0.4141563786008231,\n",
    " 'model': 'local_lr_g100',\n",
    " 'npv': 81.68642951251647,\n",
    " 'precision': 0.2689183411714408,\n",
    " 'recall': 0.9005010737294202}\n",
    "\n",
    "xg_euc_50={'auc': 0.7570882088208821,\n",
    " 'f1': 0.4844170834936514,\n",
    " 'model': 'local_xg_euc',\n",
    " 'npv': 91.56479217603912,\n",
    " 'precision': 0.3312286240463036,\n",
    " 'recall': 0.9012168933428776}\n",
    "\n",
    "lr_euc_50={'auc': 0.6994438223349895,\n",
    " 'f1': 0.4324139112557821,\n",
    " 'model': 'local_lr_euc',\n",
    " 'npv': 86.45937813440321,\n",
    " 'precision': 0.2842342342342342,\n",
    " 'recall': 0.9033643521832498}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_eval(gnb, x=x_test, y=y_test)\n",
    "local_summary_df= pd.DataFrame([xg_gow_50,\n",
    "                             lr_gow_50,\n",
    "                             xg_gow_100,\n",
    "                             lr_gow_100,\n",
    "                              xg_euc_50,\n",
    "                              lr_euc_50])\n",
    "local_summary_df.set_index('model').round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local modeling on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)\n",
    "# number_of_elements = 1000\n",
    "# for i in range(number_of_elements):\n",
    "#     time.sleep(0.1) #Replace this with a real computation\n",
    "#     update_progress(i / number_of_elements)\n",
    "# update_progress(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_model(metric, m, test=True):\n",
    "    global all_xy, all_xy_test\n",
    "    xg_fold_proba = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "    lr_fold_proba = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "    ## adding block to accomidate training or test sample specified. \n",
    "    if test==False:\n",
    "        z_icustay= z_icustay_id\n",
    "        x= np.array(x_train.copy())\n",
    "    else:\n",
    "        z_icustay= z_icustay_id_test\n",
    "        x= np.array(x_test.copy())\n",
    "\n",
    "    for i in range(0, len(z_icustay)):\n",
    "        # establishing index and icustay of the specified testing sample\n",
    "        loc_sample=z_icustay[i]\n",
    "        test_index= z_icustay.index[z_icustay==loc_sample].tolist()[0]\n",
    "        test_sample= x[test_index].reshape((1,-1)) #sample to be predicted. \n",
    "\n",
    "        #adding test set sample to all_xy for calculating 2m closest training samples\n",
    "        if loc_sample in all_xy_test.index: #if trying to find distance of a sample in test set\n",
    "            all_xy=all_xy.append(all_xy_test.loc[loc_sample])\n",
    "\n",
    "        ###calc distance\n",
    "        if metric =='gower':\n",
    "            samples=select_train_samples(loc_sample, all_xy, m, time_interval)    \n",
    "        elif metric =='euclidean':\n",
    "            samples=m_distance_samples(loc_sample, all_xy, m, time_interval, metric='euclidean')\n",
    "\n",
    "        #removing test set sample to all_xy for calculating 2m closest training samples\n",
    "        if loc_sample in all_xy_test.index & all_xy.index: #if trying to find distance of a sample in test set\n",
    "            all_xy.drop(index=loc_sample, axis=1,inplace=True)\n",
    "\n",
    "        ##extracting out only the 2m closest samples to fit the model on. \n",
    "        train_indices= z_icustay_id.index[z_icustay_id.isin(samples)].tolist()\n",
    "        train_samples= np.array(x_train)[train_indices].reshape((1,-1))\n",
    "\n",
    "        # xgboost\n",
    "        xgboost_mod= reset_model('xgboost')\n",
    "        xgboost_mod.fit(np.array(x_train)[train_indices], y[train_indices])\n",
    "        xg_y_proba = xgboost_mod.predict_proba(test_sample)[:,1]\n",
    "        xg_fold_proba.append(xg_y_proba)\n",
    "\n",
    "        # lr \n",
    "        lr_mod= reset_model('logreg')\n",
    "        lr_mod.fit(np.array(x_train)[train_indices], y[train_indices])\n",
    "        lr_y_proba = lr_mod.predict_proba(test_sample)[:,1]\n",
    "        lr_fold_proba.append(lr_y_proba)\n",
    "        \n",
    "        update_progress(i / len(z_icustay))\n",
    "    update_progress(1)\n",
    "\n",
    "    return(xg_fold_proba, lr_fold_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_proba_euc_m50, lr_proba_euc_m50 = local_model(metric='euclidean', m=50, test=True) # works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_proba_euc_m100, lr_proba_euc_m100 = local_model(metric='euclidean', m=100, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_proba_gow_m50, lr_proba_gow_m50 = local_model(metric='gower', m=50, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_proba_gow_m100, lr_proba_gow_m100 = local_model(metric='gower', m=100, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.array(xg_proba_euc_m50)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_xg_euc_50=classifier_eval(np.array(xg_proba_euc_m50), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_xg_euc_50', folder_name='clinical_agg')\n",
    "local_lr_euc_50= classifier_eval(np.array(lr_proba_euc_m50), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_lr_euc_50', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_xg_euc_100=classifier_eval(np.array(xg_proba_euc_m100), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_xg_euc_100', folder_name='clinical_agg')\n",
    "local_lr_euc_100=classifier_eval(np.array(lr_proba_euc_m100), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_lr_euc_100', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_xg_gow_50=classifier_eval(np.array(xg_proba_gow_m50), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_xg_gow_50', folder_name='clinical_agg')\n",
    "local_lr_gow_50=classifier_eval(np.array(lr_proba_gow_m50), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_lr_gow_50', folder_name='clinical_agg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_xg_gow_100=classifier_eval(np.array(xg_proba_gow_m100), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_xg_gow_100', folder_name='clinical_agg')\n",
    "local_lr_gow_100=classifier_eval(np.array(lr_proba_gow_m100), proba_input=True, x=x_test, y=y_test, save=True, model_name='local_lr_gow_100', folder_name='clinical_agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier_eval(gnb, x=x_test, y=y_test)\n",
    "local_summary_df= pd.DataFrame([local_xg_euc_50,\n",
    "                             local_lr_euc_50,\n",
    "                             local_xg_euc_100,\n",
    "                             local_lr_euc_100,\n",
    "                              local_xg_gow_50,\n",
    "                              local_lr_gow_50,\n",
    "                               local_xg_gow_100,\n",
    "                               local_lr_gow_100])\n",
    "local_summary_df.set_index('model').round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.concatenate(xg_proba_euc_m50)).to_csv('models/xg_proba_euc_m50.csv')\n",
    "pd.DataFrame(np.concatenate(lr_proba_euc_m50)).to_csv('models/lr_proba_euc_m50.csv')\n",
    "pd.DataFrame(np.concatenate(xg_proba_euc_m100)).to_csv('models/xg_proba_euc_m100.csv')\n",
    "pd.DataFrame(np.concatenate(lr_proba_euc_m100)).to_csv('models/lr_proba_euc_m100.csv')\n",
    "pd.DataFrame(np.concatenate(xg_proba_gow_m50)).to_csv('models/xg_proba_gow_m50.csv')\n",
    "pd.DataFrame(np.concatenate(lr_proba_gow_m50)).to_csv('models/lr_proba_gow_m50.csv')\n",
    "pd.DataFrame(np.concatenate(xg_proba_gow_m100)).to_csv('models/xg_proba_gow_m100.csv')\n",
    "pd.DataFrame(np.concatenate(lr_proba_gow_m100)).to_csv('models/lr_proba_gow_m100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
