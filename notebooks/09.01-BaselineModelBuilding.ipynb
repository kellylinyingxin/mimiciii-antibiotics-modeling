{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# description\n",
    "\n",
    "sklearn modeling of the median imputed training data. note the preprocessing of data from 07.20-worst_case_model was performed in R (09.newagg2_preprocessing_med_impute.rmd). this eventually will be converted over to python, but for now works in r. \n",
    "\n",
    "preprocessing includes variable formatting (categorical to factor variables in r, train/test split, and median imputation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp'\", use \"location='/tmp'\" instead.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.metrics import classification_report\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 129 ms\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling') #use to change working directory\n",
    "wd= os.getcwd() #'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling'\n",
    "\n",
    "date=\"04042019\"\n",
    "final_pt_df2 = pd.read_csv(Path(wd + '/data/raw/csv/04042019_final_pt_df2_v.csv') , index_col=0) #only for patients with minimum vitals\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 91.9 ms\n"
     ]
    }
   ],
   "source": [
    "train_data= pd.read_csv(\"/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/models/imputation/04042019_newagg2_median_imputed_train.csv\") #two class training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light data reformatting for model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most data are already converted to median type zscores, however weight and admit age still need to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.356708826689592 4.499809670330265 4.200204952921578 0.29960471740868666\n",
      "time: 13 ms\n"
     ]
    }
   ],
   "source": [
    "weight_median=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).median()\n",
    "weight_quant1=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).quantile(0.25)#.between(train_data['col'].quantile(.25), df['col'].quantile(.75), inclusive=True)]\n",
    "weight_quant3=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"weight\"]+1).quantile(0.75)\n",
    "weight_iqr=weight_quant3-weight_quant1; weight_iqr\n",
    "print(weight_median,weight_quant3,weight_quant1, weight_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.194943760778217 4.367991089683742 3.9691119690666907 0.39887912061705144\n",
      "time: 37.4 ms\n"
     ]
    }
   ],
   "source": [
    "age_median=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]+1).median()\n",
    "age_quant1=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]+1).quantile(0.25)\n",
    "age_quant3=np.log(train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"first_admit_age\"]+1).quantile(0.75)\n",
    "age_iqr=age_quant3-age_quant1;\n",
    "print(age_median,age_quant3,age_quant1, age_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.4 ms\n"
     ]
    }
   ],
   "source": [
    "#converting to log scaled standardized data for age/weight\n",
    "train_data['weight']=train_data['weight'].apply(lambda x: (np.log(x+1)-weight_median)/weight_iqr)\n",
    "train_data['first_admit_age']=train_data['first_admit_age'].apply(lambda x: (np.log(x+1)-age_median)/age_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### onehot encoding categorical var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>amax_bun</th>\n",
       "      <th>amax_creatinine</th>\n",
       "      <th>amax_daily_sofa</th>\n",
       "      <th>amax_heartrate</th>\n",
       "      <th>amax_meanartpress</th>\n",
       "      <th>amax_platelet</th>\n",
       "      <th>amax_ptt</th>\n",
       "      <th>amax_sysbp</th>\n",
       "      <th>amax_temperature</th>\n",
       "      <th>...</th>\n",
       "      <th>any_vasoactive_False</th>\n",
       "      <th>any_vasoactive_True</th>\n",
       "      <th>leukocyte_False</th>\n",
       "      <th>leukocyte_True</th>\n",
       "      <th>pao2fio2Ratio_(0, 200]</th>\n",
       "      <th>pao2fio2Ratio_(200, 333]</th>\n",
       "      <th>pao2fio2Ratio_(333, 475]</th>\n",
       "      <th>pao2fio2Ratio_(475, 3000]</th>\n",
       "      <th>vent_recieved_False</th>\n",
       "      <th>vent_recieved_True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200012</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.077448</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>-0.076639</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>-0.022901</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200014</td>\n",
       "      <td>0.056406</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.263979</td>\n",
       "      <td>-0.067398</td>\n",
       "      <td>-0.030164</td>\n",
       "      <td>0.118889</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200033</td>\n",
       "      <td>-0.068362</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.125991</td>\n",
       "      <td>-0.061462</td>\n",
       "      <td>-0.034854</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200036</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.132424</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>-0.034114</td>\n",
       "      <td>0.105303</td>\n",
       "      <td>0.078839</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200059</td>\n",
       "      <td>0.287056</td>\n",
       "      <td>0.347655</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.127583</td>\n",
       "      <td>0.196365</td>\n",
       "      <td>0.085552</td>\n",
       "      <td>0.521840</td>\n",
       "      <td>0.139305</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200063</td>\n",
       "      <td>0.311484</td>\n",
       "      <td>0.780201</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.137417</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>-0.088158</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.103102</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>200078</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.120179</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.137576</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200091</td>\n",
       "      <td>0.125998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.034613</td>\n",
       "      <td>0.145733</td>\n",
       "      <td>-0.189289</td>\n",
       "      <td>0.057380</td>\n",
       "      <td>0.078839</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200099</td>\n",
       "      <td>0.146224</td>\n",
       "      <td>0.408760</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.055494</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200108</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.148804</td>\n",
       "      <td>0.156503</td>\n",
       "      <td>0.112900</td>\n",
       "      <td>0.028836</td>\n",
       "      <td>0.123729</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200116</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.047287</td>\n",
       "      <td>0.092352</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.102095</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>200141</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>0.210148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061926</td>\n",
       "      <td>0.166784</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200150</td>\n",
       "      <td>0.183238</td>\n",
       "      <td>0.524219</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>0.051241</td>\n",
       "      <td>-0.241932</td>\n",
       "      <td>0.252744</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>0.047160</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200188</td>\n",
       "      <td>-0.181044</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.132424</td>\n",
       "      <td>0.170334</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.267385</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>200215</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.099538</td>\n",
       "      <td>0.196365</td>\n",
       "      <td>0.157598</td>\n",
       "      <td>0.074359</td>\n",
       "      <td>0.057545</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>200231</td>\n",
       "      <td>0.224244</td>\n",
       "      <td>0.780201</td>\n",
       "      <td>0.953445</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>-0.218596</td>\n",
       "      <td>0.241361</td>\n",
       "      <td>0.049399</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200249</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.123071</td>\n",
       "      <td>0.091876</td>\n",
       "      <td>-0.074737</td>\n",
       "      <td>0.105574</td>\n",
       "      <td>0.061749</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>200265</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.112274</td>\n",
       "      <td>-0.089528</td>\n",
       "      <td>0.100420</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>200269</td>\n",
       "      <td>0.267443</td>\n",
       "      <td>0.408760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037873</td>\n",
       "      <td>0.089116</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>-0.078711</td>\n",
       "      <td>0.088026</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200312</td>\n",
       "      <td>-0.536462</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.053689</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.166440</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>0.093402</td>\n",
       "      <td>-0.006575</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>200325</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.179208</td>\n",
       "      <td>0.225530</td>\n",
       "      <td>0.125022</td>\n",
       "      <td>-0.015327</td>\n",
       "      <td>0.136256</td>\n",
       "      <td>0.102340</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>200328</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.189392</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.091876</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.103866</td>\n",
       "      <td>0.065666</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200349</td>\n",
       "      <td>0.498358</td>\n",
       "      <td>1.079914</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.114153</td>\n",
       "      <td>0.010559</td>\n",
       "      <td>0.039565</td>\n",
       "      <td>0.098681</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>200350</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.120179</td>\n",
       "      <td>0.079212</td>\n",
       "      <td>0.241639</td>\n",
       "      <td>0.004263</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200352</td>\n",
       "      <td>0.231856</td>\n",
       "      <td>1.685438</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>-0.034783</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>-0.042006</td>\n",
       "      <td>0.053501</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200361</td>\n",
       "      <td>-0.181044</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.059799</td>\n",
       "      <td>0.004238</td>\n",
       "      <td>-0.098217</td>\n",
       "      <td>-0.022099</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.065666</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>200398</td>\n",
       "      <td>-0.464272</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.102193</td>\n",
       "      <td>0.033752</td>\n",
       "      <td>0.129676</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>200399</td>\n",
       "      <td>0.267443</td>\n",
       "      <td>0.408760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.111126</td>\n",
       "      <td>0.152001</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>0.112307</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200417</td>\n",
       "      <td>0.660966</td>\n",
       "      <td>2.235843</td>\n",
       "      <td>0.660964</td>\n",
       "      <td>0.037873</td>\n",
       "      <td>0.104986</td>\n",
       "      <td>0.048070</td>\n",
       "      <td>0.072609</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>200439</td>\n",
       "      <td>0.081304</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.141888</td>\n",
       "      <td>0.161758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144037</td>\n",
       "      <td>0.075082</td>\n",
       "      <td>0.043589</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>299557</td>\n",
       "      <td>0.174374</td>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.137417</td>\n",
       "      <td>0.095307</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.152645</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>299593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.091435</td>\n",
       "      <td>0.089116</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.103696</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>299614</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.132424</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.047211</td>\n",
       "      <td>-0.014210</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>299629</td>\n",
       "      <td>0.260632</td>\n",
       "      <td>0.631709</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>0.105266</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>0.088026</td>\n",
       "      <td>0.133613</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>299630</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>2.325925</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.140818</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>299645</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151076</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>299654</td>\n",
       "      <td>0.411824</td>\n",
       "      <td>1.787638</td>\n",
       "      <td>1.043731</td>\n",
       "      <td>0.246092</td>\n",
       "      <td>0.324817</td>\n",
       "      <td>-0.192038</td>\n",
       "      <td>0.373279</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.123516</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>299655</td>\n",
       "      <td>0.529792</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.030723</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>-0.026575</td>\n",
       "      <td>0.041482</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.012767</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>299685</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>-0.027812</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>299695</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.041101</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.078289</td>\n",
       "      <td>-0.072111</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>299715</td>\n",
       "      <td>0.305548</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.223545</td>\n",
       "      <td>0.134597</td>\n",
       "      <td>-0.061462</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.091621</td>\n",
       "      <td>0.075411</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>299728</td>\n",
       "      <td>0.200269</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.193375</td>\n",
       "      <td>0.296670</td>\n",
       "      <td>-0.108998</td>\n",
       "      <td>0.473858</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.082385</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>299734</td>\n",
       "      <td>-0.068362</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.082546</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>0.244104</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>299736</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.065318</td>\n",
       "      <td>-0.069505</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>299751</td>\n",
       "      <td>0.311484</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>-0.099264</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>299765</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>-0.018116</td>\n",
       "      <td>-0.085433</td>\n",
       "      <td>0.105574</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>299767</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>299800</td>\n",
       "      <td>0.155882</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.076966</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>299806</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.096932</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>299826</td>\n",
       "      <td>0.274114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>-0.094746</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>299828</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>0.780201</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.080295</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>-0.103537</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>299832</td>\n",
       "      <td>0.299501</td>\n",
       "      <td>1.297662</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.054870</td>\n",
       "      <td>-0.192038</td>\n",
       "      <td>0.301125</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>299853</td>\n",
       "      <td>0.360513</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.091413</td>\n",
       "      <td>0.110639</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>299863</td>\n",
       "      <td>0.200269</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.729716</td>\n",
       "      <td>0.141888</td>\n",
       "      <td>0.125991</td>\n",
       "      <td>-0.081420</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>299883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.172936</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.054813</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>299888</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.080295</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>-0.051765</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.063709</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>299913</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.631709</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.112596</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>0.113523</td>\n",
       "      <td>-0.025534</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>299914</td>\n",
       "      <td>0.350242</td>\n",
       "      <td>2.641747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.089790</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>299917</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>-0.035398</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>0.071521</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>299995</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.050589</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>0.064529</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5432 rows  50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      icustay_id  amax_bun  amax_creatinine  amax_daily_sofa  amax_heartrate  \\\n",
       "0         200012  0.069095         0.076014        -0.500000        0.077448   \n",
       "1         200014  0.056406        -0.164150        -0.207519        0.021221   \n",
       "2         200033 -0.068362        -0.253202        -0.500000        0.122666   \n",
       "3         200036  0.136269         0.000000        -0.500000        0.132424   \n",
       "4         200059  0.287056         0.347655         0.403677        0.127583   \n",
       "5         200063  0.311484         0.780201         0.403677        0.085914   \n",
       "6         200078  0.015050         0.148492         0.160964        0.120179   \n",
       "7         200091  0.125998         0.000000         0.292481        0.034613   \n",
       "8         200099  0.146224         0.408760         0.160964        0.071674   \n",
       "9         200108  0.104422        -0.164150        -0.207519        0.148804   \n",
       "10        200116  0.136269         0.284055         0.160964       -0.047287   \n",
       "11        200141 -0.049870        -0.253202         0.160964        0.125134   \n",
       "12        200150  0.183238         0.524219         0.660964        0.083117   \n",
       "13        200188 -0.181044        -0.164150         0.000000        0.132424   \n",
       "14        200215  0.246564         0.284055         0.160964        0.099538   \n",
       "15        200231  0.224244         0.780201         0.953445        0.014305   \n",
       "16        200249 -0.087975        -0.253202        -1.000000        0.068747   \n",
       "17        200265 -0.155149        -0.253202        -0.500000        0.074574   \n",
       "18        200269  0.267443         0.408760         0.000000        0.037873   \n",
       "19        200312 -0.536462        -0.347655         0.160964        0.053689   \n",
       "20        200325  0.043199        -0.079914         0.000000        0.179208   \n",
       "21        200328  0.104422         0.347655        -0.500000        0.189392   \n",
       "22        200349  0.498358         1.079914         0.403677        0.044295   \n",
       "23        200350  0.165260        -0.253202        -0.207519        0.120179   \n",
       "24        200352  0.231856         1.685438         0.292481       -0.034783   \n",
       "25        200361 -0.181044        -0.253202         0.292481        0.059799   \n",
       "26        200398 -0.464272        -0.347655        -0.500000        0.102193   \n",
       "27        200399  0.267443         0.408760         0.000000        0.085914   \n",
       "28        200417  0.660966         2.235843         0.660964        0.037873   \n",
       "29        200439  0.081304         0.217747         0.160964        0.141888   \n",
       "...          ...       ...              ...              ...             ...   \n",
       "5402      299557  0.174374         0.467559         0.160964        0.074574   \n",
       "5403      299593  0.000000         0.217747         0.160964        0.091435   \n",
       "5404      299614 -0.209194        -0.448205        -0.207519        0.132424   \n",
       "5405      299629  0.260632         0.631709         0.160964        0.122666   \n",
       "5406      299630  0.456100         2.325925         0.292481       -0.011172   \n",
       "5407      299645  0.043199         0.076014         0.000000        0.151076   \n",
       "5408      299654  0.411824         1.787638         1.043731        0.246092   \n",
       "5409      299655  0.529792         0.871874         0.160964       -0.030723   \n",
       "5410      299685 -0.209194        -0.079914        -0.207519        0.014305   \n",
       "5411      299695  0.253675         0.000000        -0.500000        0.041101   \n",
       "5412      299715  0.305548         0.076014         0.903677        0.223545   \n",
       "5413      299728  0.200269         0.076014         0.903677        0.193375   \n",
       "5414      299734 -0.068362        -0.164150        -0.207519        0.014305   \n",
       "5415      299736 -0.155149        -0.079914         0.000000        0.170817   \n",
       "5416      299751  0.311484         0.284055         0.403677        0.130013   \n",
       "5417      299765  0.043199        -0.079914         0.000000        0.027988   \n",
       "5418      299767 -0.209194        -0.164150         0.160964        0.071674   \n",
       "5419      299800  0.155882         0.217747         0.160964        0.044295   \n",
       "5420      299806 -0.049870         0.467559         0.160964        0.139548   \n",
       "5421      299826  0.274114         0.000000         0.160964        0.085914   \n",
       "5422      299828  0.104422         0.780201         0.403677        0.080295   \n",
       "5423      299832  0.299501         1.297662         0.792481        0.017782   \n",
       "5424      299853  0.360513         0.148492         0.160964        0.056759   \n",
       "5425      299863  0.200269        -0.079914         0.729716        0.141888   \n",
       "5426      299883  0.000000         0.284055        -0.207519        0.172936   \n",
       "5427      299888 -0.049870        -0.079914         0.500000        0.080295   \n",
       "5428      299913  0.484876         0.631709         0.160964        0.112596   \n",
       "5429      299914  0.350242         2.641747         0.160964        0.047458   \n",
       "5430      299917 -0.405288        -0.253202        -0.500000        0.056759   \n",
       "5431      299995 -0.355418        -0.164150        -1.000000        0.050589   \n",
       "\n",
       "      amax_meanartpress  amax_platelet  amax_ptt  amax_sysbp  \\\n",
       "0              0.047571      -0.076639  0.012640   -0.022901   \n",
       "1              0.263979      -0.067398 -0.030164    0.118889   \n",
       "2              0.125991      -0.061462 -0.034854    0.084386   \n",
       "3              0.153843      -0.034114  0.105303    0.078839   \n",
       "4              0.196365       0.085552  0.521840    0.139305   \n",
       "5              0.137417       0.004289 -0.088158    0.080700   \n",
       "6              0.036308       0.137576  0.015733    0.002437   \n",
       "7              0.145733      -0.189289  0.057380    0.078839   \n",
       "8              0.101873      -0.052867 -0.055494    0.071275   \n",
       "9              0.156503       0.112900  0.028836    0.123729   \n",
       "10             0.092352      -0.052867 -0.102095    0.009628   \n",
       "11             0.210148       0.000000  0.061926    0.166784   \n",
       "12             0.051241      -0.241932  0.252744   -0.007435   \n",
       "13             0.170334       0.109119  0.267385    0.080700   \n",
       "14             0.196365       0.157598  0.074359    0.057545   \n",
       "15             0.072439      -0.218596  0.241361    0.049399   \n",
       "16             0.123071       0.091876 -0.074737    0.105574   \n",
       "17             0.095556       0.112274 -0.089528    0.100420   \n",
       "18             0.089116       0.009527 -0.078711    0.088026   \n",
       "19             0.114153       0.166440 -0.036036    0.093402   \n",
       "20             0.225530       0.125022 -0.015327    0.136256   \n",
       "21             0.118146       0.091876  0.206718    0.103866   \n",
       "22             0.114153       0.010559  0.039565    0.098681   \n",
       "23             0.079212       0.241639  0.004263    0.061535   \n",
       "24             0.043860       0.023519 -0.042006    0.053501   \n",
       "25             0.004238      -0.098217 -0.022099    0.009628   \n",
       "26             0.033752       0.129676  0.000000    0.007250   \n",
       "27             0.111126       0.152001 -0.024385    0.112307   \n",
       "28             0.104986       0.048070  0.072609    0.047327   \n",
       "29             0.161758       0.000000  0.144037    0.075082   \n",
       "...                 ...            ...       ...         ...   \n",
       "5402           0.137417       0.095307  0.014705    0.152645   \n",
       "5403           0.089116       0.068445  0.103696    0.007250   \n",
       "5404           0.069000       0.047211 -0.014210    0.041019   \n",
       "5405           0.172023       0.105266  0.058293    0.088026   \n",
       "5406           0.142984       0.022551  0.036670    0.140818   \n",
       "5407           0.095556       0.044613  0.024854    0.069353   \n",
       "5408           0.324817      -0.192038  0.373279    0.041019   \n",
       "5409           0.012554      -0.026575  0.041482    0.007250   \n",
       "5410           0.040106      -0.027812 -0.017570    0.021231   \n",
       "5411           0.118146       0.078289 -0.072111    0.084386   \n",
       "5412           0.134597      -0.061462 -0.017570    0.091621   \n",
       "5413           0.296670      -0.108998  0.473858    0.014325   \n",
       "5414           0.082546      -0.052867  0.244104    0.043137   \n",
       "5415           0.153843       0.065318 -0.069505    0.120511   \n",
       "5416           0.028580       0.046349 -0.099264    0.047327   \n",
       "5417           0.172023      -0.018116 -0.085433    0.105574   \n",
       "5418           0.101873      -0.008858  0.012640    0.071275   \n",
       "5419           0.098730       0.036616  0.012640    0.076966   \n",
       "5420           0.164355       0.081225  0.035700    0.096932   \n",
       "5421           0.040106      -0.094746  0.067307    0.036736   \n",
       "5422           0.047571      -0.103537  0.014705    0.011986   \n",
       "5423           0.054870      -0.192038  0.301125    0.027977   \n",
       "5424           0.164355       0.019618  0.091413    0.110639   \n",
       "5425           0.125991      -0.081420  0.048113    0.061535   \n",
       "5426           0.058460       0.054813  0.022847    0.027977   \n",
       "5427           0.098730       0.016643 -0.051765    0.041019   \n",
       "5428           0.072439       0.113523 -0.025534    0.071275   \n",
       "5429           0.032467       0.089790  0.015733    0.063509   \n",
       "5430           0.016634      -0.035398  0.012640   -0.028245   \n",
       "5431           0.072439       0.064529  0.012640    0.071275   \n",
       "\n",
       "      amax_temperature         ...          any_vasoactive_False  \\\n",
       "0             0.021964         ...                             1   \n",
       "1             0.003685         ...                             1   \n",
       "2             0.061749         ...                             0   \n",
       "3             0.015897         ...                             1   \n",
       "4             0.018327         ...                             0   \n",
       "5             0.103102         ...                             1   \n",
       "6             0.040008         ...                             0   \n",
       "7             0.034019         ...                             1   \n",
       "8             0.025994         ...                             1   \n",
       "9             0.028005         ...                             1   \n",
       "10            0.017923         ...                             0   \n",
       "11            0.003685         ...                             0   \n",
       "12            0.047160         ...                             1   \n",
       "13            0.032017         ...                             1   \n",
       "14            0.011838         ...                             1   \n",
       "15            0.007768         ...                             0   \n",
       "16            0.061749         ...                             1   \n",
       "17            0.081225         ...                             1   \n",
       "18            0.028005         ...                             0   \n",
       "19           -0.006575         ...                             1   \n",
       "20            0.102340         ...                             1   \n",
       "21            0.065666         ...                             1   \n",
       "22            0.015898         ...                             0   \n",
       "23            0.015898         ...                             1   \n",
       "24            0.011838         ...                             1   \n",
       "25            0.065666         ...                             1   \n",
       "26            0.003685         ...                             1   \n",
       "27           -0.002462         ...                             1   \n",
       "28            0.028005         ...                             1   \n",
       "29            0.043589         ...                             1   \n",
       "...                ...         ...                           ...   \n",
       "5402          0.043986         ...                             0   \n",
       "5403          0.068402         ...                             0   \n",
       "5404          0.015898         ...                             0   \n",
       "5405          0.133613         ...                             1   \n",
       "5406          0.001639         ...                             1   \n",
       "5407          0.000000         ...                             0   \n",
       "5408          0.123516         ...                             0   \n",
       "5409         -0.012767         ...                             1   \n",
       "5410          0.009804         ...                             1   \n",
       "5411          0.023980         ...                             1   \n",
       "5412          0.075411         ...                             0   \n",
       "5413          0.082385         ...                             0   \n",
       "5414          0.040008         ...                             0   \n",
       "5415          0.041998         ...                             1   \n",
       "5416          0.038014         ...                             0   \n",
       "5417          0.055853         ...                             1   \n",
       "5418          0.025994         ...                             1   \n",
       "5419          0.001639         ...                             1   \n",
       "5420          0.081225         ...                             1   \n",
       "5421         -0.000410         ...                             1   \n",
       "5422          0.007768         ...                             1   \n",
       "5423         -0.000410         ...                             1   \n",
       "5424          0.013869         ...                             1   \n",
       "5425          0.003685         ...                             0   \n",
       "5426         -0.008636         ...                             1   \n",
       "5427          0.063709         ...                             0   \n",
       "5428          0.017923         ...                             1   \n",
       "5429          0.009804         ...                             1   \n",
       "5430          0.071521         ...                             1   \n",
       "5431          0.034019         ...                             1   \n",
       "\n",
       "      any_vasoactive_True  leukocyte_False  leukocyte_True  \\\n",
       "0                       0                1               0   \n",
       "1                       0                1               0   \n",
       "2                       1                1               0   \n",
       "3                       0                1               0   \n",
       "4                       1                1               0   \n",
       "5                       0                1               0   \n",
       "6                       1                1               0   \n",
       "7                       0                1               0   \n",
       "8                       0                1               0   \n",
       "9                       0                1               0   \n",
       "10                      1                1               0   \n",
       "11                      1                1               0   \n",
       "12                      0                1               0   \n",
       "13                      0                1               0   \n",
       "14                      0                1               0   \n",
       "15                      1                1               0   \n",
       "16                      0                1               0   \n",
       "17                      0                1               0   \n",
       "18                      1                1               0   \n",
       "19                      0                1               0   \n",
       "20                      0                1               0   \n",
       "21                      0                1               0   \n",
       "22                      1                1               0   \n",
       "23                      0                1               0   \n",
       "24                      0                0               1   \n",
       "25                      0                1               0   \n",
       "26                      0                0               1   \n",
       "27                      0                1               0   \n",
       "28                      0                1               0   \n",
       "29                      0                1               0   \n",
       "...                   ...              ...             ...   \n",
       "5402                    1                1               0   \n",
       "5403                    1                1               0   \n",
       "5404                    1                1               0   \n",
       "5405                    0                0               1   \n",
       "5406                    0                1               0   \n",
       "5407                    1                1               0   \n",
       "5408                    1                1               0   \n",
       "5409                    0                1               0   \n",
       "5410                    0                1               0   \n",
       "5411                    0                1               0   \n",
       "5412                    1                1               0   \n",
       "5413                    1                1               0   \n",
       "5414                    1                1               0   \n",
       "5415                    0                1               0   \n",
       "5416                    1                1               0   \n",
       "5417                    0                1               0   \n",
       "5418                    0                1               0   \n",
       "5419                    0                1               0   \n",
       "5420                    0                0               1   \n",
       "5421                    0                1               0   \n",
       "5422                    0                1               0   \n",
       "5423                    0                1               0   \n",
       "5424                    0                1               0   \n",
       "5425                    1                1               0   \n",
       "5426                    0                1               0   \n",
       "5427                    1                1               0   \n",
       "5428                    0                1               0   \n",
       "5429                    0                1               0   \n",
       "5430                    0                1               0   \n",
       "5431                    0                1               0   \n",
       "\n",
       "      pao2fio2Ratio_(0, 200]  pao2fio2Ratio_(200, 333]  \\\n",
       "0                          0                         0   \n",
       "1                          0                         1   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         1   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          0                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "10                         0                         0   \n",
       "11                         0                         0   \n",
       "12                         0                         0   \n",
       "13                         0                         0   \n",
       "14                         0                         0   \n",
       "15                         0                         0   \n",
       "16                         0                         0   \n",
       "17                         0                         0   \n",
       "18                         0                         0   \n",
       "19                         0                         0   \n",
       "20                         0                         0   \n",
       "21                         0                         0   \n",
       "22                         0                         0   \n",
       "23                         0                         0   \n",
       "24                         0                         0   \n",
       "25                         0                         0   \n",
       "26                         0                         0   \n",
       "27                         0                         0   \n",
       "28                         1                         0   \n",
       "29                         0                         1   \n",
       "...                      ...                       ...   \n",
       "5402                       0                         0   \n",
       "5403                       0                         0   \n",
       "5404                       0                         0   \n",
       "5405                       0                         0   \n",
       "5406                       0                         0   \n",
       "5407                       0                         0   \n",
       "5408                       1                         0   \n",
       "5409                       0                         0   \n",
       "5410                       0                         0   \n",
       "5411                       0                         0   \n",
       "5412                       1                         0   \n",
       "5413                       0                         0   \n",
       "5414                       0                         0   \n",
       "5415                       0                         0   \n",
       "5416                       0                         1   \n",
       "5417                       0                         0   \n",
       "5418                       0                         0   \n",
       "5419                       0                         0   \n",
       "5420                       1                         0   \n",
       "5421                       0                         0   \n",
       "5422                       0                         0   \n",
       "5423                       0                         0   \n",
       "5424                       0                         0   \n",
       "5425                       1                         0   \n",
       "5426                       0                         0   \n",
       "5427                       0                         1   \n",
       "5428                       0                         0   \n",
       "5429                       0                         0   \n",
       "5430                       0                         0   \n",
       "5431                       0                         0   \n",
       "\n",
       "      pao2fio2Ratio_(333, 475]  pao2fio2Ratio_(475, 3000]  \\\n",
       "0                            0                          1   \n",
       "1                            0                          0   \n",
       "2                            0                          1   \n",
       "3                            0                          1   \n",
       "4                            0                          0   \n",
       "5                            0                          1   \n",
       "6                            0                          1   \n",
       "7                            1                          0   \n",
       "8                            0                          1   \n",
       "9                            0                          1   \n",
       "10                           0                          1   \n",
       "11                           0                          1   \n",
       "12                           0                          1   \n",
       "13                           0                          1   \n",
       "14                           0                          1   \n",
       "15                           0                          1   \n",
       "16                           1                          0   \n",
       "17                           0                          1   \n",
       "18                           0                          1   \n",
       "19                           0                          1   \n",
       "20                           0                          1   \n",
       "21                           0                          1   \n",
       "22                           0                          1   \n",
       "23                           0                          1   \n",
       "24                           0                          1   \n",
       "25                           0                          1   \n",
       "26                           1                          0   \n",
       "27                           0                          1   \n",
       "28                           0                          0   \n",
       "29                           0                          0   \n",
       "...                        ...                        ...   \n",
       "5402                         0                          1   \n",
       "5403                         0                          1   \n",
       "5404                         0                          1   \n",
       "5405                         0                          1   \n",
       "5406                         0                          1   \n",
       "5407                         0                          1   \n",
       "5408                         0                          0   \n",
       "5409                         0                          1   \n",
       "5410                         0                          1   \n",
       "5411                         0                          1   \n",
       "5412                         0                          0   \n",
       "5413                         0                          1   \n",
       "5414                         0                          1   \n",
       "5415                         0                          1   \n",
       "5416                         0                          0   \n",
       "5417                         0                          1   \n",
       "5418                         0                          1   \n",
       "5419                         0                          1   \n",
       "5420                         0                          0   \n",
       "5421                         0                          1   \n",
       "5422                         0                          1   \n",
       "5423                         0                          1   \n",
       "5424                         0                          1   \n",
       "5425                         0                          0   \n",
       "5426                         0                          1   \n",
       "5427                         0                          0   \n",
       "5428                         0                          1   \n",
       "5429                         0                          1   \n",
       "5430                         0                          1   \n",
       "5431                         0                          1   \n",
       "\n",
       "      vent_recieved_False  vent_recieved_True  \n",
       "0                       1                   0  \n",
       "1                       0                   1  \n",
       "2                       0                   1  \n",
       "3                       1                   0  \n",
       "4                       0                   1  \n",
       "5                       0                   1  \n",
       "6                       1                   0  \n",
       "7                       0                   1  \n",
       "8                       1                   0  \n",
       "9                       0                   1  \n",
       "10                      1                   0  \n",
       "11                      0                   1  \n",
       "12                      1                   0  \n",
       "13                      1                   0  \n",
       "14                      1                   0  \n",
       "15                      1                   0  \n",
       "16                      0                   1  \n",
       "17                      1                   0  \n",
       "18                      1                   0  \n",
       "19                      1                   0  \n",
       "20                      0                   1  \n",
       "21                      1                   0  \n",
       "22                      1                   0  \n",
       "23                      0                   1  \n",
       "24                      1                   0  \n",
       "25                      1                   0  \n",
       "26                      1                   0  \n",
       "27                      1                   0  \n",
       "28                      1                   0  \n",
       "29                      1                   0  \n",
       "...                   ...                 ...  \n",
       "5402                    0                   1  \n",
       "5403                    1                   0  \n",
       "5404                    0                   1  \n",
       "5405                    1                   0  \n",
       "5406                    0                   1  \n",
       "5407                    0                   1  \n",
       "5408                    0                   1  \n",
       "5409                    1                   0  \n",
       "5410                    1                   0  \n",
       "5411                    1                   0  \n",
       "5412                    0                   1  \n",
       "5413                    0                   1  \n",
       "5414                    0                   1  \n",
       "5415                    0                   1  \n",
       "5416                    0                   1  \n",
       "5417                    0                   1  \n",
       "5418                    1                   0  \n",
       "5419                    1                   0  \n",
       "5420                    0                   1  \n",
       "5421                    0                   1  \n",
       "5422                    1                   0  \n",
       "5423                    1                   0  \n",
       "5424                    0                   1  \n",
       "5425                    0                   1  \n",
       "5426                    1                   0  \n",
       "5427                    1                   0  \n",
       "5428                    0                   1  \n",
       "5429                    1                   0  \n",
       "5430                    1                   0  \n",
       "5431                    0                   1  \n",
       "\n",
       "[5432 rows x 50 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "cols_to_transform=['any_vasoactive', 'leukocyte', 'pao2fio2Ratio', 'vent_recieved']\n",
    "train_data = pd.get_dummies(train_data, columns = cols_to_transform )\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'amax_bun',\n",
       " 'amax_creatinine',\n",
       " 'amax_daily_sofa',\n",
       " 'amax_heartrate',\n",
       " 'amax_meanartpress',\n",
       " 'amax_platelet',\n",
       " 'amax_ptt',\n",
       " 'amax_sysbp',\n",
       " 'amax_temperature',\n",
       " 'amin_bun',\n",
       " 'amin_creatinine',\n",
       " 'amin_daily_sofa',\n",
       " 'amin_heartrate',\n",
       " 'amin_meanartpress',\n",
       " 'amin_platelet',\n",
       " 'amin_ptt',\n",
       " 'amin_sysbp',\n",
       " 'amin_temperature',\n",
       " 'median_bun',\n",
       " 'median_creatinine',\n",
       " 'median_daily_sofa',\n",
       " 'median_heartrate',\n",
       " 'median_meanartpress',\n",
       " 'median_platelet',\n",
       " 'median_ptt',\n",
       " 'median_sysbp',\n",
       " 'median_temperature',\n",
       " 'std_bun',\n",
       " 'std_creatinine',\n",
       " 'std_daily_sofa',\n",
       " 'std_heartrate',\n",
       " 'std_meanartpress',\n",
       " 'std_platelet',\n",
       " 'std_ptt',\n",
       " 'std_sysbp',\n",
       " 'std_temperature',\n",
       " 'first_admit_age',\n",
       " 'weight',\n",
       " 'final_bin',\n",
       " 'any_vasoactive_False',\n",
       " 'any_vasoactive_True',\n",
       " 'leukocyte_False',\n",
       " 'leukocyte_True',\n",
       " 'pao2fio2Ratio_(0, 200]',\n",
       " 'pao2fio2Ratio_(200, 333]',\n",
       " 'pao2fio2Ratio_(333, 475]',\n",
       " 'pao2fio2Ratio_(475, 3000]',\n",
       " 'vent_recieved_False',\n",
       " 'vent_recieved_True']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.99 ms\n"
     ]
    }
   ],
   "source": [
    "list(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binarizing outcome for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "#binarizing and poping outcome for training data\n",
    "train_data.loc[train_data['final_bin']==\"C_pos/A_full\",\"final_bin\"]=1\n",
    "train_data.loc[train_data['final_bin']==\"C_neg/A_partial\",\"final_bin\"]=0\n",
    "train_data['final_bin']=pd.to_numeric(train_data['final_bin'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building a sklearn pipeline\n",
    "As the name suggests, pipeline class allows sticking multiple processes into a single scikit-learn estimator. pipeline class has fit, predict and score method just like any other estimator (ex. LinearRegression)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement pipeline, as usual we separate features and labels from the data-set at first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.31 ms\n"
     ]
    }
   ],
   "source": [
    "x_train= train_data.copy()\n",
    "icustay_id=x_train.pop('icustay_id')\n",
    "y_train= x_train.pop(\"final_bin\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we needed our data to be scaled we would apply that here, but i've already done that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 704 s\n"
     ]
    }
   ],
   "source": [
    "# if we needed our data to be scaled we would apply that here, but i've already done that.\n",
    "# from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create a pipeline object by providing with the list of steps. \n",
    "\n",
    "Here our steps are standard scalar and support vector machine. \n",
    "\n",
    "These steps are list of tuples consisting of name and an instance of the transformer or estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66.8 ms\n"
     ]
    }
   ],
   "source": [
    "# # steps = [('scaler', StandardScaler()), ('SVM', SVC())] #so step 1 is known as scaler, which performs StandardScaler() function on the input. \n",
    "# from sklearn.svm import SVC\n",
    "# steps = [('SVM', SVC())] #removed step 1 since i already scaled my data\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.46 ms\n"
     ]
    }
   ],
   "source": [
    "# steps = [('scaler', StandardScaler()), ('SVM', SVC())] #so step 1 is known as scaler, which performs StandardScaler() function on the input. \n",
    "from sklearn.svm import SVC\n",
    "steps = [('SVM', SVC(gamma=\"scale\"))] #removed step 1 since i already scaled my data. added gamma=scale\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strings (scaler, SVM) can be anything, as these are just names to identify clearly the transform or estimator. We can use make_pipeline instead of Pipeline to avoid naming the estimator or transformer. The final step has to be an estimator in this list of tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we needed to do train/test split (which i've already done), we could use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=30, stratify=Y) #Its necessary to use stratify as Ive mentioned before that the labels are imbalanced as most of the wine quality falls in the range 5,6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hypertuning:\n",
    "SVM is usually optimized using two parameters gamma,C . I will discuss in an upcoming post on how they exactly work, but here lets define a parameter grid that we will use in GridSearchCV ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 808 s\n"
     ]
    }
   ],
   "source": [
    "parameteres = {'SVM__kernel':('linear', 'rbf'), 'SVM__C':[0.1, 1, 10]} #i think i need to include the SVM__  because i'm passing a pipeline object in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we instantiate the GridSearchCV object with pipeline and the parameter space with 5 folds cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.3 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipeline, param_grid=parameteres, cv=5) #pipeline here is basically just adding the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to fit on the training data-set and test the algorithm on the training set. Also we can find the best fit parameters for the SVM as below. \n",
    "## NOTE: i need to figure out how to extract cv misclass/ other loss parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-da18ff0567c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(\"score = %3.2f\") %(grid.score(x_test,y_test))\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rid' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.5 s\n"
     ]
    }
   ],
   "source": [
    "grid.fit(x_train, y_train)\n",
    "#print(\"score = %3.2f\") %(grid.score(x_test,y_test))\\\n",
    "print(grid.score(x_train,y_ty_trainest))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = %s \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for %: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-956531e2358d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score = %s \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'NoneType' and 'float'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 503 ms\n"
     ]
    }
   ],
   "source": [
    "# print(\"score = %s \") %(grid.score(x_train,y_train))\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7816642120765832\n",
      "{'SVM__C': 10, 'SVM__kernel': 'linear'}\n",
      "time: 475 ms\n"
     ]
    }
   ],
   "source": [
    "print(grid.score(x_train,y_train))\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.73107057, 0.79110894, 1.71803112, 0.84989548]),\n",
       " 'mean_score_time': array([0.07952285, 0.13074217, 0.07977705, 0.11922569]),\n",
       " 'mean_test_score': array([0.7757732 , 0.76859352, 0.78019146, 0.77632548]),\n",
       " 'mean_train_score': array([0.77733802, 0.77264354, 0.78221657, 0.79768044]),\n",
       " 'param_SVM__C': masked_array(data=[1, 1, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_SVM__kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'SVM__C': 1, 'SVM__kernel': 'linear'},\n",
       "  {'SVM__C': 1, 'SVM__kernel': 'rbf'},\n",
       "  {'SVM__C': 10, 'SVM__kernel': 'linear'},\n",
       "  {'SVM__C': 10, 'SVM__kernel': 'rbf'}],\n",
       " 'rank_test_score': array([3, 4, 1, 2], dtype=int32),\n",
       " 'split0_test_score': array([0.76724931, 0.76172953, 0.7700092 , 0.77092916]),\n",
       " 'split0_train_score': array([0.78066743, 0.7735328 , 0.78688147, 0.79838895]),\n",
       " 'split1_test_score': array([0.78012879, 0.76816927, 0.78104876, 0.78656854]),\n",
       " 'split1_train_score': array([0.77445339, 0.77054085, 0.77928654, 0.79746835]),\n",
       " 'split2_test_score': array([0.77440147, 0.77163904, 0.78729282, 0.7771639 ]),\n",
       " 'split2_train_score': array([0.77565578, 0.77266452, 0.77956742, 0.79659457]),\n",
       " 'split3_test_score': array([0.76887661, 0.76335175, 0.78084715, 0.76427256]),\n",
       " 'split3_train_score': array([0.7804878 , 0.77542568, 0.78508974, 0.79889554]),\n",
       " 'split4_test_score': array([0.78821363, 0.77808471, 0.78176796, 0.78268877]),\n",
       " 'split4_train_score': array([0.77542568, 0.77105384, 0.78025771, 0.79705476]),\n",
       " 'std_fit_time': array([0.00966474, 0.06456838, 0.1400069 , 0.02205565]),\n",
       " 'std_score_time': array([0.0025298 , 0.01561365, 0.00470826, 0.00172564]),\n",
       " 'std_test_score': array([0.00769171, 0.00590098, 0.00561776, 0.00800641]),\n",
       " 'std_train_score': array([0.00267635, 0.00175954, 0.00314505, 0.00084782])}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.51 ms\n"
     ]
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local methods (trying functions written by postdoc)\n",
    "Compute_Gower_Distance.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.41 ms\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance\n",
    "from sklearn.utils import validation\n",
    "from sklearn.metrics import pairwise\n",
    "from scipy.sparse import issparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "converting to floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.7 ms\n"
     ]
    }
   ],
   "source": [
    "def _return_float_dtype(X, Y):\n",
    "    ##used in grower distance, converts values to floats for formatting.\n",
    "    \"\"\"\n",
    "    1. If dtype of X and Y is float32, then dtype float32 is returned.\n",
    "    2. Else dtype float is returned.\n",
    "    \"\"\"\n",
    "    if not issparse(X) and not isinstance(X, np.ndarray):\n",
    "        X = np.asarray(X)\n",
    "\n",
    "    if Y is None:\n",
    "        Y_dtype = X.dtype\n",
    "    elif not issparse(Y) and not isinstance(Y, np.ndarray):\n",
    "        Y = np.asarray(Y)\n",
    "        Y_dtype = Y.dtype\n",
    "    else:\n",
    "        Y_dtype = Y.dtype\n",
    "\n",
    "    if X.dtype == Y_dtype == np.float32:\n",
    "        dtype = np.float32\n",
    "    elif X.dtype == np.object and not issparse(X):\n",
    "        dtype = np.float\n",
    "        for col in range(X.shape[1]):\n",
    "            if not np.issubdtype(type(X[0, col]), np.number):\n",
    "                dtype = np.object\n",
    "                break\n",
    "    else:\n",
    "        dtype = np.float\n",
    "    return X, Y, dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.53 ms\n"
     ]
    }
   ],
   "source": [
    "# x_train_float, y_train_float, dtype =_return_float_dtype(X=x_train, Y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26.5 ms\n"
     ]
    }
   ],
   "source": [
    "def check_pairwise_arrays(X, Y, precomputed=False, dtype=None):\n",
    "    ##used in grower distance, checks x and y dimensions against each otehr.\n",
    "    X, Y, dtype_float = _return_float_dtype(X, Y)\n",
    "\n",
    "    warn_on_dtype = dtype is not None\n",
    "    estimator = 'check_pairwise_arrays'\n",
    "    if dtype is None:\n",
    "        dtype = dtype_float\n",
    "    \n",
    "    ##Input validation on an array, list, sparse matrix or similar.\n",
    "    ##By default, the input is checked to be a non-empty 2D array containing only finite values.\n",
    "    \n",
    "    if Y is X or Y is None:\n",
    "        X = Y = validation.check_array(X, accept_sparse='csr', dtype=dtype,\n",
    "                            warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "    else:\n",
    "        X = validation.check_array(X, accept_sparse='csr', dtype=dtype,\n",
    "                        warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "        Y = validation.check_array(Y, accept_sparse='csr', dtype=dtype,\n",
    "                        warn_on_dtype=warn_on_dtype, estimator=estimator)\n",
    "\n",
    "    if precomputed:\n",
    "        if X.shape[1] != Y.shape[0]:\n",
    "            raise ValueError(\"Precomputed metric requires shape \"\n",
    "                             \"(n_queries, n_indexed). Got (%d, %d) \"\n",
    "                             \"for %d indexed.\" %\n",
    "                             (X.shape[0], X.shape[1], Y.shape[0]))\n",
    "    elif X.shape[1] != Y.shape[1]:\n",
    "        raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n",
    "                         \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n",
    "                             X.shape[1], Y.shape[1]))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 0. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-22a07c5def7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_train_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-7032c11e5565>\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m     17\u001b[0m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[1;32m     18\u001b[0m         Y = validation.check_array(Y, accept_sparse='csr', dtype=dtype,\n\u001b[0;32m---> 19\u001b[0;31m                         warn_on_dtype=warn_on_dtype, estimator=estimator)\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprecomputed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    550\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 0. 1. ... 0. 0. 0.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.7 ms\n"
     ]
    }
   ],
   "source": [
    "#check_pairwise_arrays(X=x_train_float, Y=y_train_float, precomputed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 201 ms\n"
     ]
    }
   ],
   "source": [
    "def gower_distances(X, Y=None, w=None, categorical_features=None):\n",
    "    \"\"\"\n",
    "    Computes the gower distances between X and Y\n",
    "\n",
    "    Read more in the :ref:`User Guide <metrics>`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "\n",
    "    Y : array-like, shape (n_samples, n_features)\n",
    "\n",
    "    w:  array-like, shape (n_features)\n",
    "    According the Gower formula, w is an attribute weight.\n",
    "\n",
    "    categorical_features: array-like, shape (n_features)\n",
    "    Indicates with True/False wheter a column is a categorical attribute.\n",
    "    This is useful when categorical atributes are represented as integer\n",
    "    values.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    similarities : ndarray, shape (n_samples, )\n",
    "\n",
    "    Notes\n",
    "    ------\n",
    "    Gower is a similarity measure for categorical, boolean and numerical mixed\n",
    "    data.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    X, Y = check_pairwise_arrays(X, Y, dtype=(np.object, None)[issparse(X) or\n",
    "                                                               issparse(Y)])\n",
    "    rows, cols = X.shape\n",
    "\n",
    "    if categorical_features is None:\n",
    "        categorical_features = []\n",
    "        for col in range(cols):\n",
    "            if np.issubdtype(type(X[0, col]), np.number):\n",
    "                categorical_features.append(False)\n",
    "            else:\n",
    "                categorical_features.append(True)\n",
    "    # Calculates the normalized ranges and max values of numeric values\n",
    "    ranges_of_numeric = [0.0] * cols\n",
    "    max_of_numeric = [0.0] * cols\n",
    "    for col in range(cols):\n",
    "        if not categorical_features[col]:\n",
    "            max = None\n",
    "            min = None\n",
    "            if issparse(X):\n",
    "                col_array = X.getcol(col)\n",
    "                max = col_array.max() + 0.0\n",
    "                min = col_array.min() + 0.0\n",
    "            else:\n",
    "                col_array = X[:, col].astype(np.double)\n",
    "                max = np.nanmax(col_array)\n",
    "                min = np.nanmin(col_array)\n",
    "\n",
    "            if np.isnan(max):\n",
    "                max = 0.0\n",
    "            if np.isnan(min):\n",
    "                min = 0.0\n",
    "            max_of_numeric[col] = max\n",
    "            ranges_of_numeric[col] = (1 - min / max) if (max != 0) else 0.0\n",
    "\n",
    "    if w is None:\n",
    "        w = [1] * cols\n",
    "\n",
    "    yrows, ycols = Y.shape\n",
    "\n",
    "    dm = np.zeros((rows, yrows), dtype=np.double)\n",
    "\n",
    "    for i in range(0, rows):\n",
    "        j_start = i\n",
    "\n",
    "        # for non square results\n",
    "        if rows != yrows:\n",
    "            j_start = 0\n",
    "\n",
    "        for j in range(j_start, yrows):\n",
    "            sum_sij = 0.0\n",
    "            sum_wij = 0.0\n",
    "            for col in range(cols):\n",
    "                value_xi = X[i, col]\n",
    "                value_xj = Y[j, col]\n",
    "\n",
    "                if not categorical_features[col]:\n",
    "                    if (max_of_numeric[col] != 0):\n",
    "                        value_xi = value_xi / max_of_numeric[col]\n",
    "                        value_xj = value_xj / max_of_numeric[col]\n",
    "                    else:\n",
    "                        value_xi = 0\n",
    "                        value_xj = 0\n",
    "\n",
    "                    if ranges_of_numeric[col] != 0:\n",
    "                        sij = abs(value_xi - value_xj) / ranges_of_numeric[col]\n",
    "                    else:\n",
    "                        sij = 0\n",
    "                    wij = (w[col], 0)[np.isnan(value_xi) or np.isnan(value_xj)]\n",
    "                else:\n",
    "                    sij = (1.0, 0.0)[value_xi == value_xj]\n",
    "                    wij = (w[col], 0)[value_xi is None and value_xj is None]\n",
    "                sum_sij += (wij * sij)\n",
    "                sum_wij += wij\n",
    "\n",
    "            if sum_wij != 0:\n",
    "                dm[i, j] = (sum_sij / sum_wij)\n",
    "                if j < rows and i < yrows:\n",
    "                    dm[j, i] = dm[i, j]\n",
    "    return dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100\n",
      "time: 2.75 ms\n"
     ]
    }
   ],
   "source": [
    "##testing grower distance\n",
    "x_train1=x_train.iloc[:100,1:20]\n",
    "x_train2=x_train.iloc[101:201,1:20]\n",
    "print(len(x_train1), #2715\n",
    "len(x_train2)) #2715"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amax_creatinine</th>\n",
       "      <th>amax_daily_sofa</th>\n",
       "      <th>amax_heartrate</th>\n",
       "      <th>amax_meanartpress</th>\n",
       "      <th>amax_platelet</th>\n",
       "      <th>amax_ptt</th>\n",
       "      <th>amax_sysbp</th>\n",
       "      <th>amax_temperature</th>\n",
       "      <th>amin_bun</th>\n",
       "      <th>amin_creatinine</th>\n",
       "      <th>amin_daily_sofa</th>\n",
       "      <th>amin_heartrate</th>\n",
       "      <th>amin_meanartpress</th>\n",
       "      <th>amin_platelet</th>\n",
       "      <th>amin_ptt</th>\n",
       "      <th>amin_sysbp</th>\n",
       "      <th>amin_temperature</th>\n",
       "      <th>median_bun</th>\n",
       "      <th>median_creatinine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>-0.031305</td>\n",
       "      <td>0.168830</td>\n",
       "      <td>0.243009</td>\n",
       "      <td>-0.033688</td>\n",
       "      <td>0.045971</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.102960</td>\n",
       "      <td>-0.110517</td>\n",
       "      <td>0.127943</td>\n",
       "      <td>-0.099264</td>\n",
       "      <td>-0.101429</td>\n",
       "      <td>-0.021066</td>\n",
       "      <td>-0.007892</td>\n",
       "      <td>-0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>1.118385</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.030172</td>\n",
       "      <td>-0.037222</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>0.631709</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.018847</td>\n",
       "      <td>-0.036032</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>-0.050531</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>-0.021066</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>1.040469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>-0.448205</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.064773</td>\n",
       "      <td>-0.104599</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.081338</td>\n",
       "      <td>-0.031509</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.448205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>0.079212</td>\n",
       "      <td>0.104617</td>\n",
       "      <td>-0.099264</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>-0.131174</td>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.203799</td>\n",
       "      <td>-0.076508</td>\n",
       "      <td>0.055641</td>\n",
       "      <td>-0.125573</td>\n",
       "      <td>-0.042049</td>\n",
       "      <td>-0.039920</td>\n",
       "      <td>-0.078168</td>\n",
       "      <td>-0.347655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>-0.347655</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>0.150966</td>\n",
       "      <td>0.075231</td>\n",
       "      <td>0.067418</td>\n",
       "      <td>0.025592</td>\n",
       "      <td>-0.312219</td>\n",
       "      <td>-0.555695</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.078556</td>\n",
       "      <td>-0.155231</td>\n",
       "      <td>0.138129</td>\n",
       "      <td>0.038602</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>-0.023148</td>\n",
       "      <td>-0.098414</td>\n",
       "      <td>-0.501950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>0.578891</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.107438</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>-0.075070</td>\n",
       "      <td>0.384208</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.129418</td>\n",
       "      <td>-0.050632</td>\n",
       "      <td>-0.108998</td>\n",
       "      <td>0.317555</td>\n",
       "      <td>-0.033688</td>\n",
       "      <td>-0.063315</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0.076014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>0.217747</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.092352</td>\n",
       "      <td>0.066104</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>-0.002462</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.123945</td>\n",
       "      <td>-0.141823</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>-0.012767</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>0.076014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.027347</td>\n",
       "      <td>0.072609</td>\n",
       "      <td>0.038885</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.129418</td>\n",
       "      <td>-0.176429</td>\n",
       "      <td>-0.007729</td>\n",
       "      <td>-0.009778</td>\n",
       "      <td>-0.146319</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.164150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>1.762710</td>\n",
       "      <td>0.953445</td>\n",
       "      <td>0.234153</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>-0.076639</td>\n",
       "      <td>0.481033</td>\n",
       "      <td>0.075082</td>\n",
       "      <td>0.102340</td>\n",
       "      <td>0.344981</td>\n",
       "      <td>0.915764</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.024623</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>-0.183899</td>\n",
       "      <td>-0.018697</td>\n",
       "      <td>-0.176103</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0.360513</td>\n",
       "      <td>1.395769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.191390</td>\n",
       "      <td>0.117153</td>\n",
       "      <td>0.085552</td>\n",
       "      <td>-0.063069</td>\n",
       "      <td>0.057545</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.047287</td>\n",
       "      <td>-0.344214</td>\n",
       "      <td>-0.021698</td>\n",
       "      <td>-0.063069</td>\n",
       "      <td>-0.101429</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>-0.073479</td>\n",
       "      <td>-0.300429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>0.408760</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.043064</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.043740</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>0.146224</td>\n",
       "      <td>0.284055</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.152312</td>\n",
       "      <td>-0.098785</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.059526</td>\n",
       "      <td>-0.027322</td>\n",
       "      <td>0.240210</td>\n",
       "      <td>0.346407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.193847</td>\n",
       "      <td>-0.119559</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>-0.382901</td>\n",
       "      <td>0.163535</td>\n",
       "      <td>-0.119559</td>\n",
       "      <td>-0.078120</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>-0.280219</td>\n",
       "      <td>-0.306178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.077448</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>0.053982</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.030192</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>-0.050632</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.059526</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>-0.312219</td>\n",
       "      <td>-0.347655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.014987</td>\n",
       "      <td>-0.031305</td>\n",
       "      <td>-0.218596</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>-0.017654</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>-0.155149</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.078556</td>\n",
       "      <td>-0.191362</td>\n",
       "      <td>-0.285000</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>-0.154522</td>\n",
       "      <td>-0.027322</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>-0.555695</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.164373</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>-0.274114</td>\n",
       "      <td>-0.671154</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.113278</td>\n",
       "      <td>-0.045693</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.020266</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>-0.240028</td>\n",
       "      <td>-0.671154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.780201</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>0.223546</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>0.057545</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>-0.148458</td>\n",
       "      <td>0.188737</td>\n",
       "      <td>-0.082730</td>\n",
       "      <td>-0.158713</td>\n",
       "      <td>-0.025234</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>0.408760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>0.076805</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.064773</td>\n",
       "      <td>-0.104599</td>\n",
       "      <td>0.008490</td>\n",
       "      <td>-0.004313</td>\n",
       "      <td>-0.081338</td>\n",
       "      <td>-0.031509</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>0.284055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>1.737376</td>\n",
       "      <td>0.584963</td>\n",
       "      <td>0.096860</td>\n",
       "      <td>0.108071</td>\n",
       "      <td>0.151484</td>\n",
       "      <td>-0.038412</td>\n",
       "      <td>0.103866</td>\n",
       "      <td>-0.021066</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088092</td>\n",
       "      <td>-0.162146</td>\n",
       "      <td>0.130251</td>\n",
       "      <td>-0.060527</td>\n",
       "      <td>-0.130574</td>\n",
       "      <td>-0.061172</td>\n",
       "      <td>0.299501</td>\n",
       "      <td>1.331168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>0.148492</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.051569</td>\n",
       "      <td>0.082546</td>\n",
       "      <td>0.029235</td>\n",
       "      <td>0.397689</td>\n",
       "      <td>0.049399</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>-0.146232</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>-0.059262</td>\n",
       "      <td>-0.087882</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>0.280650</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.021221</td>\n",
       "      <td>0.174540</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>0.310799</td>\n",
       "      <td>0.172253</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>-0.131174</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.140657</td>\n",
       "      <td>-0.055647</td>\n",
       "      <td>0.084838</td>\n",
       "      <td>-0.104948</td>\n",
       "      <td>-0.036448</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>-0.120014</td>\n",
       "      <td>-0.255903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2737</th>\n",
       "      <td>1.631709</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.125991</td>\n",
       "      <td>-0.030310</td>\n",
       "      <td>-0.029001</td>\n",
       "      <td>0.018947</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.192589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.034783</td>\n",
       "      <td>-0.110517</td>\n",
       "      <td>-0.070432</td>\n",
       "      <td>-0.066917</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>-0.056896</td>\n",
       "      <td>0.056406</td>\n",
       "      <td>1.363969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2738</th>\n",
       "      <td>0.826712</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.125134</td>\n",
       "      <td>0.134597</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>0.233006</td>\n",
       "      <td>0.075082</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>0.578891</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.018847</td>\n",
       "      <td>-0.148458</td>\n",
       "      <td>-0.093032</td>\n",
       "      <td>0.146907</td>\n",
       "      <td>-0.142302</td>\n",
       "      <td>-0.098059</td>\n",
       "      <td>0.068855</td>\n",
       "      <td>0.731498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2739</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.102193</td>\n",
       "      <td>0.134597</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>-0.074737</td>\n",
       "      <td>0.100420</td>\n",
       "      <td>0.021964</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.152312</td>\n",
       "      <td>-0.110517</td>\n",
       "      <td>-0.060004</td>\n",
       "      <td>-0.078711</td>\n",
       "      <td>-0.134431</td>\n",
       "      <td>-0.035708</td>\n",
       "      <td>0.056406</td>\n",
       "      <td>-0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2740</th>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.050589</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>0.041982</td>\n",
       "      <td>-0.050531</td>\n",
       "      <td>0.155528</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.083288</td>\n",
       "      <td>-0.584281</td>\n",
       "      <td>-0.005491</td>\n",
       "      <td>-0.070806</td>\n",
       "      <td>-0.091210</td>\n",
       "      <td>-0.014837</td>\n",
       "      <td>0.125829</td>\n",
       "      <td>0.315855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>0.347655</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>0.054870</td>\n",
       "      <td>0.112274</td>\n",
       "      <td>-0.027841</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.146224</td>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.108077</td>\n",
       "      <td>-0.155231</td>\n",
       "      <td>0.032959</td>\n",
       "      <td>-0.027841</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>-0.037813</td>\n",
       "      <td>0.183238</td>\n",
       "      <td>0.284055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2742</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.146515</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.073804</td>\n",
       "      <td>-0.037222</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>-0.131174</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.083288</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>0.040209</td>\n",
       "      <td>-0.086793</td>\n",
       "      <td>-0.084592</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>-0.051880</td>\n",
       "      <td>-0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>0.392025</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>-0.059262</td>\n",
       "      <td>0.128490</td>\n",
       "      <td>0.047953</td>\n",
       "      <td>-0.274114</td>\n",
       "      <td>-0.555695</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.055909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.025345</td>\n",
       "      <td>-0.142645</td>\n",
       "      <td>-0.004936</td>\n",
       "      <td>-0.010700</td>\n",
       "      <td>-0.058062</td>\n",
       "      <td>-0.350704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>-0.347655</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.068747</td>\n",
       "      <td>0.062011</td>\n",
       "      <td>0.093941</td>\n",
       "      <td>0.164346</td>\n",
       "      <td>0.059547</td>\n",
       "      <td>0.075411</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.671154</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.092970</td>\n",
       "      <td>-0.258976</td>\n",
       "      <td>-0.036690</td>\n",
       "      <td>-0.046853</td>\n",
       "      <td>-0.142302</td>\n",
       "      <td>-0.091478</td>\n",
       "      <td>-0.405288</td>\n",
       "      <td>-0.501950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2745</th>\n",
       "      <td>0.732260</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.037873</td>\n",
       "      <td>-0.008644</td>\n",
       "      <td>0.099349</td>\n",
       "      <td>0.053701</td>\n",
       "      <td>-0.025561</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.231856</td>\n",
       "      <td>0.408760</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>-0.116544</td>\n",
       "      <td>0.063736</td>\n",
       "      <td>0.037638</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>0.270779</td>\n",
       "      <td>0.707528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2746</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>0.137191</td>\n",
       "      <td>0.234007</td>\n",
       "      <td>-0.070432</td>\n",
       "      <td>0.097197</td>\n",
       "      <td>0.076966</td>\n",
       "      <td>0.067621</td>\n",
       "      <td>-0.181044</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.038896</td>\n",
       "      <td>-0.104599</td>\n",
       "      <td>-0.116515</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>-0.150392</td>\n",
       "      <td>-0.039920</td>\n",
       "      <td>-0.143162</td>\n",
       "      <td>-0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5402</th>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.137417</td>\n",
       "      <td>0.095307</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.152645</td>\n",
       "      <td>0.043986</td>\n",
       "      <td>-0.015784</td>\n",
       "      <td>0.076014</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.164416</td>\n",
       "      <td>-0.183811</td>\n",
       "      <td>-0.027812</td>\n",
       "      <td>-0.066917</td>\n",
       "      <td>-0.123010</td>\n",
       "      <td>-0.060316</td>\n",
       "      <td>0.066926</td>\n",
       "      <td>0.146881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.091435</td>\n",
       "      <td>0.089116</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.103696</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>-0.278302</td>\n",
       "      <td>-0.032838</td>\n",
       "      <td>0.103696</td>\n",
       "      <td>-0.112020</td>\n",
       "      <td>0.018327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>-0.448205</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.132424</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.047211</td>\n",
       "      <td>-0.014210</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.671154</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.073894</td>\n",
       "      <td>-0.183811</td>\n",
       "      <td>-0.062930</td>\n",
       "      <td>-0.037222</td>\n",
       "      <td>-0.126768</td>\n",
       "      <td>-0.039920</td>\n",
       "      <td>-0.276123</td>\n",
       "      <td>-0.555695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405</th>\n",
       "      <td>0.631709</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.122666</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>0.105266</td>\n",
       "      <td>0.058293</td>\n",
       "      <td>0.088026</td>\n",
       "      <td>0.133613</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>0.347655</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.190116</td>\n",
       "      <td>-0.008644</td>\n",
       "      <td>0.041097</td>\n",
       "      <td>-0.081385</td>\n",
       "      <td>-0.025561</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>0.227871</td>\n",
       "      <td>0.523225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5406</th>\n",
       "      <td>2.325925</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>0.142984</td>\n",
       "      <td>0.022551</td>\n",
       "      <td>0.036670</td>\n",
       "      <td>0.140818</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.328666</td>\n",
       "      <td>2.198299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.088092</td>\n",
       "      <td>-0.093073</td>\n",
       "      <td>-0.050081</td>\n",
       "      <td>-0.093668</td>\n",
       "      <td>-0.036448</td>\n",
       "      <td>-0.054763</td>\n",
       "      <td>0.396355</td>\n",
       "      <td>2.325925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5407</th>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151076</td>\n",
       "      <td>0.095556</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>0.069353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.092970</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>-0.060004</td>\n",
       "      <td>0.024854</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>-0.060316</td>\n",
       "      <td>-0.049870</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5408</th>\n",
       "      <td>1.787638</td>\n",
       "      <td>1.043731</td>\n",
       "      <td>0.246092</td>\n",
       "      <td>0.324817</td>\n",
       "      <td>-0.192038</td>\n",
       "      <td>0.373279</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.123516</td>\n",
       "      <td>0.056406</td>\n",
       "      <td>0.347655</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>-0.018847</td>\n",
       "      <td>-0.898127</td>\n",
       "      <td>-0.440465</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>-0.230094</td>\n",
       "      <td>-0.033607</td>\n",
       "      <td>0.195849</td>\n",
       "      <td>1.099150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>0.871874</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.030723</td>\n",
       "      <td>0.012554</td>\n",
       "      <td>-0.026575</td>\n",
       "      <td>0.041482</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.012767</td>\n",
       "      <td>0.504894</td>\n",
       "      <td>0.682795</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>-0.249723</td>\n",
       "      <td>-0.075070</td>\n",
       "      <td>0.013674</td>\n",
       "      <td>-0.204307</td>\n",
       "      <td>-0.054763</td>\n",
       "      <td>0.517343</td>\n",
       "      <td>0.777335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5410</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>-0.027812</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.021231</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>-0.274114</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.140657</td>\n",
       "      <td>-0.040827</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.029001</td>\n",
       "      <td>-0.044890</td>\n",
       "      <td>-0.029414</td>\n",
       "      <td>-0.274114</td>\n",
       "      <td>-0.122032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5411</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.041101</td>\n",
       "      <td>0.118146</td>\n",
       "      <td>0.078289</td>\n",
       "      <td>-0.072111</td>\n",
       "      <td>0.084386</td>\n",
       "      <td>0.023980</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.123945</td>\n",
       "      <td>-0.044063</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>-0.089528</td>\n",
       "      <td>-0.030954</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>0.155882</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5412</th>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.223545</td>\n",
       "      <td>0.134597</td>\n",
       "      <td>-0.061462</td>\n",
       "      <td>-0.017570</td>\n",
       "      <td>0.091621</td>\n",
       "      <td>0.075411</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>-0.122339</td>\n",
       "      <td>-0.097857</td>\n",
       "      <td>-0.119300</td>\n",
       "      <td>-0.026069</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5413</th>\n",
       "      <td>0.076014</td>\n",
       "      <td>0.903677</td>\n",
       "      <td>0.193375</td>\n",
       "      <td>0.296670</td>\n",
       "      <td>-0.108998</td>\n",
       "      <td>0.473858</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.082385</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>0.729716</td>\n",
       "      <td>0.083117</td>\n",
       "      <td>-0.116544</td>\n",
       "      <td>-0.303217</td>\n",
       "      <td>0.089743</td>\n",
       "      <td>-0.123010</td>\n",
       "      <td>-0.037813</td>\n",
       "      <td>0.104422</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.014305</td>\n",
       "      <td>0.082546</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>0.244104</td>\n",
       "      <td>0.043137</td>\n",
       "      <td>0.040008</td>\n",
       "      <td>-0.108854</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.152312</td>\n",
       "      <td>-0.098785</td>\n",
       "      <td>-0.075070</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>-0.068675</td>\n",
       "      <td>-0.039920</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>-0.253202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5415</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170817</td>\n",
       "      <td>0.153843</td>\n",
       "      <td>0.065318</td>\n",
       "      <td>-0.069505</td>\n",
       "      <td>0.120511</td>\n",
       "      <td>0.041998</td>\n",
       "      <td>-0.240028</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.010789</td>\n",
       "      <td>-0.026646</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>-0.155586</td>\n",
       "      <td>-0.030954</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.253202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>0.284055</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.130013</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>-0.099264</td>\n",
       "      <td>0.047327</td>\n",
       "      <td>0.038014</td>\n",
       "      <td>0.191865</td>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.047287</td>\n",
       "      <td>-0.110517</td>\n",
       "      <td>-0.078220</td>\n",
       "      <td>-0.099264</td>\n",
       "      <td>-0.094577</td>\n",
       "      <td>-0.039920</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>0.284055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>0.172023</td>\n",
       "      <td>-0.018116</td>\n",
       "      <td>-0.085433</td>\n",
       "      <td>0.105574</td>\n",
       "      <td>0.055853</td>\n",
       "      <td>-0.068362</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.177004</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>-0.035398</td>\n",
       "      <td>-0.104948</td>\n",
       "      <td>0.007250</td>\n",
       "      <td>-0.037813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5418</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.071674</td>\n",
       "      <td>0.101873</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.064773</td>\n",
       "      <td>-0.104599</td>\n",
       "      <td>-0.043276</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.081338</td>\n",
       "      <td>-0.031509</td>\n",
       "      <td>-0.209194</td>\n",
       "      <td>-0.208676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>0.217747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.044295</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.036616</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.076966</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.136269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.108077</td>\n",
       "      <td>-0.148458</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.084592</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>0.146076</td>\n",
       "      <td>0.108874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5420</th>\n",
       "      <td>0.467559</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.096932</td>\n",
       "      <td>0.081225</td>\n",
       "      <td>-0.108854</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.011172</td>\n",
       "      <td>0.036308</td>\n",
       "      <td>-0.057119</td>\n",
       "      <td>-0.037222</td>\n",
       "      <td>-0.025561</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>-0.068362</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.085914</td>\n",
       "      <td>0.040106</td>\n",
       "      <td>-0.094746</td>\n",
       "      <td>0.067307</td>\n",
       "      <td>0.036736</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>-0.108854</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.003680</td>\n",
       "      <td>-0.104599</td>\n",
       "      <td>-0.192038</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>-0.081338</td>\n",
       "      <td>-0.037813</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>-0.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5422</th>\n",
       "      <td>0.780201</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>0.080295</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>-0.103537</td>\n",
       "      <td>0.014705</td>\n",
       "      <td>0.011986</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.029431</td>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.403677</td>\n",
       "      <td>-0.060310</td>\n",
       "      <td>-0.076508</td>\n",
       "      <td>-0.151949</td>\n",
       "      <td>-0.034854</td>\n",
       "      <td>-0.087882</td>\n",
       "      <td>-0.048382</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>0.217747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5423</th>\n",
       "      <td>1.297662</td>\n",
       "      <td>0.792481</td>\n",
       "      <td>0.017782</td>\n",
       "      <td>0.054870</td>\n",
       "      <td>-0.192038</td>\n",
       "      <td>0.301125</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.000410</td>\n",
       "      <td>0.246564</td>\n",
       "      <td>0.682795</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>-0.073894</td>\n",
       "      <td>-0.148458</td>\n",
       "      <td>-0.272328</td>\n",
       "      <td>0.160925</td>\n",
       "      <td>-0.130574</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>0.253675</td>\n",
       "      <td>1.079914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5424</th>\n",
       "      <td>0.148492</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.164355</td>\n",
       "      <td>0.019618</td>\n",
       "      <td>0.091413</td>\n",
       "      <td>0.110639</td>\n",
       "      <td>0.013869</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.064773</td>\n",
       "      <td>-0.065912</td>\n",
       "      <td>-0.132430</td>\n",
       "      <td>-0.016447</td>\n",
       "      <td>-0.071789</td>\n",
       "      <td>-0.063315</td>\n",
       "      <td>0.187321</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5425</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.729716</td>\n",
       "      <td>0.141888</td>\n",
       "      <td>0.125991</td>\n",
       "      <td>-0.081420</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.061535</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.093070</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>0.292481</td>\n",
       "      <td>-0.183492</td>\n",
       "      <td>-0.093073</td>\n",
       "      <td>-0.264296</td>\n",
       "      <td>-0.019828</td>\n",
       "      <td>-0.112020</td>\n",
       "      <td>-0.064173</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>-0.164150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5426</th>\n",
       "      <td>0.284055</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>0.172936</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.054813</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>0.027977</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>-0.131174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.022756</td>\n",
       "      <td>-0.135318</td>\n",
       "      <td>-0.002179</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>-0.108447</td>\n",
       "      <td>-0.035708</td>\n",
       "      <td>-0.087975</td>\n",
       "      <td>0.076014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>-0.079914</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.080295</td>\n",
       "      <td>0.098730</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>-0.051765</td>\n",
       "      <td>0.041019</td>\n",
       "      <td>0.063709</td>\n",
       "      <td>-0.131174</td>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.102960</td>\n",
       "      <td>-0.141823</td>\n",
       "      <td>-0.039299</td>\n",
       "      <td>-0.106383</td>\n",
       "      <td>-0.115637</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>-0.098414</td>\n",
       "      <td>-0.164150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5428</th>\n",
       "      <td>0.631709</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.112596</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>0.113523</td>\n",
       "      <td>-0.025534</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0.420338</td>\n",
       "      <td>0.467559</td>\n",
       "      <td>-0.207519</td>\n",
       "      <td>-0.123945</td>\n",
       "      <td>-0.116544</td>\n",
       "      <td>0.094625</td>\n",
       "      <td>-0.032502</td>\n",
       "      <td>-0.071789</td>\n",
       "      <td>-0.044145</td>\n",
       "      <td>0.440692</td>\n",
       "      <td>0.524219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>2.641747</td>\n",
       "      <td>0.160964</td>\n",
       "      <td>0.047458</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.089790</td>\n",
       "      <td>0.015733</td>\n",
       "      <td>0.063509</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.208459</td>\n",
       "      <td>2.217184</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.014987</td>\n",
       "      <td>-0.060739</td>\n",
       "      <td>0.066104</td>\n",
       "      <td>-0.022099</td>\n",
       "      <td>-0.047759</td>\n",
       "      <td>-0.004517</td>\n",
       "      <td>0.216448</td>\n",
       "      <td>2.272503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5430</th>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.056759</td>\n",
       "      <td>0.016634</td>\n",
       "      <td>-0.035398</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>0.071521</td>\n",
       "      <td>-0.464272</td>\n",
       "      <td>-0.347655</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.129418</td>\n",
       "      <td>-0.071167</td>\n",
       "      <td>-0.044619</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.074938</td>\n",
       "      <td>-0.008636</td>\n",
       "      <td>-0.464272</td>\n",
       "      <td>-0.347655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>-0.164150</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.050589</td>\n",
       "      <td>0.072439</td>\n",
       "      <td>0.064529</td>\n",
       "      <td>0.012640</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.034019</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.253202</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.078556</td>\n",
       "      <td>-0.031305</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>-0.040804</td>\n",
       "      <td>-0.020266</td>\n",
       "      <td>-0.012767</td>\n",
       "      <td>-0.355418</td>\n",
       "      <td>-0.164150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2715 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      amax_creatinine  amax_daily_sofa  amax_heartrate  amax_meanartpress  \\\n",
       "2717        -0.079914        -0.500000        0.021221          -0.031305   \n",
       "2718         1.118385         0.160964        0.047458           0.069000   \n",
       "2719        -0.448205         0.160964        0.071674           0.101873   \n",
       "2720        -0.347655        -0.500000       -0.003680           0.079212   \n",
       "2721        -0.347655         0.160964        0.071674           0.062011   \n",
       "2722         0.578891         0.584963        0.107438           0.098730   \n",
       "2723         0.217747        -0.207519       -0.055909           0.092352   \n",
       "2724        -0.079914         0.160964        0.056759           0.108071   \n",
       "2725         1.762710         0.953445        0.234153           0.043860   \n",
       "2726        -0.164150         0.160964        0.191390           0.117153   \n",
       "2727         0.408760        -0.207519       -0.043064           0.036308   \n",
       "2728        -0.164150        -0.207519        0.085914           0.098730   \n",
       "2729        -0.253202        -1.000000        0.077448           0.072439   \n",
       "2730         0.000000         0.160964       -0.014987          -0.031305   \n",
       "2731        -0.555695        -0.500000        0.164373           0.108071   \n",
       "2732         0.780201         0.160964        0.044295           0.036308   \n",
       "2733         0.284055         0.160964        0.071674           0.101873   \n",
       "2734         1.737376         0.584963        0.096860           0.108071   \n",
       "2735         0.148492        -0.500000       -0.051569           0.082546   \n",
       "2736        -0.164150         0.160964        0.021221           0.174540   \n",
       "2737         1.631709         0.292481        0.074574           0.125991   \n",
       "2738         0.826712         0.903677        0.125134           0.134597   \n",
       "2739         0.000000         0.160964        0.102193           0.134597   \n",
       "2740         0.871874         0.292481        0.050589           0.151162   \n",
       "2741         0.347655         0.160964       -0.060310           0.054870   \n",
       "2742         0.000000         0.160964        0.146515           0.058460   \n",
       "2743        -0.253202        -0.207519        0.010789           0.392025   \n",
       "2744        -0.347655         0.292481        0.068747           0.062011   \n",
       "2745         0.732260         0.292481        0.037873          -0.008644   \n",
       "2746         0.000000         0.292481        0.137191           0.234007   \n",
       "...               ...              ...             ...                ...   \n",
       "5402         0.467559         0.160964        0.074574           0.137417   \n",
       "5403         0.217747         0.160964        0.091435           0.089116   \n",
       "5404        -0.448205        -0.207519        0.132424           0.069000   \n",
       "5405         0.631709         0.160964        0.122666           0.172023   \n",
       "5406         2.325925         0.292481       -0.011172           0.142984   \n",
       "5407         0.076014         0.000000        0.151076           0.095556   \n",
       "5408         1.787638         1.043731        0.246092           0.324817   \n",
       "5409         0.871874         0.160964       -0.030723           0.012554   \n",
       "5410        -0.079914        -0.207519        0.014305           0.040106   \n",
       "5411         0.000000        -0.500000        0.041101           0.118146   \n",
       "5412         0.076014         0.903677        0.223545           0.134597   \n",
       "5413         0.076014         0.903677        0.193375           0.296670   \n",
       "5414        -0.164150        -0.207519        0.014305           0.082546   \n",
       "5415        -0.079914         0.000000        0.170817           0.153843   \n",
       "5416         0.284055         0.403677        0.130013           0.028580   \n",
       "5417        -0.079914         0.000000        0.027988           0.172023   \n",
       "5418        -0.164150         0.160964        0.071674           0.101873   \n",
       "5419         0.217747         0.160964        0.044295           0.098730   \n",
       "5420         0.467559         0.160964        0.139548           0.164355   \n",
       "5421         0.000000         0.160964        0.085914           0.040106   \n",
       "5422         0.780201         0.403677        0.080295           0.047571   \n",
       "5423         1.297662         0.792481        0.017782           0.054870   \n",
       "5424         0.148492         0.160964        0.056759           0.164355   \n",
       "5425        -0.079914         0.729716        0.141888           0.125991   \n",
       "5426         0.284055        -0.207519        0.172936           0.058460   \n",
       "5427        -0.079914         0.500000        0.080295           0.098730   \n",
       "5428         0.631709         0.160964        0.112596           0.072439   \n",
       "5429         2.641747         0.160964        0.047458           0.032467   \n",
       "5430        -0.253202        -0.500000        0.056759           0.016634   \n",
       "5431        -0.164150        -1.000000        0.050589           0.072439   \n",
       "\n",
       "      amax_platelet  amax_ptt  amax_sysbp  amax_temperature  amin_bun  \\\n",
       "2717       0.168830  0.243009   -0.033688          0.045971 -0.049870   \n",
       "2718       0.030172 -0.037222    0.063509          0.019945 -0.155149   \n",
       "2719       0.034795  0.012640    0.071275          0.025994 -0.405288   \n",
       "2720       0.104617 -0.099264    0.120511          0.021964 -0.131174   \n",
       "2721       0.150966  0.075231    0.067418          0.025592 -0.312219   \n",
       "2722      -0.075070  0.384208    0.084386          0.029210  0.069095   \n",
       "2723       0.066104 -0.024385    0.041019         -0.002462  0.093070   \n",
       "2724       0.027347  0.072609    0.038885          0.019945 -0.405288   \n",
       "2725      -0.076639  0.481033    0.075082          0.102340  0.344981   \n",
       "2726       0.085552 -0.063069    0.057545          0.038014 -0.155149   \n",
       "2727       0.043740  0.012640    0.063509         -0.008636  0.146224   \n",
       "2728       0.193847 -0.119559    0.047327          0.009804 -0.405288   \n",
       "2729       0.053982  0.012640    0.030192          0.003685 -0.355418   \n",
       "2730      -0.218596  0.065522   -0.017654          0.005728 -0.155149   \n",
       "2731       0.005348  0.012640    0.080700          0.047953 -0.274114   \n",
       "2732       0.223546 -0.040804    0.057545          0.047953  0.015050   \n",
       "2733       0.076805  0.013674    0.071275          0.025994  0.029431   \n",
       "2734       0.151484 -0.038412    0.103866         -0.021066  0.253675   \n",
       "2735       0.029235  0.397689    0.049399          0.013869  0.093070   \n",
       "2736       0.101340  0.310799    0.172253          0.001639 -0.131174   \n",
       "2737      -0.030310 -0.029001    0.018947         -0.004517  0.000000   \n",
       "2738      -0.057119  0.233006    0.075082          0.003685  0.029431   \n",
       "2739       0.101340 -0.074737    0.100420          0.021964  0.015050   \n",
       "2740       0.041982 -0.050531    0.155528          0.025994  0.069095   \n",
       "2741       0.112274 -0.027841    0.061535          0.028005  0.146224   \n",
       "2742       0.073804 -0.037222    0.045239          0.007768 -0.131174   \n",
       "2743       0.056465 -0.059262    0.128490          0.047953 -0.274114   \n",
       "2744       0.093941  0.164346    0.059547          0.075411 -0.405288   \n",
       "2745       0.099349  0.053701   -0.025561          0.013869  0.231856   \n",
       "2746      -0.070432  0.097197    0.076966          0.067621 -0.181044   \n",
       "...             ...       ...         ...               ...       ...   \n",
       "5402       0.095307  0.014705    0.152645          0.043986 -0.015784   \n",
       "5403       0.068445  0.103696    0.007250          0.068402 -0.087975   \n",
       "5404       0.047211 -0.014210    0.041019          0.015898 -0.355418   \n",
       "5405       0.105266  0.058293    0.088026          0.133613  0.104422   \n",
       "5406       0.022551  0.036670    0.140818          0.001639  0.328666   \n",
       "5407       0.044613  0.024854    0.069353          0.000000 -0.087975   \n",
       "5408      -0.192038  0.373279    0.041019          0.123516  0.056406   \n",
       "5409      -0.026575  0.041482    0.007250         -0.012767  0.504894   \n",
       "5410      -0.027812 -0.017570    0.021231          0.009804 -0.274114   \n",
       "5411       0.078289 -0.072111    0.084386          0.023980  0.000000   \n",
       "5412      -0.061462 -0.017570    0.091621          0.075411  0.246564   \n",
       "5413      -0.108998  0.473858    0.014325          0.082385 -0.087975   \n",
       "5414      -0.052867  0.244104    0.043137          0.040008 -0.108854   \n",
       "5415       0.065318 -0.069505    0.120511          0.041998 -0.240028   \n",
       "5416       0.046349 -0.099264    0.047327          0.038014  0.191865   \n",
       "5417      -0.018116 -0.085433    0.105574          0.055853 -0.068362   \n",
       "5418      -0.008858  0.012640    0.071275          0.025994 -0.209194   \n",
       "5419       0.036616  0.012640    0.076966          0.001639  0.136269   \n",
       "5420       0.081225  0.035700    0.096932          0.081225 -0.108854   \n",
       "5421      -0.094746  0.067307    0.036736         -0.000410 -0.108854   \n",
       "5422      -0.103537  0.014705    0.011986          0.007768  0.029431   \n",
       "5423      -0.192038  0.301125    0.027977         -0.000410  0.246564   \n",
       "5424       0.019618  0.091413    0.110639          0.013869  0.069095   \n",
       "5425      -0.081420  0.048113    0.061535          0.003685  0.093070   \n",
       "5426       0.054813  0.022847    0.027977         -0.008636 -0.131174   \n",
       "5427       0.016643 -0.051765    0.041019          0.063709 -0.131174   \n",
       "5428       0.113523 -0.025534    0.071275          0.017923  0.420338   \n",
       "5429       0.089790  0.015733    0.063509          0.009804  0.208459   \n",
       "5430      -0.035398  0.012640   -0.028245          0.071521 -0.464272   \n",
       "5431       0.064529  0.012640    0.071275          0.034019 -0.355418   \n",
       "\n",
       "      amin_creatinine  amin_daily_sofa  amin_heartrate  amin_meanartpress  \\\n",
       "2717        -0.164150        -0.500000       -0.102960          -0.110517   \n",
       "2718         0.631709         0.160964       -0.018847          -0.036032   \n",
       "2719        -0.448205        -0.500000       -0.064773          -0.104599   \n",
       "2720        -0.448205        -1.000000       -0.203799          -0.076508   \n",
       "2721        -0.555695        -0.500000       -0.078556          -0.155231   \n",
       "2722        -0.079914        -1.000000       -0.129418          -0.050632   \n",
       "2723         0.076014        -0.207519       -0.123945          -0.141823   \n",
       "2724        -0.253202         0.000000       -0.129418          -0.176429   \n",
       "2725         0.915764         0.903677        0.024623          -0.135318   \n",
       "2726        -0.347655        -0.500000       -0.047287          -0.344214   \n",
       "2727         0.284055        -0.207519       -0.152312          -0.098785   \n",
       "2728        -0.448205        -0.207519       -0.011172          -0.382901   \n",
       "2729        -0.448205        -1.000000        0.010789          -0.050632   \n",
       "2730        -0.164150        -0.500000       -0.078556          -0.191362   \n",
       "2731        -0.671154        -1.000000       -0.113278          -0.045693   \n",
       "2732         0.148492        -0.500000       -0.055909          -0.148458   \n",
       "2733         0.217747        -0.500000       -0.064773          -0.104599   \n",
       "2734         0.871874         0.000000       -0.088092          -0.162146   \n",
       "2735        -0.164150        -0.500000       -0.060310          -0.146232   \n",
       "2736        -0.347655        -0.500000       -0.140657          -0.055647   \n",
       "2737         1.192589         0.000000       -0.034783          -0.110517   \n",
       "2738         0.578891         0.500000       -0.018847          -0.148458   \n",
       "2739        -0.164150         0.000000       -0.152312          -0.110517   \n",
       "2740         0.076014         0.000000       -0.083288          -0.584281   \n",
       "2741         0.148492         0.000000       -0.108077          -0.155231   \n",
       "2742        -0.253202         0.160964       -0.083288          -0.135318   \n",
       "2743        -0.555695        -1.000000       -0.055909           0.000000   \n",
       "2744        -0.671154        -0.500000       -0.092970          -0.258976   \n",
       "2745         0.408760         0.292481       -0.011172          -0.116544   \n",
       "2746        -0.164150         0.000000       -0.038896          -0.104599   \n",
       "...               ...              ...             ...                ...   \n",
       "5402         0.076014        -0.500000       -0.164416          -0.183811   \n",
       "5403        -0.079914        -0.500000        0.047458          -0.278302   \n",
       "5404        -0.671154        -1.000000       -0.073894          -0.183811   \n",
       "5405         0.347655        -1.000000       -0.190116          -0.008644   \n",
       "5406         2.198299         0.000000       -0.088092          -0.093073   \n",
       "5407        -0.079914        -1.000000       -0.092970          -0.135318   \n",
       "5408         0.347655         0.903677       -0.018847          -0.898127   \n",
       "5409         0.682795         0.160964       -0.060310          -0.249723   \n",
       "5410        -0.164150        -0.500000       -0.140657          -0.040827   \n",
       "5411         0.000000        -1.000000       -0.123945          -0.044063   \n",
       "5412        -0.164150        -0.207519        0.007234          -0.135318   \n",
       "5413        -0.347655         0.729716        0.083117          -0.116544   \n",
       "5414        -0.253202        -0.207519       -0.152312          -0.098785   \n",
       "5415        -0.347655        -1.000000        0.010789          -0.026646   \n",
       "5416         0.217747         0.000000       -0.047287          -0.110517   \n",
       "5417        -0.164150        -1.000000       -0.177004           0.032467   \n",
       "5418        -0.253202        -0.500000       -0.064773          -0.104599   \n",
       "5419         0.000000        -0.500000       -0.108077          -0.148458   \n",
       "5420        -0.347655        -0.500000       -0.011172           0.036308   \n",
       "5421        -0.079914         0.160964       -0.003680          -0.104599   \n",
       "5422        -0.079914         0.403677       -0.060310          -0.076508   \n",
       "5423         0.682795         0.160964       -0.073894          -0.148458   \n",
       "5424        -0.164150        -0.207519       -0.064773          -0.065912   \n",
       "5425        -0.253202         0.292481       -0.183492          -0.093073   \n",
       "5426         0.000000        -0.207519       -0.022756          -0.135318   \n",
       "5427        -0.164150        -0.500000       -0.102960          -0.141823   \n",
       "5428         0.467559        -0.207519       -0.123945          -0.116544   \n",
       "5429         2.217184        -0.500000       -0.014987          -0.060739   \n",
       "5430        -0.347655        -0.500000       -0.129418          -0.071167   \n",
       "5431        -0.253202        -1.000000       -0.078556          -0.031305   \n",
       "\n",
       "      amin_platelet  amin_ptt  amin_sysbp  amin_temperature  median_bun  \\\n",
       "2717       0.127943 -0.099264   -0.101429         -0.021066   -0.007892   \n",
       "2718       0.003225 -0.050531   -0.017654         -0.021066    0.043199   \n",
       "2719       0.034795 -0.040804   -0.081338         -0.031509   -0.405288   \n",
       "2720       0.055641 -0.125573   -0.042049         -0.039920   -0.078168   \n",
       "2721       0.138129  0.038602   -0.119300         -0.023148   -0.098414   \n",
       "2722      -0.108998  0.317555   -0.033688         -0.063315    0.093070   \n",
       "2723       0.056465 -0.024385   -0.108447         -0.012767    0.165260   \n",
       "2724      -0.007729 -0.009778   -0.146319         -0.050506   -0.355418   \n",
       "2725      -0.183899 -0.018697   -0.176103          0.017923    0.360513   \n",
       "2726      -0.021698 -0.063069   -0.101429         -0.050506   -0.073479   \n",
       "2727       0.024483 -0.040804   -0.059526         -0.027322    0.240210   \n",
       "2728       0.163535 -0.119559   -0.078120         -0.008636   -0.280219   \n",
       "2729       0.021578 -0.040804   -0.059526         -0.029414   -0.312219   \n",
       "2730      -0.285000  0.048113   -0.154522         -0.027322   -0.087975   \n",
       "2731      -0.052867 -0.040804   -0.020266         -0.016910   -0.240028   \n",
       "2732       0.188737 -0.082730   -0.158713         -0.025234    0.104422   \n",
       "2733       0.008490 -0.004313   -0.081338         -0.031509    0.043199   \n",
       "2734       0.130251 -0.060527   -0.130574         -0.061172    0.299501   \n",
       "2735       0.020600 -0.059262   -0.087882         -0.029414    0.280650   \n",
       "2736       0.084838 -0.104948   -0.036448         -0.008636   -0.120014   \n",
       "2737      -0.070432 -0.066917   -0.108447         -0.056896    0.056406   \n",
       "2738      -0.093032  0.146907   -0.142302         -0.098059    0.068855   \n",
       "2739      -0.060004 -0.078711   -0.134431         -0.035708    0.056406   \n",
       "2740      -0.005491 -0.070806   -0.091210         -0.014837    0.125829   \n",
       "2741       0.032959 -0.027841   -0.108447         -0.037813    0.183238   \n",
       "2742       0.040209 -0.086793   -0.084592         -0.029414   -0.051880   \n",
       "2743      -0.025345 -0.142645   -0.004936         -0.010700   -0.058062   \n",
       "2744      -0.036690 -0.046853   -0.142302         -0.091478   -0.405288   \n",
       "2745       0.063736  0.037638   -0.108447         -0.050506    0.270779   \n",
       "2746      -0.116515  0.036670   -0.150392         -0.039920   -0.143162   \n",
       "...             ...       ...         ...               ...         ...   \n",
       "5402      -0.027812 -0.066917   -0.123010         -0.060316    0.066926   \n",
       "5403      -0.032838  0.103696   -0.112020          0.018327    0.000000   \n",
       "5404      -0.062930 -0.037222   -0.126768         -0.039920   -0.276123   \n",
       "5405       0.041097 -0.081385   -0.025561         -0.050506    0.227871   \n",
       "5406      -0.050081 -0.093668   -0.036448         -0.054763    0.396355   \n",
       "5407      -0.060004  0.024854   -0.119300         -0.060316   -0.049870   \n",
       "5408      -0.440465  0.015733   -0.230094         -0.033607    0.195849   \n",
       "5409      -0.075070  0.013674   -0.204307         -0.054763    0.517343   \n",
       "5410      -0.057119 -0.029001   -0.044890         -0.029414   -0.274114   \n",
       "5411      -0.008858 -0.089528   -0.030954         -0.008636    0.155882   \n",
       "5412      -0.122339 -0.097857   -0.119300         -0.026069    0.253675   \n",
       "5413      -0.303217  0.089743   -0.123010         -0.037813    0.104422   \n",
       "5414      -0.075070 -0.032502   -0.068675         -0.039920   -0.087975   \n",
       "5415      -0.003277 -0.155586   -0.030954          0.001639   -0.209194   \n",
       "5416      -0.078220 -0.099264   -0.094577         -0.039920    0.253675   \n",
       "5417      -0.035398 -0.104948    0.007250         -0.037813    0.000000   \n",
       "5418      -0.043276 -0.040804   -0.081338         -0.031509   -0.209194   \n",
       "5419       0.034795 -0.040804   -0.084592         -0.050506    0.146076   \n",
       "5420      -0.057119 -0.037222   -0.025561         -0.008636   -0.068362   \n",
       "5421      -0.192038 -0.001074   -0.081338         -0.037813    0.093070   \n",
       "5422      -0.151949 -0.034854   -0.087882         -0.048382    0.093070   \n",
       "5423      -0.272328  0.160925   -0.130574         -0.050506    0.253675   \n",
       "5424      -0.132430 -0.016447   -0.071789         -0.063315    0.187321   \n",
       "5425      -0.264296 -0.019828   -0.112020         -0.064173    0.165260   \n",
       "5426      -0.002179  0.022847   -0.108447         -0.035708   -0.087975   \n",
       "5427      -0.039299 -0.106383   -0.115637         -0.044145   -0.098414   \n",
       "5428       0.094625 -0.032502   -0.071789         -0.044145    0.440692   \n",
       "5429       0.066104 -0.022099   -0.047759         -0.004517    0.216448   \n",
       "5430      -0.044619 -0.040804   -0.074938         -0.008636   -0.464272   \n",
       "5431       0.044613 -0.040804   -0.020266         -0.012767   -0.355418   \n",
       "\n",
       "      median_creatinine  \n",
       "2717          -0.122032  \n",
       "2718           1.040469  \n",
       "2719          -0.448205  \n",
       "2720          -0.347655  \n",
       "2721          -0.501950  \n",
       "2722           0.076014  \n",
       "2723           0.076014  \n",
       "2724          -0.164150  \n",
       "2725           1.395769  \n",
       "2726          -0.300429  \n",
       "2727           0.346407  \n",
       "2728          -0.306178  \n",
       "2729          -0.347655  \n",
       "2730           0.000000  \n",
       "2731          -0.671154  \n",
       "2732           0.408760  \n",
       "2733           0.284055  \n",
       "2734           1.331168  \n",
       "2735          -0.079914  \n",
       "2736          -0.255903  \n",
       "2737           1.363969  \n",
       "2738           0.731498  \n",
       "2739          -0.122032  \n",
       "2740           0.315855  \n",
       "2741           0.284055  \n",
       "2742          -0.122032  \n",
       "2743          -0.350704  \n",
       "2744          -0.501950  \n",
       "2745           0.707528  \n",
       "2746          -0.122032  \n",
       "...                 ...  \n",
       "5402           0.146881  \n",
       "5403           0.000000  \n",
       "5404          -0.555695  \n",
       "5405           0.523225  \n",
       "5406           2.325925  \n",
       "5407          -0.079914  \n",
       "5408           1.099150  \n",
       "5409           0.777335  \n",
       "5410          -0.122032  \n",
       "5411           0.000000  \n",
       "5412           0.000000  \n",
       "5413          -0.079914  \n",
       "5414          -0.253202  \n",
       "5415          -0.253202  \n",
       "5416           0.284055  \n",
       "5417          -0.079914  \n",
       "5418          -0.208676  \n",
       "5419           0.108874  \n",
       "5420          -0.079914  \n",
       "5421          -0.079914  \n",
       "5422           0.217747  \n",
       "5423           1.079914  \n",
       "5424           0.000000  \n",
       "5425          -0.164150  \n",
       "5426           0.076014  \n",
       "5427          -0.164150  \n",
       "5428           0.524219  \n",
       "5429           2.272503  \n",
       "5430          -0.347655  \n",
       "5431          -0.164150  \n",
       "\n",
       "[2715 rows x 19 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.1 ms\n"
     ]
    }
   ],
   "source": [
    "x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype float64 was converted to object by check_pairwise_arrays.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype float64 was converted to object by check_pairwise_arrays.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:99: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.24318248, 0.14126017, 0.11850909, ..., 0.16277388, 0.25359059,\n",
       "        0.21829271],\n",
       "       [0.14126017, 0.18324272, 0.15246607, ..., 0.16600347, 0.25083128,\n",
       "        0.17877063],\n",
       "       [0.11850909, 0.15246607, 0.17748913, ..., 0.19899093, 0.28713812,\n",
       "        0.16931492],\n",
       "       ...,\n",
       "       [0.16277388, 0.16600347, 0.19899093, ..., 0.20421216, 0.24213328,\n",
       "        0.17592173],\n",
       "       [0.25359059, 0.25083128, 0.28713812, ..., 0.24213328, 0.28678125,\n",
       "        0.16907204],\n",
       "       [0.21829271, 0.17877063, 0.16931492, ..., 0.17592173, 0.16907204,\n",
       "        0.15356587]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 610 ms\n"
     ]
    }
   ],
   "source": [
    "gower_distances(X=x_train1, Y=x_train2, w=None, categorical_features=None) #works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = np.array([['Syria', 1200, 0, 411114.44, True],\n",
    "#                ['Ireland', 300, 0, 199393333.22, False],\n",
    "#                ['United Kingdom', 100, 0, 32323222.121, None]], dtype=object)\n",
    "#\n",
    "# Y2 = np.array([['United Kingdom', 200, 0, 99923921.47, True]], dtype=object)\n",
    "#\n",
    "# flag = [True,True,False,False,True]\n",
    "#\n",
    "# D = gower_distances(X2, Y2,categorical_features = flag)\n",
    "#\n",
    "# print D\n",
    "\n",
    "# compute the gower distance for an example from AKI dataset\n",
    "\n",
    "# folder = '/Users/xuzhenxing/Documents/mimic_AKI_data/real_time_prediction/features/all/dropped/x'\n",
    "#\n",
    "# time_interval = 24 # 24,48, ...., Note that, the length of 24h  is different from other hours  in terms of columns\n",
    "#\n",
    "# all_x = pd.read_csv(os.path.join(folder, 'all_{}hours.csv'.format(time_interval)), index_col=0)\n",
    "\n",
    "# all_x = all_x.fillna(np.nan)\n",
    "#\n",
    "# for i in all_x.index:\n",
    "# # i = 211552\n",
    "#     A_x = all_x.loc[i]\n",
    "#     print i\n",
    "#\n",
    "#     break\n",
    "#\n",
    "# candidate_set = all_x.values[:, :]\n",
    "# testing_sample_0 = A_x.as_matrix()\n",
    "# testing_sample = testing_sample_0.reshape(1,-1)\n",
    "\n",
    "# if time_interval ==24:\n",
    "#     flag_cate_fea = [True,False]  # 24,48, ...., Note that, the length of 24h  is different from other hours  in terms of columns\n",
    "# else:\n",
    "\n",
    "# D1 = gower_distances(candidate_set, testing_sample,categorical_features = flag_cate_fea)\n",
    "\n",
    "# folder = '/Users/xuzhenxing/Documents/mimic_AKI_data/real_time_prediction/features/all/dropped/x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "def select_train_samples(sample_id, all_xy, m, time_interval):# m is number of similar cases or controls\n",
    "    num_control = m   # the ratio of case and control is 1:2, 1:3,1:4\n",
    "    if time_interval == 24:\n",
    "        top_con_variables = [False]*128\n",
    "        mid_cat_variables = [True]*5\n",
    "        age_variable = [False]\n",
    "        next_cat_variables = [True]*10\n",
    "        last_con_variables = [False]*2\n",
    "\n",
    "        flag_cate_fea = top_con_variables + mid_cat_variables + age_variable + next_cat_variables + last_con_variables # 24,48, ...., Note that, the length of 24h  is different from other hours  in terms of columns\n",
    "    else:\n",
    "        top_con_variables = [False]*129  #there is another item in other hours\n",
    "        mid_cat_variables = [True]*5\n",
    "        age_variable = [False]\n",
    "        next_cat_variables = [True]*10\n",
    "        last_con_variables = [False]*2\n",
    "\n",
    "        flag_cate_fea = top_con_variables + mid_cat_variables + age_variable + next_cat_variables + last_con_variables # 24,48, ...., Note that, the length of 24h  is different from other hours  in terms of columns\n",
    "        \n",
    "    all_xy = all_xy.fillna(np.nan) # fill empty with nan\n",
    "\n",
    "    x_candidate_label = all_xy.loc[sample_id] # get the object sample\n",
    "    x_candidate = x_candidate_label.drop('label')\n",
    "    x_candidate_tem = x_candidate.as_matrix()\n",
    "    testing_sample = x_candidate_tem.reshape(1, -1)  # covert into ....\n",
    "\n",
    "    all_x_candidate_tem = all_xy.drop([sample_id], axis=0, inplace=False) # delete the object sample from whole set\n",
    "\n",
    "# select similar cases\n",
    "    all_cases = all_x_candidate_tem[all_x_candidate_tem.label == 1]\n",
    "    all_cases_candidate = all_cases.drop(['label'], axis=1, inplace=False)\n",
    "    gower_candidate_case = all_cases_candidate.values[:, :] # convert into ndarray\n",
    "\n",
    "    Gower_Distance_1 = gower_distances(gower_candidate_case, testing_sample, categorical_features = flag_cate_fea) # Gower_Distance_1 is ndarray\n",
    "    Gower_Distance_2 = list(Gower_Distance_1)\n",
    "    Gower_Distance_3 = pd.Series(Gower_Distance_2, index = all_cases_candidate.index)\n",
    "    Gower_Distance_4 = Gower_Distance_3.sort_values(ascending=False)\n",
    "\n",
    "    Id_selected_cases = Gower_Distance_4.index[:m].tolist() # the id set of the top m similar samples\n",
    "\n",
    "# select similar controls\n",
    "    all_controls = all_x_candidate_tem[all_x_candidate_tem.label == 0]\n",
    "    all_controls_candidate = all_controls.drop(['label'], axis=1, inplace=False)\n",
    "    gower_candidate_control = all_controls_candidate.values[:, :] # convert into ndarray\n",
    "\n",
    "    Gower_Distance_11 = gower_distances(gower_candidate_control, testing_sample,categorical_features = flag_cate_fea) # Gower_Distance_1 is ndarray\n",
    "    Gower_Distance_22 = list(Gower_Distance_11)\n",
    "    Gower_Distance_33 = pd.Series(Gower_Distance_22, index = all_controls_candidate.index)\n",
    "    Gower_Distance_44 = Gower_Distance_33.sort_values(ascending=False)\n",
    "\n",
    "    Id_selected_controls = Gower_Distance_44.index[:num_control].tolist() # the id set of the top m similar samples\n",
    "\n",
    "    train_set_id = Id_selected_controls+Id_selected_cases\n",
    "\n",
    "    train_set_id = np.array(train_set_id)\n",
    "    return train_set_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "individualization_predictor.py:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.82 ms\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, Imputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from Compute_gower_distance import select_train_samples\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, accuracy_score, auc, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier #conda install -c conda-forge xgboost to install\n",
    "\n",
    "\n",
    "RANDOM_STATE = 15485867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder = '/Users/xuzhenxing/Documents/mimic_AKI_data/real_time_prediction/features/all/dropped/xy'\n",
    "# folder = './xy'\n",
    "\n",
    "\n",
    "def preprocessing(folder, time_interval, isnormalized=True):\n",
    "    \"\"\"Data preprocessing, Preprocessing  missing data with mean imputation; Normalize continous feature with MinMaxScaler;\n",
    "    Normalize categorical feature with OneHotEncoder.\n",
    "\n",
    "    Args:\n",
    "        folder: dir path of source data;\n",
    "        time_interval: interval of time, can be 24,48,72,96,120,144.\n",
    "    Returns:\n",
    "        x: features\n",
    "        y: lables\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    all_xy = pd.read_csv(os.path.join(folder, 'all_{}hours_test_individualization_1thousand.csv'.format(time_interval)), index_col=0)\n",
    "    # print (all_xy.shape)\n",
    "    # print (all_xy.columns)\n",
    "\n",
    "    medi = ['diuretics', 'nsaid', 'radio', 'angiotensin']\n",
    "    pat = ['gender', 'age', 'ethnicity']\n",
    "    # Total 9 comorbidity\n",
    "    comm = ['congestive_heart_failure', 'peripheral_vascular', 'hypertension',\n",
    "            'diabetes', 'liver_disease', 'mi', 'cad', 'cirrhosis', 'jaundice']\n",
    "\n",
    "    # Total 8 chartevents\n",
    "    chart = ['DiasBP_min', 'DiasBP_max', 'DiasBP_first', 'DiasBP_last', 'DiasBP_slope', 'DiasBP_avg',\n",
    "             'Glucose_min', 'Glucose_max', 'Glucose_first', 'Glucose_last', 'Glucose_slope', 'Glucose_avg',\n",
    "             'HeartRate_min', 'HeartRate_max', 'HeartRate_first', 'HeartRate_last', 'HeartRate_slope', 'HeartRate_avg',\n",
    "             'MeanBP_min', 'MeanBP_max', 'MeanBP_first', 'MeanBP_last', 'MeanBP_slope', 'MeanBP_avg',\n",
    "             'RespRate_min', 'RespRate_max', 'RespRate_first', 'RespRate_last', 'RespRate_slope', 'RespRate_avg',\n",
    "             'SpO2_min', 'SpO2_max', 'SpO2_first', 'SpO2_last', 'SpO2_slope', 'SpO2_avg',\n",
    "             'SysBP_min', 'SysBP_max', 'SysBP_first', 'SysBP_last', 'SysBP_slope', 'SysBP_avg',\n",
    "             'Temp_min', 'Temp_max', 'Temp_first', 'Temp_last', 'Temp_slope', 'Temp_avg']\n",
    "\n",
    "    # Total 12 labvents\n",
    "    lab = ['BICARBONATE_first', 'BICARBONATE_last', 'BICARBONATE_min', 'BICARBONATE_max', 'BICARBONATE_avg',\n",
    "           'BICARBONATE_slope', 'BICARBONATE_count',\n",
    "           'BUN_first', 'BUN_last', 'BUN_min', 'BUN_max', 'BUN_avg', 'BUN_slope', 'BUN_count',\n",
    "           'CHLORIDE_first', 'CHLORIDE_last', 'CHLORIDE_min', 'CHLORIDE_max', 'CHLORIDE_avg', 'CHLORIDE_slope',\n",
    "           'CHLORIDE_count',\n",
    "           'CREATININE_first', 'CREATININE_last', 'CREATININE_min', 'CREATININE_max', 'CREATININE_avg',\n",
    "           'CREATININE_slope', 'CREATININE_count',\n",
    "           'HEMOGLOBIN_first', 'HEMOGLOBIN_last', 'HEMOGLOBIN_min', 'HEMOGLOBIN_max', 'HEMOGLOBIN_avg',\n",
    "           'HEMOGLOBIN_slope', 'HEMOGLOBIN_count',\n",
    "           'INR_first', 'INR_last', 'INR_min', 'INR_max', 'INR_avg', 'INR_count',\n",
    "           'PLATELET_first', 'PLATELET_last', 'PLATELET_min', 'PLATELET_max', 'PLATELET_avg', 'PLATELET_slope',\n",
    "           'PLATELET_count',\n",
    "           'POTASSIUM_first', 'POTASSIUM_last', 'POTASSIUM_min', 'POTASSIUM_max', 'POTASSIUM_avg', 'POTASSIUM_slope',\n",
    "           'POTASSIUM_count',\n",
    "           'PT_first', 'PT_last', 'PT_min', 'PT_max', 'PT_avg', 'PT_count',\n",
    "           'PTT_first', 'PTT_last', 'PTT_min', 'PTT_max', 'PTT_avg', 'PTT_count',\n",
    "           'WBC_first', 'WBC_last', 'WBC_min', 'WBC_max', 'WBC_avg', 'WBC_slope', 'WBC_count',\n",
    "           'CALCIUM_first', 'CALCIUM_last', 'CALCIUM_min', 'CALCIUM_max', 'CALCIUM_avg', 'CALCIUM_count'\n",
    "           ]\n",
    "\n",
    "    if time_interval != 24:  # The 24h data lack of the feature 'CALCIUM_slope'\n",
    "        lab.append('CALCIUM_slope')\n",
    "    subset = medi + pat + comm + ['avg_urine'] + ['egfr_min'] + ['label'] # note that ['avg_urine'] + ['egfr_min'] is important, ignoring if they are empty.\n",
    "\n",
    "    all_xy = all_xy.dropna(subset=subset)\n",
    "\n",
    "    # print ('after dropping nan in the catergorical variables, the shape is {}'.format(all_xy.shape))\n",
    "\n",
    "    all_conti_x = all_xy[chart + lab + ['avg_urine'] + ['egfr_min'] + ['age']]\n",
    "    # print (all_conti_x.shape)\n",
    "    # print (all_conti_x)\n",
    "    all_categ_x = all_xy[['gender'] + ['ethnicity'] + medi + comm]\n",
    "    # print (all_categ_x.shape)\n",
    "    # print (all_categ_x)\n",
    "\n",
    "    # Using mean imputer after drop the nan data in medication, patient demographic data, avg_ureine, egfr_min and label\n",
    "    imp = Imputer(strategy='mean', axis=0)\n",
    "    all_conti_x_fitted = imp.fit_transform(all_conti_x)\n",
    "\n",
    "    def normalize(all_conti_x_fitted, all_categ_x):\n",
    "        # using the MinMaxScaler to normalization the all_x\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        all_conti_x_fitted = min_max_scaler.fit_transform(all_conti_x_fitted)\n",
    "        # print (all_conti_x_fitted.shape, all_conti_x_fitted)\n",
    "        # all_conti_x = DataFrame(all_conti_x_fitted, columns=all_conti_x.columns)\n",
    "        # print (all_conti_x.shape)\n",
    "\n",
    "        onehot_enc = OneHotEncoder(sparse=False)  # dense format\n",
    "        all_categ_x_fitted = onehot_enc.fit_transform(all_categ_x)\n",
    "        # print (all_categ_x_fitted.shape, all_categ_x_fitted)\n",
    "        return all_conti_x_fitted, all_categ_x_fitted\n",
    "\n",
    "    if isnormalized:\n",
    "        all_conti_x_fitted, all_categ_x_fitted = normalize(all_conti_x_fitted, all_categ_x)\n",
    "\n",
    "    x = np.hstack((all_conti_x_fitted, all_categ_x_fitted))\n",
    "    # y = all_xy['label']\n",
    "    # x = np.array(x)\n",
    "    # y = np.array(y)\n",
    "    # print (x.shape, y.shape)\n",
    "    # return x, y\n",
    "    y = all_xy['label']\n",
    "    z_icustay_id = y.index\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z_icustay_id = np.array(z_icustay_id)\n",
    "\n",
    "    print (x.shape, y.shape)\n",
    "    return x, y, z_icustay_id, all_xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_model(pipe, param_grid, name, X_train, X_test,\n",
    "               y_train, y_test, scoring, verbose=0):\n",
    "    gs = GridSearchCV(estimator=pipe, param_grid=param_grid, scoring=scoring, cv=5, n_jobs=-1, verbose=verbose)\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    y_train_pred = gs.predict(X_train)\n",
    "    y_test_pred = gs.predict(X_test)\n",
    "\n",
    "    acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "    acc_test = accuracy_score(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_train, gs.predict_proba(X_train)[:, 1])\n",
    "    auc_train = auc(fpr, tpr)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, gs.predict_proba(X_test)[:, 1])\n",
    "    auc_test = auc(fpr, tpr)\n",
    "\n",
    "    confmat_train = confusion_matrix(y_true=y_train, y_pred=y_train_pred)\n",
    "    confmat_test = confusion_matrix(y_true=y_test, y_pred=y_test_pred)\n",
    "\n",
    "    print (' best parameter: ', gs.best_params_)\n",
    "    print (' training acc:%.2f auc:%.2f ' % (acc_train, auc_train))\n",
    "    print (' testing acc:%.2f auc:%.2f ' % (acc_test, auc_test))\n",
    "\n",
    "    print (' train confusion matrix:\\n', confmat_train)\n",
    "    print (' testing confusion matrix:\\n', confmat_test)\n",
    "    print (' classification report:\\n', classification_report(y_test, y_test_pred))\n",
    "\n",
    "    train_report = np.array(precision_recall_fscore_support(y_train, y_train_pred))\n",
    "    train_class1_report = train_report[:, 1]\n",
    "    train_metrics = list(train_class1_report[:-1])\n",
    "    train_metrics.extend([acc_train, auc_train])\n",
    "    print ('training metrics: precision, recall, f1-score, acc, auc')\n",
    "    print (train_metrics)\n",
    "\n",
    "    test_report = np.array(precision_recall_fscore_support(y_test, y_test_pred))\n",
    "    test_class1_report = test_report[:, 1]\n",
    "    test_metrics = list(test_class1_report[:-1])\n",
    "    test_metrics.extend([acc_test, auc_test])\n",
    "    print ('test metrics: precision, recall, f1-score, acc, auc')\n",
    "    print (test_metrics)\n",
    "\n",
    "    return train_metrics, test_metrics\n",
    "    \"\"\"\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate (recall)\")\n",
    "\n",
    "    plt.plot(fpr, tpr, label=\"acc:%f auc:%f\" % (acc_test, auc_test))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_train, gs.predict_proba(X_train)[:,1])\n",
    "    average_precision = average_precision_score(y_test, gs.predict_proba(X_test)[:,1])\n",
    "    plt.xlabel(\"precision\")\n",
    "    plt.ylabel(\"recall\")\n",
    "    plt.step(precision, recall, where='post', label='AP={0:0.2f}'.format(average_precision))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_dbdt(X_train, X_test, y_train, y_test, scoring):\n",
    "    gbm = GradientBoostingClassifier(learning_rate=0.05, n_estimators=120, min_samples_leaf=60,\n",
    "                                     max_features=9, subsample=0.7, random_state=10)\n",
    "\n",
    "    param_grid = {'max_depth': list(range(3, 14, 2)), 'min_samples_split': list(range(100, 801, 200))}\n",
    "    train_metrics, test_metrics = perf_model(gbm, param_grid, 'GBDT', X_train, X_test, y_train, y_test, scoring, 0)\n",
    "    return train_metrics, test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#issue im having is that \n",
    "\n",
    "def try_models_cross(X_train, X_test, y_train, y_test, scoring):#  select data cross 5 Fold\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, stratify=Y, random_state=RANDOM_STATE)\n",
    "    # \"\"\"\n",
    "    # print ('\\n\\nLinear Logistic Regression with L1 Penalty')\n",
    "    # lgr_l1_train_metrics, lgr_l1_test_metrics = try_lgr_l1(X_train, X_test, y_train, y_test, scoring)\n",
    "    #\n",
    "    # print ('\\n\\nLinear Logistic Regression with L2 Penalty')\n",
    "    # lgr_l2_train_metrics, lgr_l2_test_metrics = try_lgr_l2(X_train, X_test, y_train, y_test, scoring)\n",
    "    #\n",
    "    # print ('\\n\\nStochastic Gradient Descent')\n",
    "    # Elastic_train_metrics, Elastic_test_metrics = try_sgd(X_train, X_test, y_train, y_test, scoring)\n",
    "    #\n",
    "    # print ('\\n\\nRandom Forest')\n",
    "    # rf_train_metrics, rf_test_metrics = try_rf(X_train, X_test, y_train, y_test, scoring)\n",
    "    # #\n",
    "    print ('\\n\\nGradient Boosting Decision tree')\n",
    "    xgboost_train_metrics, xgboost_test_metrics = try_dbdt(X_train, X_test, y_train, y_test, scoring)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-19371be02faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mskf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.8 ms\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if __name__ == '__main__': #basically execute only if run as a script. i will unravel this so i can run it inline here\n",
    "\n",
    "#ge:reading in a file when running as script\n",
    "\n",
    "# path = './logs/individualization_24_1th.txt'\n",
    "# f = open(path, 'a+')\n",
    "# orig_stdout = sys.stdout\n",
    "# sys.stdout = f\n",
    "\n",
    "\n",
    "\n",
    "for time_interval in [24]:  # ,48,72,96,120,144]:\n",
    "    x, y, z_icustay_id, all_xy = preprocessing(folder, time_interval)  # all_xy is for compute gower distance\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    print '%%%%%'\n",
    "    num_fold = 0\n",
    "    for train_index, test_index in skf.split(x, y):\n",
    "        print '***************'\n",
    "        # print 'This is the '+ str(i)+' times result of '+str(n_fold)+' fold'\n",
    "        X_train_0, X_test_0 = x[train_index], x[test_index]\n",
    "        y_train_0, y_test_0 = y[train_index], y[test_index]\n",
    "\n",
    "        print '#####################'\n",
    "\n",
    "        num_fold = num_fold + 1\n",
    "        print 'this is the results of the %d fold in 5 folds:' %num_fold\n",
    "\n",
    "        print 'the number of testing samples in this fold:', test_index.size\n",
    "\n",
    "        train_z_icustay_id = z_icustay_id[train_index] # the icustay_id of samples in training set from 5 fold\n",
    "        test_z_icustay_id = z_icustay_id[test_index] # the icustay_id of samples in testing set from 5 fold\n",
    "\n",
    "        xg_one_fold_pred = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "        xg_one_fold_proba = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "        lr_one_fold_pred = [] # obtain the pred label of testing samples for one fold using lr\n",
    "        lr_one_fold_proba = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "        indicator_time = 0 # the indicator\n",
    "        for i, j in zip(test_z_icustay_id, test_index):\n",
    "            # i_index = np.where(test_z_icustay_id == i)\n",
    "            # tem_test_z_icustay_id = np.delete(test_z_icustay_id, i_index)\n",
    "            testing_sample_id = i\n",
    "\n",
    "            all_xy_0 = all_xy.loc[train_z_icustay_id] # select training samples from  5 fold\n",
    "            all_xy_training = all_xy_0.append(all_xy.loc[i]) # note that , containing the i\n",
    "\n",
    "            m = 400  # m is the number of similar cases or similar controls\n",
    "\n",
    "            X_test_00 = x[j]\n",
    "            y_test = y[j]\n",
    "\n",
    "            X_test = X_test_00.reshape(1, -1)\n",
    "\n",
    "            # print 'start selecting......'\n",
    "\n",
    "            Id_train_set = select_train_samples(testing_sample_id, all_xy_training, m, time_interval)  #  individulization\n",
    "\n",
    "            ix = np.isin(z_icustay_id, Id_train_set)\n",
    "            Id_train_set_index = list(np.where(ix))\n",
    "\n",
    "            # Id_train_set_index = np.argwhere(z_icustay_id == Id_train_set)\n",
    "\n",
    "            X_train = x[Id_train_set_index]\n",
    "            y_train = y[Id_train_set_index]\n",
    "\n",
    "            # print 'start training......'\n",
    "\n",
    "            # scoring = 'roc_auc'\n",
    "\n",
    "# xgboost\n",
    "\n",
    "            xgboost_mod = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "                          min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                          objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "            xgboost_mod.fit(X_train, y_train)\n",
    "            xg_y_pred = xgboost_mod.predict(X_test)\n",
    "            xg_y_pred_proba = xgboost_mod.predict_proba(X_test)[:,1]\n",
    "\n",
    "            xg_one_fold_pred.append(xg_y_pred)\n",
    "            xg_one_fold_proba.append(xg_y_pred_proba)\n",
    "\n",
    "# lr \n",
    "\n",
    "            logreg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "                                        intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "            logreg.fit(X_train, y_train)\n",
    "            lr_y_pred = logreg.predict(X_test)\n",
    "            lr_y_pred_proba = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "            lr_one_fold_pred.append(lr_y_pred)\n",
    "            lr_one_fold_proba.append(lr_y_pred_proba)\n",
    "\n",
    "            indicator_time = indicator_time + 1\n",
    "            # print 'the next testing sample and total samples:', indicator_time, test_index.size\n",
    "\n",
    "        xg_y_individual_pred = np.array(xg_one_fold_pred)\n",
    "        xg_y_individual_proba = np.array(xg_one_fold_proba)\n",
    "\n",
    "        lr_y_individual_pred = np.array(lr_one_fold_pred)\n",
    "        lr_y_individual_proba = np.array(lr_one_fold_proba)\n",
    "\n",
    "        one_fold_y_test = y[test_index]\n",
    "\n",
    "        print 'this is the result of individual predictor using xgboost:'\n",
    "        print 'the acc of one fold:', accuracy_score(one_fold_y_test, xg_y_individual_pred)\n",
    "        print 'the classification_report :', classification_report(one_fold_y_test, xg_y_individual_pred)\n",
    "        print 'the auc of one fold:', roc_auc_score(one_fold_y_test, xg_y_individual_proba)\n",
    "\n",
    "        print 'this is the result of individual predictor using lr:'\n",
    "        print 'the acc of one fold:', accuracy_score(one_fold_y_test, lr_y_individual_pred)\n",
    "        print 'the classification_report :', classification_report(one_fold_y_test, lr_y_individual_pred)\n",
    "        print 'the auc of one fold:', roc_auc_score(one_fold_y_test, lr_y_individual_pred)\n",
    "\n",
    "# using non-individual predictor for classification\n",
    "\n",
    "        xgboost_random = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "                                    min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                                    objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "        xgboost_random.fit(X_train_0, y_train_0)\n",
    "        y_pred_random = xgboost_random.predict(X_test_0)\n",
    "        y_proba_random = xgboost_random.predict_proba(X_test_0)[:,1]\n",
    "\n",
    "        y_test_random = y[test_index]\n",
    "\n",
    "        print 'this is the result of non-individual predictor using xgboost:'\n",
    "        print 'the acc is:',accuracy_score(y_test_random, y_pred_random)\n",
    "        print 'the classification_report:', classification_report(y_test_random, y_pred_random)\n",
    "        print 'the auc is:', roc_auc_score(y_test_random, y_proba_random)\n",
    "\n",
    "        logreg_random = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "                                    intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "        logreg_random.fit(X_train_0, y_train_0)\n",
    "        lr_y_pred_random = logreg_random.predict(X_test_0)\n",
    "        lr_y_pred_proba_random = logreg_random.predict_proba(X_test_0)[:, 1]\n",
    "\n",
    "        print 'this is the result of non-individual predictor using lr:'\n",
    "        print 'the acc is:',accuracy_score(y_test_random, lr_y_pred_random)\n",
    "        print 'the classification_report:', classification_report(y_test_random, lr_y_pred_random)\n",
    "        print 'the auc is:', roc_auc_score(y_test_random, lr_y_pred_proba_random)\n",
    "\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == '__main__': #basically execute only if run as a script. i will undo this\n",
    "#     path = './logs/individualization_24_1th.txt'\n",
    "#     f = open(path, 'a+')\n",
    "#     orig_stdout = sys.stdout\n",
    "#     sys.stdout = f\n",
    "#     for time_interval in [24]:  # ,48,72,96,120,144]:\n",
    "#         x, y, z_icustay_id, all_xy = preprocessing(folder, time_interval)  # all_xy is for compute gower distance\n",
    "\n",
    "#         skf = StratifiedKFold(n_splits=5)\n",
    "#         print '%%%%%'\n",
    "#         num_fold = 0\n",
    "#         for train_index, test_index in skf.split(x, y):\n",
    "#             print '***************'\n",
    "#             # print 'This is the '+ str(i)+' times result of '+str(n_fold)+' fold'\n",
    "#             X_train_0, X_test_0 = x[train_index], x[test_index]\n",
    "#             y_train_0, y_test_0 = y[train_index], y[test_index]\n",
    "\n",
    "#             print '#####################'\n",
    "\n",
    "#             num_fold = num_fold + 1\n",
    "#             print 'this is the results of the %d fold in 5 folds:' %num_fold\n",
    "\n",
    "#             print 'the number of testing samples in this fold:', test_index.size\n",
    "\n",
    "#             train_z_icustay_id = z_icustay_id[train_index] # the icustay_id of samples in training set from 5 fold\n",
    "#             test_z_icustay_id = z_icustay_id[test_index] # the icustay_id of samples in testing set from 5 fold\n",
    "\n",
    "#             xg_one_fold_pred = [] # obtain the pred label of testing samples for one fold using xgboost\n",
    "#             xg_one_fold_proba = [] # obtain the proba  of testing samples for one fold using xgboost\n",
    "\n",
    "#             lr_one_fold_pred = [] # obtain the pred label of testing samples for one fold using lr\n",
    "#             lr_one_fold_proba = [] # obtain the proba  of testing samples for one fold using lr\n",
    "\n",
    "#             indicator_time = 0 # the indicator\n",
    "#             for i, j in zip(test_z_icustay_id, test_index):\n",
    "#                 # i_index = np.where(test_z_icustay_id == i)\n",
    "#                 # tem_test_z_icustay_id = np.delete(test_z_icustay_id, i_index)\n",
    "#                 testing_sample_id = i\n",
    "\n",
    "#                 all_xy_0 = all_xy.loc[train_z_icustay_id] # select training samples from  5 fold\n",
    "#                 all_xy_training = all_xy_0.append(all_xy.loc[i]) # note that , containing the i\n",
    "\n",
    "#                 m = 400  # m is the number of similar cases or similar controls\n",
    "\n",
    "#                 X_test_00 = x[j]\n",
    "#                 y_test = y[j]\n",
    "\n",
    "#                 X_test = X_test_00.reshape(1, -1)\n",
    "\n",
    "#                 # print 'start selecting......'\n",
    "\n",
    "#                 Id_train_set = select_train_samples(testing_sample_id, all_xy_training, m, time_interval)  #  individulization\n",
    "\n",
    "#                 ix = np.isin(z_icustay_id, Id_train_set)\n",
    "#                 Id_train_set_index = list(np.where(ix))\n",
    "\n",
    "#                 # Id_train_set_index = np.argwhere(z_icustay_id == Id_train_set)\n",
    "\n",
    "#                 X_train = x[Id_train_set_index]\n",
    "#                 y_train = y[Id_train_set_index]\n",
    "\n",
    "#                 # print 'start training......'\n",
    "\n",
    "#                 # scoring = 'roc_auc'\n",
    "\n",
    "# # xgboost\n",
    "\n",
    "#                 xgboost_mod = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "#                               min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#                               objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "#                 xgboost_mod.fit(X_train, y_train)\n",
    "#                 xg_y_pred = xgboost_mod.predict(X_test)\n",
    "#                 xg_y_pred_proba = xgboost_mod.predict_proba(X_test)[:,1]\n",
    "\n",
    "#                 xg_one_fold_pred.append(xg_y_pred)\n",
    "#                 xg_one_fold_proba.append(xg_y_pred_proba)\n",
    "\n",
    "# # lr \n",
    "\n",
    "#                 logreg = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "#                                             intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "#                 logreg.fit(X_train, y_train)\n",
    "#                 lr_y_pred = logreg.predict(X_test)\n",
    "#                 lr_y_pred_proba = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "#                 lr_one_fold_pred.append(lr_y_pred)\n",
    "#                 lr_one_fold_proba.append(lr_y_pred_proba)\n",
    "\n",
    "#                 indicator_time = indicator_time + 1\n",
    "#                 # print 'the next testing sample and total samples:', indicator_time, test_index.size\n",
    "\n",
    "#             xg_y_individual_pred = np.array(xg_one_fold_pred)\n",
    "#             xg_y_individual_proba = np.array(xg_one_fold_proba)\n",
    "\n",
    "#             lr_y_individual_pred = np.array(lr_one_fold_pred)\n",
    "#             lr_y_individual_proba = np.array(lr_one_fold_proba)\n",
    "\n",
    "#             one_fold_y_test = y[test_index]\n",
    "\n",
    "#             print 'this is the result of individual predictor using xgboost:'\n",
    "#             print 'the acc of one fold:', accuracy_score(one_fold_y_test, xg_y_individual_pred)\n",
    "#             print 'the classification_report :', classification_report(one_fold_y_test, xg_y_individual_pred)\n",
    "#             print 'the auc of one fold:', roc_auc_score(one_fold_y_test, xg_y_individual_proba)\n",
    "\n",
    "#             print 'this is the result of individual predictor using lr:'\n",
    "#             print 'the acc of one fold:', accuracy_score(one_fold_y_test, lr_y_individual_pred)\n",
    "#             print 'the classification_report :', classification_report(one_fold_y_test, lr_y_individual_pred)\n",
    "#             print 'the auc of one fold:', roc_auc_score(one_fold_y_test, lr_y_individual_pred)\n",
    "\n",
    "# # using non-individual predictor for classification\n",
    "\n",
    "#             xgboost_random = XGBClassifier(learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "#                                         min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#                                         objective='binary:logistic', nthread=4, scale_pos_weight=1, seed=27)\n",
    "#             xgboost_random.fit(X_train_0, y_train_0)\n",
    "#             y_pred_random = xgboost_random.predict(X_test_0)\n",
    "#             y_proba_random = xgboost_random.predict_proba(X_test_0)[:,1]\n",
    "\n",
    "#             y_test_random = y[test_index]\n",
    "\n",
    "#             print 'this is the result of non-individual predictor using xgboost:'\n",
    "#             print 'the acc is:',accuracy_score(y_test_random, y_pred_random)\n",
    "#             print 'the classification_report:', classification_report(y_test_random, y_pred_random)\n",
    "#             print 'the auc is:', roc_auc_score(y_test_random, y_proba_random)\n",
    "\n",
    "#             logreg_random = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=10, fit_intercept=True,\n",
    "#                                         intercept_scaling=1, class_weight='balanced', random_state=None)\n",
    "#             logreg_random.fit(X_train_0, y_train_0)\n",
    "#             lr_y_pred_random = logreg_random.predict(X_test_0)\n",
    "#             lr_y_pred_proba_random = logreg_random.predict_proba(X_test_0)[:, 1]\n",
    "\n",
    "#             print 'this is the result of non-individual predictor using lr:'\n",
    "#             print 'the acc is:',accuracy_score(y_test_random, lr_y_pred_random)\n",
    "#             print 'the classification_report:', classification_report(y_test_random, lr_y_pred_random)\n",
    "#             print 'the auc is:', roc_auc_score(y_test_random, lr_y_pred_proba_random)\n",
    "\n",
    "#             # break\n",
    "#     sys.stdout = orig_stdout\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to have a robust evaluation of model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## need to try cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
