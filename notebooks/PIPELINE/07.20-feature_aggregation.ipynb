{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the purpose of this notebook is to take the big dataframe created in 07.01-baseline_data_merging, and make an aggregate we can use for our baseline \"worst case\" scenario model. This will then be fed into R, where we will use the MICE package to impute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changelog:\n",
    "\n",
    "* 4/16/19: added newagg\n",
    "* 4/17/19: reformatted the ordering of how code runs, and variable names. added aggregation #3.\n",
    "* 4/19/19: changed the standardizing so that log(x+1) is now applied prior to standardization. also removed ordinal variables from standardizing algorithm and concat them in later with median 0 and iqr 1 so standardize value is either 0 or 1. values from ordinal are not log transformed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/14/19:\n",
    "# prior to this point my pipeline:\n",
    "1. first median standardized\n",
    "2. aggregated\n",
    "3. converted to 2class\n",
    "4. train/test split\n",
    "5. imputed\n",
    "\n",
    "\n",
    "# a big change will happen in this notebook, I will first:\n",
    "1. convert to two class (c-/abshort &c+/ablong)\n",
    "2. split the train and test set\n",
    "3. median standardize\n",
    "4. aggregate\n",
    "5. impute\n",
    "BEFORE I AGGREGATE and median standardize, as some information may be leaking from the train/test set as i had it previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last run: 6/14/19: sensitivity analysis 3day timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 17.2 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp'\", use \"location='/tmp'\" instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import train_test_split\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 96 ms\n"
     ]
    }
   ],
   "source": [
    "#cohort import\n",
    "\n",
    "os.chdir('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling') #use to change working directory\n",
    "wd= os.getcwd() #'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling'\n",
    "\n",
    "\n",
    "most_updated_patient_df= \"04042019\"\n",
    "final_pt_df2 = pd.read_csv('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/raw/csv/%s_final_pt_df2.csv'%(most_updated_patient_df), index_col=0) #only for patients with minimum vitals, 14478 icustay_id\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11987"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.91 ms\n"
     ]
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.03 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# # ##24 hr sensitivity\n",
    "# # #importing in all clinical_variable files\n",
    "# lower_window=0\n",
    "# upper_window=1\n",
    "# time_col=\"charttime\"\n",
    "# time_var=\"t_0\"\n",
    "# folder=\"24_hr_window\"\n",
    "# timewindowdays=\"24\"\n",
    "# date= '09062019'\n",
    "# patient_df= final_pt_df2\n",
    "\n",
    "# #48 hr sensitivity\n",
    "# lower_window=0\n",
    "# upper_window=2\n",
    "# time_var=\"t_0\"\n",
    "# folder=\"48_hr_window\"\n",
    "# timewindowdays=\"48\"\n",
    "# date='16052019'\n",
    "# time_col=\"charttime\"\n",
    "# time_var= 't_0'\n",
    "# patient_df= final_pt_df2\n",
    "\n",
    "#72 hr elixhauser-redo\n",
    "date='11062019'\n",
    "lower_window=0\n",
    "upper_window=3\n",
    "timewindowdays=\"72\"\n",
    "folder=\"{}_hr_window\".format(timewindowdays)\n",
    "time_col=\"charttime\"\n",
    "time_var= 't_0'\n",
    "patient_df= final_pt_df2\n",
    "\n",
    "\n",
    "os.chdir(r'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/processed/')\n",
    "big_df= pd.read_csv(Path(wd+'/data/processed/merged/{}_longdf_preImp_{}.csv'.format(date,timewindowdays),  index_col=0))\n",
    "big_df= big_df.reset_index(drop=True).iloc[:,1:]\n",
    "\n",
    "#quick housekeeping addition to accomidate older generated data\n",
    "if len(big_df.loc[big_df['label']==\"pao2/fio2\",'label'])>1:\n",
    "    big_df.loc[big_df['label']==\"pao2/fio2\",'label']=\"pao2fio2ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "## last minute data cleaning/formatting\n",
    "\n",
    "# #removing firstpos else neg ssc col\n",
    "# big_df=big_df.loc[:,list(big_df.columns!=\"first_pos_else_neg_ssc\")]\n",
    "# #changing pao2/fio2 ratio label\n",
    "\n",
    "len(big_df.loc[big_df['label']==\"pao2/fio2\",'label'])>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>leukocyte</th>\n",
       "      <td>11016</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>9554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasopressin</th>\n",
       "      <td>12766</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rrt</th>\n",
       "      <td>11017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenylephrine</th>\n",
       "      <td>18415</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer_elix</th>\n",
       "      <td>11017</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2_flow</th>\n",
       "      <td>11155</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norepinephrine</th>\n",
       "      <td>23224</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitrite</th>\n",
       "      <td>11016</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>10725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dobutamine</th>\n",
       "      <td>11753</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dopamine</th>\n",
       "      <td>13976</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinephrine</th>\n",
       "      <td>11956</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>11017</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>6028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_recieved</th>\n",
       "      <td>10914</td>\n",
       "      <td>3</td>\n",
       "      <td>Mech</td>\n",
       "      <td>5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pco2</th>\n",
       "      <td>11017</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>6969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bands</th>\n",
       "      <td>11017</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>11017</td>\n",
       "      <td>5</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>7986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_elix</th>\n",
       "      <td>11851</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mingcs</th>\n",
       "      <td>4482</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_sofa</th>\n",
       "      <td>23858</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>4448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>35029</td>\n",
       "      <td>55</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resprate</th>\n",
       "      <td>558756</td>\n",
       "      <td>68</td>\n",
       "      <td>20.0</td>\n",
       "      <td>45200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>40420</td>\n",
       "      <td>77</td>\n",
       "      <td>139.0</td>\n",
       "      <td>3605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>38608</td>\n",
       "      <td>81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>48926</td>\n",
       "      <td>94</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>41906</td>\n",
       "      <td>99</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spo2</th>\n",
       "      <td>510797</td>\n",
       "      <td>101</td>\n",
       "      <td>100.0</td>\n",
       "      <td>118984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>7229</td>\n",
       "      <td>118</td>\n",
       "      <td>177.8</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calcium</th>\n",
       "      <td>17603</td>\n",
       "      <td>155</td>\n",
       "      <td>1.13</td>\n",
       "      <td>914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>36748</td>\n",
       "      <td>159</td>\n",
       "      <td>9.8</td>\n",
       "      <td>867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inr</th>\n",
       "      <td>22815</td>\n",
       "      <td>162</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>34945</td>\n",
       "      <td>171</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bun</th>\n",
       "      <td>34807</td>\n",
       "      <td>189</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diasbp</th>\n",
       "      <td>515736</td>\n",
       "      <td>190</td>\n",
       "      <td>56.0</td>\n",
       "      <td>16401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartrate</th>\n",
       "      <td>532852</td>\n",
       "      <td>193</td>\n",
       "      <td>80.0</td>\n",
       "      <td>14003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysbp</th>\n",
       "      <td>517868</td>\n",
       "      <td>232</td>\n",
       "      <td>108.0</td>\n",
       "      <td>9783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>22567</td>\n",
       "      <td>262</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilirubin</th>\n",
       "      <td>10516</td>\n",
       "      <td>352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>159152</td>\n",
       "      <td>518</td>\n",
       "      <td>36.6666666666667</td>\n",
       "      <td>4340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanartpress</th>\n",
       "      <td>523930</td>\n",
       "      <td>572</td>\n",
       "      <td>72.0</td>\n",
       "      <td>13949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>127381</td>\n",
       "      <td>645</td>\n",
       "      <td>110.0</td>\n",
       "      <td>1355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbc</th>\n",
       "      <td>30894</td>\n",
       "      <td>689</td>\n",
       "      <td>8.1</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelet</th>\n",
       "      <td>31943</td>\n",
       "      <td>829</td>\n",
       "      <td>150.0</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <td>11017</td>\n",
       "      <td>898</td>\n",
       "      <td>476.0</td>\n",
       "      <td>6970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptt</th>\n",
       "      <td>23930</td>\n",
       "      <td>1149</td>\n",
       "      <td>150.0</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>10017</td>\n",
       "      <td>1306</td>\n",
       "      <td>70.0</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first_admit_age</th>\n",
       "      <td>11017</td>\n",
       "      <td>4578</td>\n",
       "      <td>300.0</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count unique                top    freq\n",
       "label                                                    \n",
       "leukocyte         11016      2     Neg/Not_tested    9554\n",
       "vasopressin       12766      2                0.0   10735\n",
       "rrt               11017      2                0.0   10176\n",
       "phenylephrine     18415      2                0.0    9382\n",
       "cancer_elix       11017      2                0.0    9660\n",
       "o2_flow           11155      2                0.0   10550\n",
       "norepinephrine    23224      2                1.0   14334\n",
       "nitrite           11016      2     Neg/Not_tested   10725\n",
       "dobutamine        11753      2                0.0   10858\n",
       "dopamine          13976      2                0.0   10388\n",
       "epinephrine       11956      2                0.0   10813\n",
       "gender            11017      2                  M    6028\n",
       "vent_recieved     10914      3               Mech    5439\n",
       "pco2              11017      3             absent    6969\n",
       "bands             11017      3             absent    9276\n",
       "ethnicity         11017      5  white/nonhispanic    7986\n",
       "sum_elix          11851     13                0.0    7774\n",
       "mingcs             4482     13               15.0    1672\n",
       "daily_sofa        23858     22                  1    4448\n",
       "bicarbonate       35029     55               23.0    2847\n",
       "resprate         558756     68               20.0   45200\n",
       "sodium            40420     77              139.0    3605\n",
       "chloride          38608     81              106.0    2480\n",
       "potassium         48926     94                4.0    3412\n",
       "ph                41906     99                7.4    2210\n",
       "spo2             510797    101              100.0  118984\n",
       "height             7229    118              177.8     464\n",
       "calcium           17603    155               1.13     914\n",
       "hemoglobin        36748    159                9.8     867\n",
       "inr               22815    162                1.2    3375\n",
       "creatinine        34945    171                0.7    2921\n",
       "bun               34807    189               14.0    1040\n",
       "diasbp           515736    190               56.0   16401\n",
       "heartrate        532852    193               80.0   14003\n",
       "sysbp            517868    232              108.0    9783\n",
       "lactate           22567    262                1.2    1032\n",
       "bilirubin         10516    352                0.4     899\n",
       "temperature      159152    518   36.6666666666667    4340\n",
       "meanartpress     523930    572               72.0   13949\n",
       "glucose          127381    645              110.0    1355\n",
       "wbc               30894    689                8.1     262\n",
       "platelet          31943    829              150.0     145\n",
       "pao2fio2ratio     11017    898              476.0    6970\n",
       "ptt               23930   1149              150.0     607\n",
       "weight            10017   1306               70.0     185\n",
       "first_admit_age   11017   4578              300.0     652"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "#overview of all variables and formats\n",
    "big_df.groupby('label')['value'].describe().sort_values('unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.48 ms\n"
     ]
    }
   ],
   "source": [
    "#convert to two class\n",
    "\n",
    "final_pt_df2['final_bin'].unique()\n",
    "two_classes=['C_neg/A_partial','C_pos/A_full']\n",
    "two_class_icu=final_pt_df2.loc[final_pt_df2.loc[:,\"final_bin\"].isin(two_classes),['icustay_id','subject_id','final_bin']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 729 ms\n"
     ]
    }
   ],
   "source": [
    "big_df=big_df.loc[big_df['icustay_id'].isin(list(two_class_icu['icustay_id'])),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5877"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "len(big_df)#7015776 -> ~3000000\n",
    "big_df['icustay_id'].nunique() #14181 ->7588"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roundabout way of sampling train/test set so that each subject is only in either train or test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "# label each subject_id with the max of the two classes. \n",
    "two_class_pt=two_class_icu.copy()\n",
    "two_class_pt['final_bin']=pd.factorize(two_class_pt['final_bin'])[0]\n",
    "two_class_maxsub=two_class_pt.loc[two_class_pt.groupby('subject_id')['final_bin'].idxmax(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 713 ms\n"
     ]
    }
   ],
   "source": [
    "# 70/30 train/test set split with 12345=seed, splitting on max final bin of each SUBJECT_ID\n",
    "train, test = train_test_split(two_class_maxsub, test_size=0.3, random_state=12345, \n",
    "                               stratify=two_class_maxsub['final_bin'])\n",
    "# generate list of each SUBJECT_ID in each split\n",
    "train_subject=list(train['subject_id'])\n",
    "test_subject=list(test['subject_id'])\n",
    "\n",
    "#filtering big_df on train subjects and test subjects to get my train/test splits.\n",
    "big_df_train= big_df.loc[big_df.loc[:,'subject_id'].isin(train_subject),:].copy()\n",
    "big_df_test= big_df.loc[big_df.loc[:,'subject_id'].isin(test_subject),:].copy()\n",
    "del big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 ms\n"
     ]
    }
   ],
   "source": [
    "# #converting venttype to category\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']= big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].astype('category')\n",
    "# #big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].apply(astype('category'))\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'] = pd.Categorical(big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.5 ms\n"
     ]
    }
   ],
   "source": [
    "def category_mapper(big_df):\n",
    "    #converting categories to integers\n",
    "    mapper={'Mech':2 , 'Oxygen': 1, 'None': 0}\n",
    "    big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']=big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].replace(mapper).copy()\n",
    "\n",
    "    #gender_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='gender','value'])[1]\n",
    "    mapper={'F':0 , 'M': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='gender','value']=big_df.loc[big_df.loc[:,'label']=='gender','value'].replace(mapper).copy()\n",
    "\n",
    "    #leukocyte_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='leukocyte','value']=big_df.loc[big_df.loc[:,'label']=='leukocyte','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[0] \n",
    "\n",
    "    #nitrite_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='nitrite','value']=big_df.loc[big_df.loc[:,'label']=='nitrite','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[0] \n",
    "    \n",
    "    \n",
    "    # changing pao2/fio2 ratio to a category\n",
    "    \"\"\"\n",
    "    A PaO2/FiO2 ratio less than or equal to 200 is necessary for the diagnosis of acute respiratory distress syndrome by the AECC criteria.[6] \n",
    "    The more recent Berlin criteria defines mild ARDS at a ratio of <300.\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 250 is one of the minor criteria for severe community acquired pneumonia (i.e., possible indication for inpatient treatment).\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 333 is one of the variables in the SMART-COP risk score for intensive respiratory or vasopressor support in community-acquired pneumonia.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    pd.to_numeric(big_df[big_df['label']==\"pao2fio2ratio\"]['value'])\n",
    "    labels= ['0-200', '201-333', \"334-475\",\"476+\"]\n",
    "    bins = pd.IntervalIndex.from_tuples([(0, 200), (200, 333), (333, 475),(475,3000)])\n",
    "\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']=pd.cut(pd.to_numeric(big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']), bins,right=False, labels=labels)\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value'].value_counts()\n",
    "\n",
    "    \n",
    "    return(big_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.79 s\n"
     ]
    }
   ],
   "source": [
    "big_df_train=category_mapper(big_df_train)\n",
    "big_df_test=category_mapper(big_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1997\n",
       "2    1801\n",
       "0     272\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 65.3 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='vent_recieved','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2269\n",
       "0    1851\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69.2 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    3581\n",
       "<10        332\n",
       ">10        207\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 69.6 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='bands','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    2818\n",
       "<50        939\n",
       ">50        363\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 71.6 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pco2','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2269\n",
       "0    1851\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 70 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    1284\n",
       "(333, 475]      177\n",
       "(0, 200]        151\n",
       "(200, 333]      145\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 34.9 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_test.loc[big_df_test.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    3092\n",
       "(0, 200]        362\n",
       "(333, 475]      354\n",
       "(200, 333]      312\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 70 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc median/iqr for standardization\n",
    "take all non-categorical variables for HEALTHY PATIENTS and calculate the median and IQR for them. then will use this to make z scores via: x-median/IQR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### june 13: changed sparse to catgorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.6 ms\n"
     ]
    }
   ],
   "source": [
    "continuous=['daily_sofa',\n",
    "            'lactate',\n",
    "            'mingcs',\n",
    "            'diasbp',\n",
    "            'heartrate',\n",
    "            'meanartpress',\n",
    "            'resprate',\n",
    "            'sysbp',\n",
    "            'temperature',\n",
    "            'hemoglobin',\n",
    "            'platelet',\n",
    "            'wbc',\n",
    "            'calcium',\n",
    "            'glucose',\n",
    "            'ph',\n",
    "            'bicarbonate',\n",
    "            'bun',\n",
    "            'chloride',\n",
    "            'creatinine',\n",
    "            'inr',\n",
    "            'potassium',\n",
    "            'ptt',\n",
    "            'sodium',\n",
    "            'bilirubin',\n",
    "            'spo2',\n",
    "            'sum_elix']\n",
    "\n",
    "\n",
    "onetime=['first_admit_age','height','weight']\n",
    "\n",
    "vaso_active=['phenylephrine',\n",
    "            'norepinephrine',\n",
    "            'vasopressin',\n",
    "            'dobutamine',\n",
    "            'dopamine',\n",
    "            'epinephrine'] \n",
    "\n",
    "ordinal=[\n",
    "            'leukocyte',\n",
    "            'nitrite',\n",
    "            'vent_recieved',\n",
    "            'o2_flow',\n",
    "            'rrt',\n",
    "            'pao2fio2ratio',\n",
    "            'cancer_elix',\n",
    "            \"any_vasoactives\",\n",
    "            'bands', #added 6/13/19\n",
    "            'pco2' #added 6/13/19\n",
    "]\n",
    "\n",
    "categorical=[\n",
    "            \"ethnicity\",\n",
    "            'gender'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 358 ms\n"
     ]
    }
   ],
   "source": [
    "def median_label_fxn(big_df):\n",
    "    global final_pt_df2\n",
    "    \n",
    "    healthy_pt=list(final_pt_df2[final_pt_df2['final_bin']==\"C_neg/A_partial\"]['icustay_id'])\n",
    "\n",
    "    #filter to only healthy patients filter\n",
    "    ##splitting big_df, making a copy and restricting it to all values that will be usd in standardizing\n",
    "    healthy_df=big_df[big_df['label'].isin(continuous+onetime)].copy()\n",
    "    healthy_df['value']= pd.to_numeric(healthy_df['value']) #converting to numeric \n",
    "    healthy_df=healthy_df[healthy_df['icustay_id'].isin(healthy_pt)].copy() #only numerical values for cneg/ab partial pt\n",
    "    \n",
    "    #finding the last 24 hours of each healthy patient.\n",
    "    healthy_pt_end=pd.DataFrame(healthy_df.groupby(\"icustay_id\")['delta'].max())\n",
    "    healthy_pt_end[\"start\"]=healthy_pt_end['delta']- pd.to_timedelta(\"1 day 00:00:00\")\n",
    "    healthy_pt_end=healthy_pt_end.rename(columns={\"delta\":\"end\"}).reset_index()\n",
    "    healthy_df= pd.merge(healthy_df,healthy_pt_end, left_on=\"icustay_id\", right_on=\"icustay_id\", how=\"left\" ) #now have the last 24 hours annotated for each patient as start and end.\n",
    "    \n",
    "    #calculating medians and iqr for each label based on healthy patient's last 24 hours in icu\n",
    "    median_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].median())).reset_index()\n",
    "    median_label=median_label.rename(columns={'value':\"median\"})\n",
    "    iqr_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].quantile(0.75)-healthy_df.groupby(\"label\")['value'].quantile(0.25))).reset_index()\n",
    "    iqr_label=iqr_label.rename(columns={'value':\"iqr\"})\n",
    "    median_label=pd.merge(median_label,iqr_label)  #final median df\n",
    "    return(median_label)\n",
    "\n",
    "def combine_vasoactives(big_noCat, median_label):\n",
    "    global vaso_active\n",
    "    ##combining vasoactives\n",
    "    vaso_active_df=big_noCat[big_noCat['label'].isin(vaso_active)].groupby('icustay_id')['value'].max().reset_index()\n",
    "    vaso_active_df['uom']=\"y/n\"\n",
    "    vaso_active_df['label']=\"any_vasoactives\"\n",
    "    vaso_active_df['delta']=pd.to_timedelta(\"0days\")\n",
    "    vaso_active_df['source']=\"any_vasoactives\"\n",
    "\n",
    "    vaso_active_df=pd.merge(vaso_active_df, final_pt_df2[[\"icustay_id\",'subject_id',\"t_0\"]], how=\"left\", left_on=\"icustay_id\", right_on=\"icustay_id\")\n",
    "    vaso_active_df=pd.merge(vaso_active_df, median_label, how=\"left\").fillna(0)\n",
    "    vaso_active_df['standardize']=vaso_active_df['value']\n",
    "    vaso_active_df['raw_value']=vaso_active_df['value']\n",
    "    vaso_active_df.head()\n",
    "\n",
    "    # # #grabing the rest of the variables not suitable for range or mean/std\n",
    "    big_noCat=pd.concat([big_noCat, vaso_active_df], sort=False)\n",
    "    return(big_noCat)\n",
    "\n",
    "def standardization_fxn(big_df):\n",
    "    global continuous, onetime, vaso_active, ordinal, categorical\n",
    "    \n",
    "    median_label=median_label_fxn(big_df)\n",
    "    \n",
    "    ### dataformatting: convert all dtypes to a numeric type that pereserves nan. \n",
    "    #splitting categorical, ordinal and continuous\n",
    "    big_categorical= big_df.loc[big_df.loc[:,'label'].isin(categorical),:].copy() \n",
    "\n",
    "    #continuous and ordinal variables\n",
    "    big_noCat= big_df.loc[big_df.loc[:,'label'].isin(continuous),:].copy() \n",
    "    big_noCat['value']= big_noCat['value'].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better. \n",
    "    \n",
    "    ### adding a standardized value (x-median)/iqr  where median is of the last 24 hours in time window for culture neg/ ab partial patients \n",
    "    big_noCat=pd.merge(big_noCat, median_label, how=\"left\") \n",
    "    #loging values\n",
    "    big_noCat['median']= np.log(big_noCat['median']+1.0)\n",
    "    big_noCat['iqr']= np.log(big_noCat['iqr']+1.0)\n",
    "    big_noCat['raw_value']=big_noCat['value']\n",
    "    big_noCat['value']=np.log(big_noCat['value']+1.0)\n",
    "    \n",
    "    big_noCat['standardize']=((big_noCat['value']-big_noCat['median'])/big_noCat['iqr']).fillna(0) #standardize is log standardized\n",
    "\n",
    "    #making an ordinal df to concat on\n",
    "    ord_df=big_df.loc[big_df.loc[:,'label'].isin(ordinal+vaso_active),:].copy()\n",
    "    ord_df['raw_value']=ord_df['value']\n",
    "    ord_df['standardize']=ord_df['value']\n",
    "    ord_df['median']=None\n",
    "    ord_df['iqr']=None\n",
    "\n",
    "    big_noCat=pd.concat([big_noCat,ord_df], sort=False)\n",
    "    \n",
    "    #making all ordinal values in standardize equal to unstandardized\n",
    "    big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'standardize']=big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'value']  #do i need to add sparse?\n",
    "    #ig_noCat.head()\n",
    "    \n",
    "    big_noCat['standardize']= big_noCat['standardize'].apply(pd.to_numeric, args=('coerce',)) #errors occuring downstream due to not having numeric, trying this 4/18/19\n",
    "    \n",
    "    ##last step, combining vasoactives into 1 feature\n",
    "    big_noCat=combine_vasoactives(big_noCat, median_label)  \n",
    "\n",
    "    return(big_noCat, big_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train, cat_df_train = standardization_fxn(big_df_train)\n",
    "noCat_df_test, cat_df_test = standardization_fxn(big_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 694 Âµs\n"
     ]
    }
   ],
   "source": [
    "#noCat_df_train[noCat_df_train['label']=='any_vasoactives'].head()#.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation1:\n",
    "### clincally guided min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "hi_value= [#'bands',\n",
    "'bilirubin',\n",
    "'bun',\n",
    "'chloride',\n",
    "'creatinine',\n",
    "'daily_sofa',\n",
    "'glucose',\n",
    "'heartrate',\n",
    "'inr',\n",
    "'lactate',\n",
    "#'pco2',\n",
    "'potassium',\n",
    "'ptt',\n",
    "'resprate',\n",
    "'temperature',\n",
    "'weight', 'rrt', \n",
    "'phenylephrine', 'norepinephrine', 'vasopressin', 'dobutamine', 'dopamine', 'epinephrine',  #added this and removed individual vasoactive 5/3/19\n",
    "'first_admit_age','leukocyte','nitrite','vent_recieved','o2_flow', \n",
    "'any_vasoactives', #added this and removed individual vasoactive 5/3/19\n",
    "'sum_elix', #added 6/4/19\n",
    "'cancer_elix'  ]#added 6/4/19\n",
    "\n",
    "low_value=['bicarbonate',\n",
    "'diasbp',\n",
    "'hemoglobin',\n",
    "'meanartpress',\n",
    "'mingcs',\n",
    "'ph',\n",
    "'platelet',\n",
    "'spo2',\n",
    "'sysbp']\n",
    "\n",
    "both_value=['calcium',\n",
    "'sodium',\n",
    "'wbc']\n",
    "\n",
    "#important_ordinal=[\"any_vasoactives\"]\n",
    "important_onetime=['first_admit_age','weight','pao2fio2ratio', 'pco2','bands'] #added pco2 and bands here, removed them above 06/14/19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daily_sofa', 'diasbp', 'glucose', 'heartrate', 'meanartpress',\n",
       "       'resprate', 'spo2', 'sum_elix', 'sysbp', 'temperature',\n",
       "       'bicarbonate', 'bun', 'chloride', 'creatinine', 'hemoglobin',\n",
       "       'inr', 'platelet', 'potassium', 'ptt', 'sodium', 'wbc', 'calcium',\n",
       "       'lactate', 'ph', 'bilirubin', 'mingcs', 'bands', 'cancer_elix',\n",
       "       'dopamine', 'epinephrine', 'norepinephrine', 'phenylephrine',\n",
       "       'rrt', 'vasopressin', 'vent_recieved', 'dobutamine', 'o2_flow',\n",
       "       'pao2fio2ratio', 'pco2', 'leukocyte', 'nitrite', 'any_vasoactive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.3 ms\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train['label'].unique()#noCat_df_train['label']=='any_vasoactives'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running the min/max aggregations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 123 ms\n"
     ]
    }
   ],
   "source": [
    "def merge_cat_agg(num_df, cat_df, ):\n",
    "    \"\"\"\n",
    "    merges the categorical and aggregated dataframes together. \n",
    "    \"\"\"\n",
    "    \n",
    "    worst_df=pd.merge(num_df, cat_df, left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    worst_df['ethnicity']=worst_df['ethnicity'].astype(\"category\")\n",
    "    worst_df['gender']=worst_df['gender'].astype(\"category\")\n",
    "    \n",
    "    return(worst_df)\n",
    "\n",
    "def clin_agg(big_noCat, big_cat,big_df, values=\"standardize\"):\n",
    "    \"\"\"\n",
    "    clincally guided aggregations.\n",
    "    \n",
    "    values= choose here if wanna use standardization or raw values.\n",
    "    \n",
    "    note: getting two minor errors, could use some cleaning up at later date.\n",
    "    \"\"\"\n",
    "    global hi_value, low_value, both_value, important_onetime\n",
    "    #max aggregation for selected variables\n",
    "    big_max= big_noCat.loc[big_noCat.loc[:,'label'].isin(hi_value),:]\n",
    "    table = pd.pivot_table(big_max, values=values, columns='label', index=['icustay_id'],aggfunc=max, dropna=False)\n",
    "    \n",
    "    #min aggregation for selected variables\n",
    "    big_min= big_noCat.loc[big_noCat.loc[:,'label'].isin(low_value),:]\n",
    "    table2 = pd.pivot_table(big_min, values=values, columns='label', index=['icustay_id'],aggfunc=min, dropna=False)\n",
    "    \n",
    "    #max&min aggregation for selected variables\n",
    "    big_both= big_noCat.loc[big_noCat.loc[:,'label'].isin(both_value),:]\n",
    "    table3 = pd.pivot_table(big_both, values=values, columns='label', index=['icustay_id'],aggfunc=[max,min], dropna=False)\n",
    "    \n",
    "    #first left join all different continuous aggregations together. \n",
    "    worst_df=pd.merge(table.reset_index(), table2.reset_index(), how='left')\n",
    "    worst_df=pd.merge(worst_df, table3.reset_index(), left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    \n",
    "    ### formatting categorical to wide format to match the tables/worst_df\n",
    "    big_cat= big_cat.pivot(\n",
    "    index='icustay_id',\n",
    "    values='value',\n",
    "    columns='label').reset_index() #need to convert to wide format. should be one row per patient per time. \n",
    "    \n",
    "    ## merging the categorical and aggregated dataframes together. \n",
    "    worst_df=merge_cat_agg(worst_df, big_cat) #using max/min aggregates \n",
    "\n",
    "    #adding important one_time values to final aggregated\n",
    "    agg_remaining= big_df.loc[big_df.loc[:,'label'].isin(important_onetime),:]\n",
    "    agg_table2 = pd.pivot_table(agg_remaining, values='value', columns='label', index=['icustay_id'],aggfunc=[max], dropna=False) \n",
    "    agg_table2.columns = agg_table2.columns.get_level_values(1)\n",
    "    agg_table2=agg_table2.reset_index()\n",
    "    agg_table2.head()#.rename(columns={})\n",
    "\n",
    "    worst_df=pd.merge(worst_df, agg_table2, how='left')\n",
    "    return(worst_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "worst_df_train=clin_agg(noCat_df_train, cat_df_train,big_df_train, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "worst_df_test=clin_agg(noCat_df_test, cat_df_test, big_df_test, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>any_vasoactive</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>...</th>\n",
       "      <th>(min, calcium)</th>\n",
       "      <th>(min, sodium)</th>\n",
       "      <th>(min, wbc)</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>bands</th>\n",
       "      <th>first_admit_age</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200030.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0881052</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0207853</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082467</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.114634</td>\n",
       "      <td>black</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>54.19</td>\n",
       "      <td>(333, 475]</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>113.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0822292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0042337</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424307</td>\n",
       "      <td>-0.024447</td>\n",
       "      <td>-0.207628</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>67.14</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0167035</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007917</td>\n",
       "      <td>-0.174736</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>74.93</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200061.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.46649</td>\n",
       "      <td>-0.101564</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0740006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008031</td>\n",
       "      <td>0.192664</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>45.75</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200063.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148081</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0042337</td>\n",
       "      <td>0.632268</td>\n",
       "      <td>0.347709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.555683</td>\n",
       "      <td>-0.012090</td>\n",
       "      <td>-0.109319</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>37.07</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id any_vasoactive bilirubin        bun cancer_elix   chloride  \\\n",
       "0    200030.0            1.0       NaN  0.0881052           0  0.0207853   \n",
       "1    200033.0            1.0       NaN -0.0822292           1  0.0042337   \n",
       "2    200036.0            0.0       NaN   0.119501           0  0.0167035   \n",
       "3    200061.0            0.0   1.46649  -0.101564           0          0   \n",
       "4    200063.0            0.0       NaN   0.148081           0  0.0042337   \n",
       "\n",
       "  creatinine daily_sofa dobutamine dopamine  ... (min, calcium) (min, sodium)  \\\n",
       "0          0   0.138647          1        0  ...       0.082467      0.003972   \n",
       "1  -0.234465  -0.430677          0        0  ...      -0.424307     -0.024447   \n",
       "2          0  -0.430677          0        0  ...            NaN      0.007917   \n",
       "3 -0.0740006          0          0        0  ...            NaN     -0.008031   \n",
       "4   0.632268   0.347709          0        0  ...      -0.555683     -0.012090   \n",
       "\n",
       "  (min, wbc)          ethnicity gender   bands first_admit_age pao2fio2ratio  \\\n",
       "0   0.114634              black      1  absent           54.19    (333, 475]   \n",
       "1  -0.207628  white/nonhispanic      1  absent           67.14   (475, 3000]   \n",
       "2  -0.174736  white/nonhispanic      1  absent           74.93   (475, 3000]   \n",
       "3   0.192664      unknown/other      1  absent           45.75   (475, 3000]   \n",
       "4  -0.109319      unknown/other      1  absent           37.07   (475, 3000]   \n",
       "\n",
       "     pco2 weight  \n",
       "0     <50  113.6  \n",
       "1  absent   74.0  \n",
       "2  absent   79.0  \n",
       "3  absent  250.0  \n",
       "4  absent    NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 30.9 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            4120\n",
       "unique              4\n",
       "top       (475, 3000]\n",
       "freq             3092\n",
       "Name: pao2fio2ratio, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.3 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pao2fio2ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'any_vasoactive',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " ('max', 'calcium'),\n",
       " ('max', 'sodium'),\n",
       " ('max', 'wbc'),\n",
       " ('min', 'calcium'),\n",
       " ('min', 'sodium'),\n",
       " ('min', 'wbc'),\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'first_admit_age',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2',\n",
       " 'weight']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.07 ms\n"
     ]
    }
   ],
   "source": [
    "list(worst_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    4045\n",
       "1.0      75\n",
       "Name: vasopressin, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.74 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['vasopressin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    3581\n",
       "<10        332\n",
       ">10        207\n",
       "Name: bands, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.37 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['bands'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    2818\n",
       "<50        939\n",
       ">50        363\n",
       "Name: pco2, dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.7 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pco2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'16052019'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.4 ms\n"
     ]
    }
   ],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 338 ms\n"
     ]
    }
   ],
   "source": [
    "##saving\n",
    "pd.DataFrame(worst_df_train).to_csv(Path(\n",
    "    wd+'/data/processed/merged/{}_worst_df_train_preImp_{}.csv'.format(date,timewindowdays)),index=False)\n",
    "pd.DataFrame(worst_df_test).to_csv(Path(\n",
    "    wd+'/data/processed/merged/{}_worst_df_test_preImp_{}.csv'.format(date,timewindowdays)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/processed/merged/16052019_worst_df_train_preImp_48.csv'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.02 ms\n"
     ]
    }
   ],
   "source": [
    "wd+'/data/processed/merged/{}_worst_df_train_preImp_{}.csv'.format(date,timewindowdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wd+'/data/processed/merged/{}_worstdf_preImp{}.csv'.format(date,timewindowdays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation 2:\n",
    "## out of date and needs updating as of 6/13/19\n",
    "## 4-11-19: range, mean and stdev aggregations (newagg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.ptp = difference btween min and max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##choose here if wanna use standardization or raw values.\n",
    "values=\"standardize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_range= big_noCat.loc[big_noCat.loc[:,'label'].isin(continuous),:]\n",
    "table4 = pd.pivot_table(big_range, values=values, columns='label', index=['icustay_id'],aggfunc=[np.ptp, np.median, np.std], dropna=[False,False,False]) \n",
    "table4.columns=['_'.join(col).strip() for col in table4.columns.values]\n",
    "table4=table4.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabing the rest of the variables not suitable for range or mean/std\n",
    "remaining= big_noCat.loc[big_noCat.loc[:,'label'].isin(onetime+ordinal),:]\n",
    "table5 = pd.pivot_table(remaining, values='value', columns='label', index=['icustay_id'],aggfunc=[max], dropna=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table5.columns\n",
    "table5.columns = table5.columns.get_level_values(1)\n",
    "table5=table5.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table4.head()#.rename(columns={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging aggregations together\n",
    "#first left join all different newagg together. \n",
    "table4=pd.merge(table4, table5, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(table4)[1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### formatting categorical to wide format to match the aggregated numerical\n",
    "big_categorical= big_df.loc[big_df.loc[:,'label'].isin(categorical),:].copy()\n",
    "big_categorical= big_categorical.pivot(\n",
    "    index='icustay_id',\n",
    "    values='value',\n",
    "    columns='label').reset_index() #need to convert to wide format. should be one row per patient per time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging categorical with aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using fxn written for worst_df to make newagg_df\n",
    "newagg_df=merge_cat_agg(table4, big_categorical, twoclass=False) #using range/mean/stdev aggregates \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newagg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(newagg_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(newagg_df).to_csv(Path(\n",
    "    wd+'/data/processed/merged/%s_newaggdf_std.csv' %(date)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newagg_df['leukocyte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd+'/data/processed/merged/%s_newaggdf_std.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation 3:\n",
    "# grabbing min/max/median/sd for only values found to be important from combining variable importance for random forest, boosted trees, and logistic regression on the baseline clinical max/min data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important_variables=[\"temperature\",\"sysbp\",\"daily_sofa\",\"meanartpress\",\"bun\",\"platelet\",\"ptt\",\"heartrate\",\"pao2fio2ratio\",\"creatinine\",\"first_admit_age\"]\n",
    "important_continuous=[\"temperature\",\"sysbp\",\"daily_sofa\",\"meanartpress\",\"bun\",\"platelet\",\"ptt\",\"heartrate\",\"creatinine\"]\n",
    "important_ordinal=[\"any_vasoactives\", 'vent_recieved', \"leukocyte\",\"pao2fio2ratio\"]\n",
    "important_onetime=['first_admit_age','weight']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #continuous and ordinal variables\n",
    "# big_noCat= big_df.loc[big_df.loc[:,'label'].isin(continuous+ordinal),:].copy()\n",
    "# big_noCat['value']= big_noCat['value'].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_noCat[big_noCat['label'].isin(vaso_active)].groupby('icustay_id')['value'].max().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##combining vasoactives\n",
    "vaso_active_df=big_noCat[big_noCat['label'].isin(vaso_active)].groupby('icustay_id')['value'].max().reset_index()\n",
    "vaso_active_df['uom']=\"y/n\"\n",
    "vaso_active_df['label']=\"any_vasoactives\"\n",
    "vaso_active_df['delta']=pd.to_timedelta(\"0days\")\n",
    "vaso_active_df['source']=\"any_vasoactives\"\n",
    "\n",
    "vaso_active_df=pd.merge(vaso_active_df, final_pt_df2[[\"icustay_id\",'subject_id',\"t_0\"]], how=\"left\", left_on=\"icustay_id\", right_on=\"icustay_id\")\n",
    "vaso_active_df=pd.merge(vaso_active_df, median_label, how=\"left\").fillna(0)\n",
    "vaso_active_df['standardize']=vaso_active_df['value']\n",
    "vaso_active_df['raw_value']=vaso_active_df['value']\n",
    "vaso_active_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaso_active_df.iloc[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_noCat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_noCat['label'].unique()\n",
    "#big_noCat=pd.concat([big_noCat, vaso_active_df], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_noCat[big_noCat['label']==\"any_vasoactives\"].head() #so this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##choose here if wanna use standardization or raw values.\n",
    "values=\"standardize\"\n",
    "#big_noCat[values]= big_noCat[values].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big_df2=pd.concat([big_df, vaso_active_df], sort=False)\n",
    "\n",
    "# #splitting categorical, ordinal and continuous\n",
    "# big_categorical= big_df.loc[big_df.loc[:,'label'].isin(important_ordinal+important_onetime),:].copy()\n",
    "\n",
    "# #continuous and ordinal variables\n",
    "# df_continuous= big_df.loc[big_df.loc[:,'label'].isin(important_continuous+ordinal),:].copy()\n",
    "# big_noCat['value']= big_noCat['value'].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous= big_noCat.loc[big_noCat.loc[:,'label'].isin(important_continuous),:]\n",
    "agg_table1 = pd.pivot_table(df_continuous, values=values, columns='label', index=['icustay_id'],aggfunc=[np.max, np.min, np.median, np.std], dropna=[False,False,False, False]) \n",
    "agg_table1.columns=['_'.join(col).strip() for col in agg_table1.columns.values]\n",
    "agg_table1=agg_table1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code above is not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabing the rest of the variables not suitable for range or mean/std\n",
    "big_df2=pd.concat([big_df, vaso_active_df], sort=False)\n",
    "\n",
    "agg_remaining= big_df2.loc[big_df2.loc[:,'label'].isin(important_onetime+important_ordinal),:]\n",
    "agg_table2 = pd.pivot_table(agg_remaining, values='value', columns='label', index=['icustay_id'],aggfunc=[max], dropna=False) \n",
    "agg_table2.columns = agg_table2.columns.get_level_values(1)\n",
    "agg_table2=agg_table2.reset_index()\n",
    "agg_table2.head()#.rename(columns={})\n",
    "\n",
    "agg_cont_cat=pd.merge(agg_table1, agg_table2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merging aggregations together\n",
    "#first left join all different newagg together. \n",
    "agg_cont_cat=pd.merge(agg_table1, agg_table2, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(agg_cont_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cont_cat['pao2fio2ratio'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cont_cat['any_vasoactives'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_cont_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(agg_cont_cat).to_csv(Path(\n",
    "    wd+'/data/processed/merged/%s_newaggdf2_std.csv' %(date)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YUS, got this reprocessed using a few of the top variables  4-16-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying to pipeline this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sklearn example  https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer_mixed_types.html#sphx-glr-auto-examples-compose-plot-column-transformer-mixed-types-py\n",
    "# We will train our classifier with the following features:\n",
    "# Numeric Features:\n",
    "# - age: float.\n",
    "# - fare: float.\n",
    "# Categorical Features:\n",
    "# - embarked: categories encoded as strings {'C', 'S', 'Q'}.\n",
    "# - sex: categories encoded as strings {'female', 'male'}.\n",
    "# - pclass: ordinal integers {1, 2, 3}.\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', LogisticRegression(solver='lbfgs'))])\n",
    "\n",
    "X = data.drop('survived', axis=1)\n",
    "y = data['survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"model score: %.3f\" % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_features = ['age', 'fare']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_features = ['embarked', 'sex', 'pclass']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class onehot(TransformerMixin):\n",
    "    def __init__(self, cols_to_transform):\n",
    "        self.cols_to_transform=cols_to_transform\n",
    "        \n",
    "    def transform(self,df ):\n",
    "        data = pd.get_dummies(df, columns = self.cols_to_transform, drop_first=True)\n",
    "        return(data)\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
