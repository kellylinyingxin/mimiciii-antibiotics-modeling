{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "offline editing 10/27/18\n",
    "\n",
    "todo: \n",
    "-1: look into making a data dictionary. need to look up structure and specific function of this. basically i need to annotate what all of my data is, where it comes from, how it's organized (ie by day, by specific time, by icustay, etc) and any limitations of it. \n",
    "\n",
    "-2: make a folder in notebooks specifically for older code (specifically for the different clinical variable versions)\n",
    "\n",
    "-3: refine cohort to only those who have bare minimum vitals. \n",
    "\n",
    "-4: questions for nelson and Yuan:\n",
    "\n",
    "    with missingness table i removed values that were null and counted those as missing, is this kosher? is this case by case basis?\n",
    "    also need to talk about how I wrangled sofa score and get their opinion.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.2 ms\n"
     ]
    }
   ],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime\n",
    "%reload_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 99.3 ms\n"
     ]
    }
   ],
   "source": [
    "#cohort import\n",
    "\n",
    "os.chdir('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling') #use to change working directory\n",
    "wd= os.getcwd() #'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling'\n",
    "\n",
    "final_pt_df2 = pd.read_csv(wd + '/data/raw/csv/16082018_fasnal_pt_df2.csv' , index_col=0)\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###different way to code filepaths, unsure if any better.\n",
    "# github_path= Path('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling')\n",
    "# data_folder = Path('data/raw/csv/72_hr_window')\n",
    "# file=\"%s_vaso_dose_72.csv\"%(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:472: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "#reading in all of my data that is not limited to 72 hour time window between t_0 and t+72\n",
    "date= '27082018' \n",
    "\n",
    "ventcategory_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/%s_ventcategory_df.csv' %(date)), index_col=0)\n",
    "\n",
    "vaso_dose_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_vaso_dose_72.csv' %(date)), index_col=0)\n",
    "#ventsettings_72=pd.read_csv(\n",
    "#    wd+'/data/raw/csv/72_hr_window/%s_ventsettings_72.csv' %(date), index_col=0)\n",
    "\n",
    "ventcategory_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/%s_ventcategory_df.csv' %(date)), index_col=0)\n",
    "\n",
    "echodata_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_echodata_72.csv' %(date)), index_col=0)\n",
    "labs_all_nosummary_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_labs_all_nosummary_72.csv' %(date)), index_col=0)\n",
    "\n",
    "\n",
    "weightfirstday_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_weightfirstday_df.csv' %(date)), index_col=0)\n",
    "heightfirstday_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_heightfirstday_df.csv' %(date)), index_col=0)\n",
    "\n",
    "vitals_all_nosummary_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_vitals_all_nosummary_72.csv' %(date)), index_col=0)\n",
    "uti_all_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_uti_all_72.csv' %(date)), index_col=0)\n",
    "bg_all_nosummary_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_bg_all_nosummary_72.csv' %(date)), index_col=0)\n",
    "\n",
    "rrt_merged_allpt_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_rrt_merged_allpt_df.csv' %(date)), index_col=0)\n",
    "gcs72_df=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/72_hr_window/%s_gcs72_df.csv' %(date)), index_col=0)\n",
    "\n",
    "sofa_df_72=pd.read_csv(Path(\n",
    "    wd+'/data/raw/csv/%s_sofa_df_72.csv' %(date)), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    " \n",
    "# import deeper_directory as py_mod_1\n",
    "# import deeper_directory.deepest_directory.py_mod_2 as py_mod_2\n",
    " \n",
    "# from deeper_directory import *\n",
    "# from deeper_directory.deepest_directory import *\n",
    " \n",
    "# print\n",
    " \n",
    "# LOCATE_PY_FILENAME = __file__\n",
    "# LOCATE_PY_DIRECTORY_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "# LOCATE_PY_PARENT_DIR = os.path.abspath(os.path.join(LOCATE_PY_DIRECTORY_PATH, \"..\"))\n",
    " \n",
    "# print \"Filename of locate.py: \" + LOCATE_PY_FILENAME\n",
    "# print \"Filepath of locate.py: \" + os.path.join(LOCATE_PY_DIRECTORY_PATH, LOCATE_PY_FILENAME)\n",
    "# print \"Directory Path of locate.py: \" + LOCATE_PY_DIRECTORY_PATH\n",
    "# print \"Parent Directory Path of locate.py: \" + LOCATE_PY_PARENT_DIR\n",
    " \n",
    "# print\n",
    " \n",
    "# print \"Filename of py_mod_1.py: \" + py_mod_1.PY_MOD_1_PY_FILENAME\n",
    "# print \"Filepath of py_mod_1.py: \" + os.path.join(py_mod_1.PY_MOD_1_PY_DIRECTORY_PATH, py_mod_1.PY_MOD_1_PY_FILENAME)\n",
    "# print \"Directory Path of py_mod_1.py: \" + py_mod_1.PY_MOD_1_PY_DIRECTORY_PATH\n",
    "# print \"Parent Directory Path of py_mod_1.py: \" + py_mod_1.PY_MOD_1_PY_PARENT_DIR\n",
    " \n",
    "# print\n",
    " \n",
    "# print \"Filename of py_mod_2.py: \" + py_mod_2.PY_MOD_2_PY_FILENAME\n",
    "# print \"Filepath of py_mod_2.py: \" + os.path.join(py_mod_2.PY_MOD_2_PY_DIRECTORY_PATH, py_mod_2.PY_MOD_2_PY_FILENAME)\n",
    "# print \"Directory Path of py_mod_2.py: \" + py_mod_2.PY_MOD_2_PY_DIRECTORY_PATH\n",
    "# print \"Parent Directory Path of py_mod_2.py: \" + py_mod_2.PY_MOD_2_PY_PARENT_DIR\n",
    " \n",
    "# print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.07 ms\n"
     ]
    }
   ],
   "source": [
    "def missingness_fxn(df,name, groupby,filteron):\n",
    "    \n",
    "    \"\"\"\n",
    "    input: dataframe w/ clinical data we want to assess the % missing values on.\n",
    "    output: a dataframe grouped by the different clinical variables with \n",
    "        associated % missingnss (ie how many icustays do not have this value)\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    missing_df= pd.DataFrame(\n",
    "        100* (1-(df.groupby(groupby)[filteron].nunique()/ len(hadm_id)))) #number of unique icustays with data /total # icustay\n",
    "    missing_df.reset_index(inplace=True)\n",
    "    missing_df= missing_df.rename(index=str, columns={\"label\":'label', filteron:'%missingness'})\n",
    "    missing_df['source']= name\n",
    "    missing_df['data_label']=groupby\n",
    "    return(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
